<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>CodingLabs</title>
        <link>http://blog.codinglabs.org</link>
        <description>keep coding, keep foolish</description>
        <lastBuildDate>Fri, 15 Feb 2019 14:52:22 +0800</lastBuildDate>
        <language>zh-cn</language>
        
        <item> 
            <title>统计学习理论的数理基础</title> 
            <link>http://blog.codinglabs.org/articles/statistical-learning-theory.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link> 
            <guid>http://blog.codinglabs.org/articles/statistical-learning-theory.html</guid> 
            <author>ericzhang.buaa@gmail.com 张洋</author> 
            <pubDate>Sat, 15 Sep 2018 00:00:00 +0800</pubDate> 
            <description>&lt;p&gt;统计学习（Statistical learning）是目前人工智能领域最为活跃的一个分支，其理论基础是统计学习理论（Statistical learning theory，以下有时会简称SLT）：一种以数理统计为数学基础，研究是否可以以及如何从经验数据中学习普遍概念的理论。&lt;/p&gt;
&lt;p&gt;目前诸多机器学习相关的初级书籍中，重点都放在了对各种模型的探讨，而对统计学习理论部分，要么是不涉及，要么是简要几页草草描述一下，这种不成体系的论述无法令读者尤其是机器学习的初学者对统计学习的基础理论形成系统化认知。&lt;/p&gt;
&lt;p&gt;所以我阅读了一些SLT相关的论文，并对SLT的基础部分进行了一个系统化学习，这篇文章是我对SLT数理基础的整理和总结。&lt;/p&gt;
&lt;p&gt;这篇文章目标是对于统计学习理论进行一个概述，在这个概述中，将始终保持简洁及易读，并尽量将SLT基础部分的系统脉络梳理清楚，给出SLT的一些基础但十分重要的结论。&lt;/p&gt;
&lt;p&gt;虽然不希望数学公式成为各位阅读本文的障碍，但是想要完全抛弃数学语言，又可以明确阐述SLT是不可能的，因此文章中会不可避免存在一些相对严格的数学描述、公式及证明。读者只要具有本科工科的数学水平，即可以无障碍阅读此文。&lt;/p&gt;
&lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%AE%9A%E4%B9%89%E5%8F%8A%E6%A1%86%E6%9E%B6&quot;&gt;1 统计学习的定义及框架&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#11-%E7%9B%AE%E6%A0%87&quot;&gt;1.1 目标&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#12-%E6%9C%80%E4%BC%98%E8%A7%A3%E7%A4%BA%E4%BE%8B&quot;&gt;1.2 最优解示例&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#13-%E9%80%9A%E7%94%A8%E6%9C%80%E4%BC%98%E8%A7%A3&quot;&gt;1.3 通用最优解&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#131-%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98%E7%9A%84%E6%9C%80%E4%BC%98%E8%A7%A3&quot;&gt;1.3.1 回归问题的最优解&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#132-%E4%BA%8C%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E7%9A%84%E6%9C%80%E4%BC%98%E8%A7%A3&quot;&gt;1.3.2 二分类问题的最优解&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#14-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0&quot;&gt;1.4 统计学习&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#2-%E4%B8%80%E8%87%B4%E6%80%A7&quot;&gt;2 一致性&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#21-%E5%AF%B9%E5%81%87%E8%AE%BE%E7%A9%BA%E9%97%B4%E7%9A%84%E6%80%9D%E8%80%83&quot;&gt;2.1 对假设空间的思考&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#22-%E5%81%8F%E5%B7%AE-%E6%96%B9%E5%B7%AE%E5%9D%87%E8%A1%A1&quot;&gt;2.2 偏差-方差均衡&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#23-%E4%B8%80%E8%87%B4%E6%80%A7&quot;&gt;2.3 一致性&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#3-%E5%85%A8%E5%B1%80%E4%B8%80%E8%87%B4%E7%AE%97%E6%B3%95&quot;&gt;3 全局一致算法&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#31-k-nearest-neighbor%E7%AE%97%E6%B3%95%E5%AE%9A%E4%B9%89&quot;&gt;3.1 K-nearest neighbor算法定义&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#32-knn%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7&quot;&gt;3.2 kNN的一致性&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#4-%E7%BB%8F%E9%AA%8C%E9%A3%8E%E9%99%A9%E6%9C%80%E5%B0%8F%E5%8C%96&quot;&gt;4 经验风险最小化&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#41-%E5%AE%9A%E4%B9%89&quot;&gt;4.1 定义&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#42-%E5%AF%B9erm%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E5%88%9D%E6%AD%A5%E6%8E%A2%E8%AE%A8&quot;&gt;4.2 对ERM一致性的初步探讨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#43-%E5%81%87%E8%AE%BE%E7%A9%BA%E9%97%B4%E4%B8%8E%E4%B8%80%E8%87%B4%E6%94%B6%E6%95%9B&quot;&gt;4.3 假设空间与一致收敛&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#431-%E5%8D%95%E4%B8%80%E5%87%BD%E6%95%B0%E5%81%87%E8%AE%BE%E7%A9%BA%E9%97%B4%E4%B8%8E%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B&quot;&gt;4.3.1 单一函数假设空间与大数定律&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#432-%E4%B8%80%E8%87%B4%E6%94%B6%E6%95%9Buniform-convergence&quot;&gt;4.3.2 一致收敛（Uniform Convergence）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#5-%E5%81%87%E8%AE%BE%E7%A9%BA%E9%97%B4%E5%BA%A6%E9%87%8F&quot;&gt;5 假设空间度量&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#51-%E6%9C%89%E9%99%90%E5%81%87%E8%AE%BE%E7%A9%BA%E9%97%B4&quot;&gt;5.1 有限假设空间&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#52-%E6%97%A0%E9%99%90%E5%81%87%E8%AE%BE%E7%A9%BA%E9%97%B4&quot;&gt;5.2 无限假设空间&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#521-symmetrization&quot;&gt;5.2.1 Symmetrization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#522-shattering-coefficient&quot;&gt;5.2.2 Shattering Coefficient&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#523-%E4%B8%80%E8%87%B4%E6%94%B6%E6%95%9B%E4%B8%8A%E7%95%8C&quot;&gt;5.2.3 一致收敛上界&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#524-vc%E7%BB%B4&quot;&gt;5.2.4 VC维&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#53-%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%B8%80%E8%87%B4&quot;&gt;5.3 贝叶斯一致&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#6-%E5%A4%A9%E4%B8%8B%E6%B2%A1%E6%9C%89%E5%85%8D%E8%B4%B9%E5%8D%88%E9%A4%90%E5%AE%9A%E7%90%86&quot;&gt;6 天下没有免费午餐定理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#7-%E7%89%B9%E5%AE%9A%E5%88%86%E5%B8%83%E5%BD%A2%E5%BC%8F%E4%B8%8B%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6&quot;&gt;7 特定分布形式下的学习框架&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#71-%E9%A2%91%E7%8E%87%E5%AD%A6%E6%B4%BEvs%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E6%B4%BE&quot;&gt;7.1 频率学派vs贝叶斯学派&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#72-%E9%A2%91%E7%8E%87%E5%AD%A6%E6%B4%BE%E4%B8%8E%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1&quot;&gt;7.2 频率学派与最大似然估计&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#73-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E6%B4%BE%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E4%B9%A0&quot;&gt;7.3 贝叶斯学派与贝叶斯学习&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#74-%E5%AF%B9%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83&quot;&gt;7.4 对两种方法的比较&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#8-%E6%80%BB%E7%BB%93&quot;&gt;8 总结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- toc stop --&gt;


&lt;h1 id=&quot;1-统计学习的定义及框架&quot;&gt;1 统计学习的定义及框架&lt;/h1&gt;
&lt;h2 id=&quot;11-目标&quot;&gt;1.1 目标&lt;/h2&gt;
&lt;p&gt;我们先来相对严格的描述，统计学习的目标是什么。&lt;/p&gt;
&lt;p&gt;现设存在以下实体：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;集合$X$，称为输入空间，集合$Y$，称为输出空间&lt;/li&gt;
&lt;li&gt;$X$与$Y$的联合概率分布$P(X,Y)$&lt;/li&gt;
&lt;li&gt;$X$到$Y$的映射，$f(x)=y$，其中$x\in X, y\in Y$&lt;/li&gt;
&lt;li&gt;定义在$X$，$Y$及$f$上的函数$L(x,y,f)\rightarrow \mathbb{R}$，其中$\mathbb{R}$表示实数集合&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;统计学习的终极目标是&lt;strong&gt;找一个映射$f$，使得$L$的期望最小&lt;/strong&gt;。所以，统计学习本质上是一个最优化问题，用数学语言描述，统计学习的目标找到下面的映射：
$$
f^\star=\mathop{\arg\min}_{f}{E(L(x,y,f))}
$$&lt;/p&gt;
&lt;h2 id=&quot;12-最优解示例&quot;&gt;1.2 最优解示例&lt;/h2&gt;
&lt;p&gt;注意假设我们知道$X$，$Y$，$P$和$L$的具体形式，那么统计学习则是根本不必要的，因为这本身变成了一个数学上的最优化问题，我们先忽略这个问题，并通过几个例子，建立对这个理论目标的直观认识。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;例1：$L$为常数函数$L(x,y,f)=0$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;根据期望的定义可知，此情况下$L$的期望$E(L(x,y,f))$亦退化为常函数恒等于0，因此问题变得十分trivial，只要随便取一个映射，如$f(x)=0$，即是目标映射&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;例2：$X=\mathbb{R}$，$Y=\mathbb{R}$，$L(x,y,f)=(y-f(x))^2$，且已知对于任意$x\in X$有$y=x^2$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;此时，输入和输出之间的关系是完全确定的，不存在随机性。由$L$的定义可知$L\ge0$，因此只要取$f(x)=x^2$即可令$L$处处为0，因此期望也自然是0。此时$f(x)=x^2$就是最优解。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;例3：$X=\mathbb{R}$，$Y=\mathbb{R}$，$L(x,y,f)=(y-f(x))^2$，且已知对于任意$x\in X$有$y=x^2+\epsilon$，其中$\epsilon\sim N(\mu,\sigma^2)$，即$\epsilon$服从均值为$\mu$，方差为$\sigma^2$的正态分布&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这里和例2唯一的不同是，输出中多了一个随机变量。此时：
$$
E(L(x,y,f))=E((y-f(x))^2)
$$
取$f(x)=x^2+\mu$，则：
$$
\begin{align}
E(L(x,y,f)) &amp;= E((x^2+\epsilon-x^2-\mu)^2) \\
&amp;= E((\epsilon-\mu)^2) \\
&amp;= E(\epsilon^2+\mu^2-2\mu\epsilon) \\
&amp;= E(\epsilon^2)+E(\mu^2)-2E(\mu)E(\epsilon) \\
&amp;= E^2(\epsilon)+Var(\epsilon) + \mu^2 - 2\mu^2 \\
&amp;= \mu^2+\sigma^2+\mu^2-2\mu^2 \\
&amp;= \sigma^2
\end{align}
$$
可以证明这是$E(L(x,y,f))$的最小值，所以$f(x)=x^2+\mu$是此时的最优解。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;例4：$X=\{0,1\}$，$Y=\{0,1\}$，当$f(x)=y$，$L(x,y,f)=0$，否则$L(x,y,f)=1$，联合概率分布$P$取值如下：$P(X=0,Y=0)=0.1$，$P(X=0,Y=1)=0.3$，$P(X=1,Y=0)=0.4$，$P(X=1,Y=1)=0.2$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这是一个离散情况，我们现在不经证明给出起最优映射为$f(x)=1-x$，此时$L$的期望为：
$$
E(L(x,y,f))=0.1\times1+0.3\times0+0.4\times0+0.2\times1=0.3
$$&lt;/p&gt;
&lt;h2 id=&quot;13-通用最优解&quot;&gt;1.3 通用最优解&lt;/h2&gt;
&lt;p&gt;上面举了几个在各项条件已知的情况下，最优映射的例子，可以看到，随着$X$，$Y$，$L$，$P$的不同，最优解的形式也各不相同。那么我们自然会有一个疑问：是否存在一个通用最优解公式，对于任意的$X$，$Y$，$L$，$P$，均可以套用公式得到最优解？答案是存在。&lt;/p&gt;
&lt;p&gt;但是直接在如此抽象的定义域上讨论通用最优解，会使得整个推理过于抽象，所以我们对定义域进行一定的限制，将重点放在以下两类常见的统计学习问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;回归问题（Regression）：$X=\mathbb{R}^m$，$Y=\mathbb{R}$，$L(x,y,f)=(y-f(x))^2$&lt;/li&gt;
&lt;li&gt;二分类问题（Binary Classification）：$X=\mathbb{R}^m$，$Y=\{0,1\}$，$L(x,y,f)=|y-f(x)|$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面分别分析两类问题的最优解。&lt;/p&gt;
&lt;h3 id=&quot;131-回归问题的最优解&quot;&gt;1.3.1 回归问题的最优解&lt;/h3&gt;
&lt;p&gt;在上述回归问题中，我们要求解的目标变成了：
$$
f^\star=\mathop{\arg\min}_f{E(L(x,y,f))}=\mathop{\arg\min}_f\int_Y\int_X(y-f(x))^2P(x,y)dxdy
$$
具体导出最优解的数学过程有点繁琐，所以这里我们用一个非严格但相对直观的方式，推导一下最优解。对严格数学推导过程感兴趣的同学可以自行推导，或参考资料。&lt;/p&gt;
&lt;p&gt;首先，由上述公式可以看出，这里的期望值是一个大于等于0的值，且显然$(y-f(x))^2\ge0$。因此我们直观上能感受到，最优解$f^\star$应该使得$f^\star(x)$在任何地方都尽量接近$y$，这样才能让$(y-f(x))^2$尽可能小。&lt;/p&gt;
&lt;p&gt;但是由于一般情况下我们认为$y$对$x$不是确定函数（否则这个函数就直接是最优解了），所以我们用条件概率刻画这个关系，任意给定一对$x\in X$，其对应的$y$服从：
$$
y\sim P(Y|X=x)
$$
而这个条件概率，可以对联合概率边缘化导出：
$$
P(Y|X=x)=\frac{P(x,Y)}{P(X=x)}
$$
而要想令$(y-f(x))^2$尽可能小，直觉上我们可以让$f^\star(x)$取$X=x$是$y$的条件期望（实际上数学严格证明结论也是如此）：
$$
f^\star(x)=E_{Y|X}(Y|X=x)=\int_YyP(y|X=x)dy
$$
也就是说&lt;strong&gt;回归问题的最优解是输入值的条件期望&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&quot;132-二分类问题的最优解&quot;&gt;1.3.2 二分类问题的最优解&lt;/h3&gt;
&lt;p&gt;二分类问题的最优解分析与回归问题类似，但是要简单很多，这得益于二分类问题的输出空间要更简单一些。下面具体看一下：&lt;/p&gt;
&lt;p&gt;与分析回归类似，我们先代入已知条件，写出优化目标：
$$
f^\star=\mathop{\arg\min}_f{E(L(x,y,f))}=\mathop{\arg\min}_f\{\int_X|0-f(x)|P(x,0)dx+\int_X|1-f(x)|P(x,1)dx\}
$$
上面的期望可以将联合概率分布改写为条件概率分布形式：
$$
E(L(x,y,f))=\int_X|0-f(x)|P(Y=0|x)P(x)dx+\int_X|1-f(x)|P(Y=1|x)P(x)dx
$$&lt;/p&gt;
&lt;p&gt;同样我们来非严格的分析一下这个式子如何取最小值。注意这里$f(x)$可能的取值只有0和1，所以$|0-f(x)|$和$|1-f(x)|$的取值一定是一个0一个1，所以按直觉来说一个合理的推断是无论何时，我们希望让被积函数部分尽可能小，具体来说：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如果$P(Y=0|x)P(x) &gt; P(Y=1|x)P(x)$，我们希望$|0-f(x)|=0$且$|1-f(x)|=1$，即令$f(x)=0$&lt;/li&gt;
&lt;li&gt;如果$P(Y=0|x)P(x) &lt; P(Y=1|x)P(x)$，我们希望$|0-f(x)|=1$且$|1-f(x)|=0$，即令$f(x)=1$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;另外我们注意到$P(x)$是一个大于等于0的常数，所以我们只要在$P(Y=0|x)$与$P(Y=1|x)$选择较大的即可，即：
$$
f^\star(x)=\mathop{\arg\max}_y{P(Y=y|X=x)}
$$
&lt;strong&gt;以上最优解叫做贝叶斯分类器，是二分类问题的理论最优分类器，也是平均意义下统计学习所能达到的分类器上限&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&quot;14-统计学习&quot;&gt;1.4 统计学习&lt;/h2&gt;
&lt;p&gt;下面我们严格定义统计学习。为了简单起见，从现在起，我们所有的讨论都围绕二分类问题展开，所得到的各种结论，理论上都可以推广到一般化的问题，但是在这里就不再从一般意义上进行推导，而是默认将问题限定在二分类问题。&lt;/p&gt;
&lt;p&gt;首先，我们给上面到处都用到的那个期望$E(L(x,y,f))$起一个名字：风险，用$R$表示。注意在其他条件已知的情形下，$R$是$f$的函数，即：
$$
R(f)=E(L(x,y,f))
$$
因此我们上述目标可以简化成：
$$
f^\star=\mathop{\arg\min}_{f}R(f)
$$
上文可以知道，如果我们知道联合概率分布$P(X,Y)$，则可以通过数学计算直接导出最优解：贝叶斯分类器。因此也就不需要统计学习什么的了，但是现实情况是，我们往往不知道，也无法通过什么方法观测到$P(X,Y)$，而只可以观测到一个可数但无穷（现实中往往是又穷的，但这里我们暂时放宽这个条件）的&lt;strong&gt;独立无偏&lt;/strong&gt;样本：$D_n=\{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\},n\rightarrow\infty$，我们是否有某种可靠的方式，去得到或逼近贝叶斯分类器。&lt;/p&gt;
&lt;p&gt;严格来说，（二分类）统计学习是这样一个问题：&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;统计学习&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;已知输入空间$X=\mathbb{R}^m$，输出空间$Y=\{0,1\}$，损失函数$L(x,y,f)=|y-f(x)|$。另存在一固定但未知且不可直接观测联合概率分布$P(X,Y)$，以及可数但任意大的iid（独立同分布）抽样$D_n=\{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\},n\rightarrow\infty$。设$f_b$为$P$下的贝叶斯分类器。&lt;/p&gt;
&lt;p&gt;现给出一个函数空间$F$（称为假设空间），和从$F$中选择分类器算法，使得当$n\rightarrow\infty$时，算法从$F$中选择的分类器的风险依概率收敛到贝叶斯分类器的风险，即对于任意$\epsilon&gt;0$，由算法选择的$f\in F$满足：
$$
P(|R(f)-R(f_b)|&gt;\epsilon)\rightarrow0,\text{when }n\rightarrow\infty
$$&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;注意，以上定义是一个非常严苛的定义，在定义一下，我们要求我们的算法在样本无限多时能以任意大的概率和任意小的差距逼近最优分类器且对联合概率分布没有任何假设。这是我们最理想的统计学习，但实际中，由于达到这个目标非常困难，所以我们可能会退而求其次寻求一些更宽松的目标。&lt;/p&gt;
&lt;p&gt;这一章节，我们通过数学方式严格定义了统计学习，并给出了最理想的情况。下一章节，我们进一步统计学习的一些细节问题。&lt;/p&gt;
&lt;h1 id=&quot;2-一致性&quot;&gt;2 一致性&lt;/h1&gt;
&lt;h2 id=&quot;21-对假设空间的思考&quot;&gt;2.1 对假设空间的思考&lt;/h2&gt;
&lt;p&gt;上面说道，我们的算法是从一个假设空间$F$中选择一个假设（函数），由此引出一个问题，不同的假设空间，对于是否能达到上述目标是有影响的。考虑下图中的两个假设空间：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../uploads/pictures/statistical-learning-theory/slt01.png&quot; alt=&quot;slt01&quot;&gt;&lt;/p&gt;
&lt;p&gt;其中All sapce是所有可能的分类器集合，橙色的分类器是贝叶斯分类器。可以看到，假设空间1包含了贝叶斯分类器，而假设空间2没有包含。那么，理论上任何算法都不可能从假设空间2中学到贝叶斯分类器（假设不存在与贝叶斯分类器的等效分类器），所以，如果我们不能保证所采用的假设空间包含贝叶斯分类器，就不可能达到上述的学习目标。&lt;/p&gt;
&lt;p&gt;同时，由于我们对联合概率分布$P$一无所知，现实中很难有办法保证我们选择的假设空间一定包含$f_b$。&lt;/p&gt;
&lt;p&gt;那么我们换个思路，能不能直接用All space作为假设空间。理论上是可以的，而且也确实有这种算法（例如KNN）。这样做虽然可以理论上直接以$f_b$为优化目标，但只有在样本真的是无限的情况下才可能，而且想要尽可能逼近$f_b$，对样本量的需求和对计算量的需求都会膨胀的十分迅速，因此实践中受现实条件所限，有可能无法使用。&lt;/p&gt;
&lt;h2 id=&quot;22-偏差-方差均衡&quot;&gt;2.2 偏差-方差均衡&lt;/h2&gt;
&lt;p&gt;另一类实践中更常用的方法是经验风险最小化（Empirical Risk Minimization，以下简称ERM），下面会有对ERM的单独讨论。这里只是简单说一下，ERM中存在偏差-方差均衡问题。为了解释这个，我们看下面的图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../uploads/pictures/statistical-learning-theory/slt02.png&quot; alt=&quot;slt02&quot;&gt;&lt;/p&gt;
&lt;p&gt;橙色点是贝叶斯分类器$f_b$，绿色点是我们的假设空间中最优的分类器$f_F$，其数学定义为：
$$
f_F=\mathop{\arg\min}_{f\in F}(R(f_b)-R(f))
$$
灰色点是我们的学习算法在观察了$n$个样本后得到的分类器$f_n$，这里假设$f_b\notin F$。此时相较于最优分类器，我们的整体差距为：
$$
R(f_b)-R(f_n)=(R(f_n)-R(f_F))+(R(f_F)-R(f_b))
$$
其中前一部分叫做方差（Variance），含义是我们学到的分类器和假设空间中最优分类器的差距，后者叫做偏差（Bias），表示假设空间中最优分类器与贝叶斯分类器的差距。&lt;/p&gt;
&lt;p&gt;我们当然希望两者可以同时被优化，但是后面的量化分析会提到，在ERM学习框架下，两者是矛盾的，为了缩小偏差，我们需要一个更大的假设空间，而更大的假设空间则意味着更大的偏差，甚至有可能导致ERM的学习过程不收敛（理论上不管多少样本也无法学到$f_F$），因此为了更小的方差，ERM希望有个一小的$F$，而这又往往意味着大的偏差。&lt;/p&gt;
&lt;p&gt;总而言之，ERM框架下，一般来说实践中无法同时将方差和偏差无限优化，需要在两者间做一个权衡（样本无限时理论上偏差和方差可以同时收敛到0，但实践中往往不可能拥有无限样本）。&lt;/p&gt;
&lt;p&gt;这里先简要给出这样一个结论，后面对ERM框架的定量分析会说明为什么会存在这个问题。&lt;/p&gt;
&lt;h2 id=&quot;23-一致性&quot;&gt;2.3 一致性&lt;/h2&gt;
&lt;p&gt;有了上述内容，现在我们可以定义一致性了，对一致性的严格描述是后续具体算法定量分析的基础。这里我们直接给出三种一致性的定义：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一致（Consistent）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在假设空间$F$和联合概率分布$P(X,Y)$固定的情况下，如果随着$n$趋向于无穷大，$f_n$依概率收敛于$f_F$，即对于任意$\epsilon&gt;0$：
$$
P(R(f_n)-R(f_F)&gt;\epsilon)\rightarrow 0,\text{when }n\rightarrow\infty
$$
则称学习算法一致。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;贝叶斯一致（Bayes-consistent）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在假设空间$F$和联合概率分布$P(X,Y)$固定的情况下，如果随着$n$趋向于无穷大，$f_n$依概率收敛于$f_b$，即对于任意$\epsilon&gt;0$：
$$
P(R(f_n)-R(f_b)&gt;\epsilon)\rightarrow 0,\text{when }n\rightarrow\infty
$$
则称学习算法贝叶斯一致。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;全局一致（Universally consistent）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在给定假设空间$F$的情况下，若不论联合概率分布$P(X,Y)$是什么分布，学习算法均贝叶斯一致，则称此算法全局一致。&lt;/p&gt;
&lt;p&gt;可以看到，三种一致从上到下是越来越苛刻的，所以也越来越难达到。我们在1.4中给出的统计学习定义，是按照全局一致来定义的，这是最理想的情况。在实践中，很多时候并无法达到全局一致，所以实际中能达到贝叶斯一致甚至仅仅能做到一致的算法，也是十分有用的（同时也更加简单且节省资源）。&lt;/p&gt;
&lt;h1 id=&quot;3-全局一致算法&quot;&gt;3 全局一致算法&lt;/h1&gt;
&lt;p&gt;长期以来，人们并不知道是否存在全局一致的统计学习算法。直到1977年，有人从数学上证明了K-nearest neighbor（kNN）算法（服从某些条件时）是全局一致的。&lt;/p&gt;
&lt;p&gt;我们现在来讨论kNN和其一致性问题。&lt;/p&gt;
&lt;h2 id=&quot;31-k-nearest-neighbor算法定义&quot;&gt;3.1 K-nearest neighbor算法定义&lt;/h2&gt;
&lt;p&gt;对于二分类问题，kNN可以这样描述：&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;K-nearest neighbor算法（用于二分类的）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;设$d$是定义在$X$空间上的距离函数，其满足如下条件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;任一点到自己的距离为零，即$d(x,x)=0$&lt;/li&gt;
&lt;li&gt;$d$的取值非负&lt;/li&gt;
&lt;li&gt;满足三角不等式，即：$d(x_1,x_2)\le d(x_1,x_3)+d(x_3,x_2)$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;kNN这样做分类：&lt;/p&gt;
&lt;p&gt;对于待分类点$x\in X$，取$D_n$中与$x$距离最小的k个点的类别$Y_k=\{y_1,y_2,...,y_k\}$，以$Y_k$的众数（mode）为$x$的取值。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;用白话说，就是找到$x$最近的k个样本，看这k个样本多数是0还是1，然后用多数表决的方式，为$x$分类。&lt;/p&gt;
&lt;p&gt;不难证明，kNN是在忽略联合分布的情况下，直接去逼近贝叶斯分类器的方法。那么这是否说明kNN一定是全局一致呢？&lt;/p&gt;
&lt;h2 id=&quot;32-knn的一致性&quot;&gt;3.2 kNN的一致性&lt;/h2&gt;
&lt;p&gt;我们先考虑最简单k=1的情况。考虑下面的例子：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;例5：设输入空间$X\sim Uni(0,1)$，即在0到1的区间服从均匀分布，$Y$是一个与$X$独立的随机变量，且取0的概率为0.1，取1的概率为0.9。使用1NN分类器进行分类，使用欧氏距离为距离函数，求贝叶斯分类器及1NN分类器的风险各是多少。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;先来考虑贝叶斯风险，由于$Y$独立于$X$，且取值1的概率更大，因此贝叶斯分类器为$f_b(x)=1$，此时贝叶斯风险为：
$$
R(f_b)=1\times0.1+0\times0.9=0.1
$$
而使用1NN分类器时，不管样本多大，离$x$最近的样本也服从取0的概率为0.1，取1的概率为0.9，我们设离$x$最近的样本为$x_d$因此，1NN分类器的风险为：
$$
R(f_{1nn})=P(y=0)\times P(x_d=1)+P(y=1)\times P(x_d=0)=0.1\times 0.9 + 0.9\times 0.1=0.18
$$
这个风险与样本集的数量无关。因此，1NN分类器在此情况下，不一致。&lt;/p&gt;
&lt;p&gt;使用同样的思路，我们可以证明，&lt;strong&gt;对于任意的有限的k，kNN算法均不一致&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;至此我们得到了一个kNN必要条件：若要kNN分类器一致，一个必要条件是$k\rightarrow\infty$。&lt;/p&gt;
&lt;p&gt;那么这个条件是否也是一个充分条件呢？并不是。Stone在1977年关于kNN全局一致证明的论文中，给出了如下充要条件：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;kNN算法全局一致，当且仅当，随着$n\rightarrow \infty$，$k\rightarrow \infty$，且$k/n\rightarrow 0$&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由此可以看成，kNN虽然是一个理论上全局一致的算法，但是实际中受限于训练样本的数量，其实很难做到适用于各种场景的万金油。否则，我们也不用研究其他算法，全都用kNN就好了。&lt;/p&gt;
&lt;p&gt;同时可以从上面看到，如果想要kNN发挥较好的效果，除了样本量$n$要足够大外，$k$的选择也尤为重要，根据理论分析，较好的选择是$k\sim log(n)$。如果k过小，例如1NN，此时方差很大，模型很容易过拟合，但如果k特别大，例如极端情况，$k=n$，此时分类器对于所有新样本均预测为同样的值（样本集的多数），导致欠拟合。&lt;/p&gt;
&lt;h1 id=&quot;4-经验风险最小化&quot;&gt;4 经验风险最小化&lt;/h1&gt;
&lt;p&gt;从上面分析可以看出，kNN算法虽然理论上可以达到全局一致，但是受限于现实中样本数量，并不是处处通用。下面讨论另一种统计学习准则：经验风险最小化。&lt;/p&gt;
&lt;h2 id=&quot;41-定义&quot;&gt;4.1 定义&lt;/h2&gt;
&lt;p&gt;所谓经验风险最小化（Empirical Risk Minimization，简称ERM），就是选择分类器$f_n$，使得分类结果在训练样本集上风险最小。为了形式化定义ERM，我们先定义经验风险：&lt;/p&gt;
&lt;p&gt;设有样本集$D_n=\{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\}$，分类器$f$的经验风险定义为：
$$
R_{emp}(f)=\frac{1}{n}\sum_{i=1}^n{L(x_i,y_i,f)}
$$
经验风险最小化就是选择$f_n$，使得：
$$
f_n=\mathop{\arg\min}_{f\in F}R_{emp}(f)
$$
直觉上这是很合理的，如果训练样本来自总体的无偏独立抽样，那么感觉只要最小化经验风险，应该也可以得到一个总体风险很小的分类器。但这毕竟是直觉，下面我们从数学上严格的分析一下ERM是否能真的如我们所愿。&lt;/p&gt;
&lt;h2 id=&quot;42-对erm一致性的初步探讨&quot;&gt;4.2 对ERM一致性的初步探讨&lt;/h2&gt;
&lt;p&gt;首先我们来考察ERM的一致性，这里我们先不要求全局一致或贝叶斯一致，只要求最宽松的一致性，即在样本无限多的情况下，ERM是否能无限逼近$F$中风险最小的分类器$f_F$。&lt;/p&gt;
&lt;p&gt;考虑下面的例子：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;例6：设输入空间$X\sim Uni(0,1)$，即在0到1的区间服从均匀分布，，其中当$X\le0.5$时，$Y=0$；当$X\gt 0.5$时，$Y=1$。现有iid样本集$D_n$，$F$不限制范围。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;注意由于例6中输入和输出是确定关系，因此：
$$
f_b(x)=f_F(x)=
\begin{cases}
    0       &amp; \quad \text{if } x \le 0.5\\
    1  &amp; \quad \text{if } x \gt 0.5
\end{cases}
$$
全局风险$R$为0。&lt;/p&gt;
&lt;p&gt;同时我们构建这样一个分类器：
$$
f_n(x)=
\begin{cases}
    y_i &amp; \quad \text{if } x \in D_n \text{ and } x=x_i\\
    1  &amp; \quad \text{otherwise}
\end{cases}
$$
也就是说，如果待分类样本$x$出现在样本集，就按样本中那个样本的标签分类，否则分类为1。很明显，这个分类器可以做到$R_{emp}$为0，但是，当放到全部$X$上时，由于$D_n$的大小相对$X$是可以忽略不计的（用测度论的语言来说，$D_n$是一个零测集），所以我们可以认为$f_n$始终输出1，因此$R(f_n)=0.5$。由于$D_n$是可数集合，所以其测度始终为0，因此就算$D_n$无限多，$f_n$也不会收敛到$f_F$，所以，在这个分类器下，ERM不一致。&lt;/p&gt;
&lt;p&gt;通过这个反例，我们可以得出结论：&lt;strong&gt;ERM在不加任何限制条件的情况下，不一致&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&quot;43-假设空间与一致收敛&quot;&gt;4.3 假设空间与一致收敛&lt;/h2&gt;
&lt;p&gt;上面得出结论，ERM不能在不加任何限制的情况下保证一致。那么是否有什么方法，可以限制ERM的某些方面，让ERM一致呢。一个直观感觉是，ERM所面对的假设空间$F$太大了，由于有太多假设可以选择，选择方式过于自由，导致ERM可以直接去拟合样本集。那么如果限制假设空间，会有什么效果吗？&lt;/p&gt;
&lt;h3 id=&quot;431-单一函数假设空间与大数定律&quot;&gt;4.3.1 单一函数假设空间与大数定律&lt;/h3&gt;
&lt;p&gt;我们先可以考虑一个最极端的情况，如果$F$中仅有一个函数$f$，此时，任何学习算法都显然一致，因为此时假设空间中只有一个选择，所以无论何时$f_n=f_F=f$。虽然这样一个假设空间看起来毫无作用，但是我们可以借此分析一个问题：当$n\rightarrow\infty$时，$R_{emp}(f)\rightarrow R(f)$吗？换言之，当样本增多时，$f$的经验风险是否可以无限逼近真实风险？&lt;/p&gt;
&lt;p&gt;为了回答这个问题，先引入统计学中一个重要的定理：大数定律。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;大数定律&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;设有随机变量$\xi$，以及$\xi$的iid抽样$D_n=\{\xi_1,\xi_2,...,\xi_n\}$。当$n\rightarrow \infty$时，样本均值依概率收敛于$\xi$的期望，用数学语言表述就是，对于任意$\epsilon \gt 0$：
$$
P(|\frac{1}{n}\sum_{i=1}^n{\xi_i}-E(\xi)|&gt;\epsilon)\rightarrow 0, \text{ when } n\rightarrow \infty
$$&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;如果考察上面的表示，发现在$f$固定的情况下，$R(f)$是$L$的期望，而$R_{emp}(f)$是$L$的样本均值，因此根据大数定律可以直接得出结论：&lt;strong&gt;在$f$固定时，$R_{emp}(f)$依概率收敛到$R(f)$&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&quot;432-一致收敛（uniform-convergence）&quot;&gt;4.3.2 一致收敛（Uniform Convergence）&lt;/h3&gt;
&lt;p&gt;通过以上分析可以看到，如果是单一函数，经验风险是依概率收敛到真实风险的，而当$F$中有多个函数时，由于$f_n$是一个依赖于样本集的非固定函数，因此大数定律失效。&lt;/p&gt;
&lt;p&gt;那么有没有办法将大数定律推广到假设空间是多函数情况的呢，考虑下面定义：
$$
\mathop{sup}_{f\in F}|R(f)-R_{emp}(f)|
$$
这个式子表示$F$中所有函数真实风险和经验风险误差的上界。由于是上界，我们显然有：
$$
|R(f)-R_{emp}(f)|\le\mathop{sup}_{f\in F}|R(f)-R_{emp}(f)| \\
P(|R(f_n)-R_{emp}(f_n)|\ge\epsilon)\le P(\mathop{sup}_{f\in F}|R(f)-R_{emp}(f)|\ge\epsilon)
$$
显然如果上式子右边依概率收敛，则左边也依概率收敛。下面将上式和$F$的一致性关联起来：
$$
\begin{align}
|R(f_n)-R(f_F)| &amp;= R(f_n)-R(f_F) \\
&amp;= R(f_n) +(-R_{emp}(f_n)+R_{emp}(f_n)-R_{emp}(f_F)+R_{emp}(f_F)) -R(f_F) \\
&amp;\le (R(f_n)-R_{emp}(f_n))+(R(f_F)-R_{emp}(f_F)) \\
&amp;\le 2\mathop{sup}_{f\in F}|R(f)-R_{emp}(f)|
\end{align}
$$
综上可得：
$$
P(|R(f_n)-R(f_F)|\ge\epsilon)\le P(\mathop{sup}_{f\in F}|R(f)-R_{emp}(f)|\ge\epsilon/2)
$$
如果右边依概率收敛，则左边必然依概率收敛，而左边依概率收敛，则意味着一致。&lt;/p&gt;
&lt;p&gt;如果随着$n\rightarrow\infty$，$P(\mathop{sup}_{f\in F}|R(f)-R_{emp}(f)|\ge\epsilon)\rightarrow 0$，我们说假设空间$F$是一致收敛（Uniform convergence）的。&lt;/p&gt;
&lt;p&gt;由上，我们得出重要结论：&lt;strong&gt;如果假设空间$F$一致收敛，则ERM学习在$F$上是一致的&lt;/strong&gt;。&lt;/p&gt;
&lt;h1 id=&quot;5-假设空间度量&quot;&gt;5 假设空间度量&lt;/h1&gt;
&lt;p&gt;从上面分析我们可以知道，若要使用ERM，则必须保证假设空间$F$一致收敛，否则无法保证ERM的一致性。那么现在我们面对的问题就变成了，如何选择或从数学上证明一个假设空间是一致收敛的呢？&lt;/p&gt;
&lt;h2 id=&quot;51-有限假设空间&quot;&gt;5.1 有限假设空间&lt;/h2&gt;
&lt;p&gt;我们先讨论假设空间有限的情况。设$F=\{f_1,f_2,...,f_m\}$是一个具有$m$个假设函数的有限假设空间。这：
$$
P(\mathop{sup}_{f\in F}|R(f)-R_{emp}(f)|\ge \epsilon)\le\sum_{i=1}^mP(|R(f_i)-R_{emp}(f_i)|\ge \epsilon)
$$
以上式子的意义是，由于$F$中任意一个假设的经验风险与实际风险的误差大于$\epsilon$就会导致$F$的误差上限大于$\epsilon$，所以右侧是比左侧更可能的发生的事件，所以右侧的概率大于左侧。&lt;/p&gt;
&lt;p&gt;我们现在不加证明给出一个定理：Chernoff bound：&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Chernoff bound&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果$\xi$是一个随机变量，且取值范围为$[0,1]$，则对于$\xi$的iid样本集$\{\xi_1,\xi_2,...,\xi_n\}$，有下面不等式：
$$
P(|\frac{1}{n}\sum_{i=1}^n\xi_i-E(\xi)|\ge\epsilon)\le2\exp(-2n\epsilon^2)
$$&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Chernoff bound相比大数定律给出了一个定量的上界。由Chernoff bound可以得出：
$$
P(\mathop{sup}_{f\in F}|R(f)-R_{emp}(f)|\ge \epsilon)\le\sum_{i=1}^mP(|R(f_i)-R_{emp}(f_i)|\ge \epsilon) \le 2m\ exp(-2n\epsilon^2)
$$
和明显，当$n\rightarrow\infty$时，右侧收敛到0，这蕴含着$F$一致收敛，因此：&lt;strong&gt;有限的假设空间上，ERM是一致的&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&quot;52-无限假设空间&quot;&gt;5.2 无限假设空间&lt;/h2&gt;
&lt;p&gt;一般来说，我们现实中很少会使用有限假设空间，因此，我们需要继续分析假设空间无限的情况，有什么方法可以保证其一致收敛。&lt;/p&gt;
&lt;h3 id=&quot;521-symmetrization&quot;&gt;5.2.1 Symmetrization&lt;/h3&gt;
&lt;p&gt;在继续分析之前，我们先来处理一个十分讨厌的问题。如果仔细看上面的分析就会发现，我们一直带着一个很烦人的东西$R(f)$，为什么这东西烦人呢，因为由于实际中我们无法知道联合概率分布，所以自然也无法计算出真实风险$R(f)$，所以如果继续带着这么一个无法观测的东西，总觉得是颗雷。所以我们先把这东西用什么可以观测的量代替掉。&lt;/p&gt;
&lt;p&gt;这个还真可以做到，需要通过一个叫Symmetrization的技巧。简单来说，Symmetrization的意思是，如果我们除了$D_n$，还有一组独立于$D_n$且同样大小的iid抽样$D_n&#39;$，我们定义其上的经验风险是$R_{emp}&#39;(f)$，则有如下定理：&lt;/p&gt;
&lt;p&gt;若$m\epsilon^2\gt 2$，则：
$$
P(\mathop{sup}_{f\in F}|R(f)-R_{emp}(f)|\gt\epsilon)\le2P(\mathop{sup}_{f\in F}|R_{emp}(f)-R_{emp}&#39;(f)|\gt\epsilon/2)
$$
由于证明比较繁琐，我们不去证明这个不等式。但是我们可以看出上式的价值，就是我们不再依赖不可观测的$R(f)$了，而只依赖可以观测的经验风险。所以如果我们能找出什么条件使得$\mathop{sup}_{f\in F}{|R_{emp}(f)-R_{emp}&#39;(f)|}$依概率收敛，则大功告成。现在我们进行这一步。&lt;/p&gt;
&lt;h3 id=&quot;522-shattering-coefficient&quot;&gt;5.2.2 Shattering Coefficient&lt;/h3&gt;
&lt;p&gt;为什么只依赖经验风险是非常重要的呢，因为我们需要注意这样一个非常重要的事实：&lt;strong&gt;即使$F$是无限的，但是对于特定的$n$，经验风险的取值是有限的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;什么意思呢，考虑一个二分类问题，给出一个有n个样本的样本集，不论你的$F$中有多少函数，最终输出最多只能有$2^n$种可能（每个样本输出要么0，要么1），所以，如果只考虑经验风险，任何$F$在面对n个样本时，在ERM评价下其等价于一个&lt;strong&gt;最多&lt;/strong&gt;有$2^n$个假设函数的有限假设空间。&lt;/p&gt;
&lt;p&gt;我们量化一下这个度量，对于假设空间$F$，我们定义一个函数：
$$
\mathcal{N}(F,n)=\text{当样本数为n时，F所能产生的不同分类结果的数量}
$$
这个函数我们称为$F$的shattering coefficient，下面举例子直观说明一下它的含义。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;例7：设一个输入空间在$[0,1]$上的二分类问题。有这样一个模型：它选择一个点$\theta\in [0,1]$，将区间分为$[0,\theta]$和$(\theta,1]$两部分，然后将两个部分分别作为一个类别。这个模型的shattering coefficient是什么？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;简单来说，这个模型就是将输入空间一分为二，一边赋值为0，一边赋值为1，因为$\theta$有无数种选择，所以$F$是一个无限集合。&lt;/p&gt;
&lt;p&gt;另外可以看出，基于上面模型分类时，能输出几种分类结果，仅与样本点的标签和相对排布有关，与具体位置无关。当有n个二值样本点时，在一维空间里有$2^n$种排布方式。显然在$n\le 2$时，是可以完美分开的，所以$\mathcal{N}(F,1)=2$，$\mathcal{N}(F,2)=4$。现在考察$n\gt 2$的情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当$n=3$时，有8种排布方式，其中ooo，oox，oxx，xxx，xxo，xoo可以由$F$输出，但是oxo和xox两种情况是无法输出的，因此$$\mathcal{N}(F,3)=6$$&lt;/li&gt;
&lt;li&gt;当$n=4$时，有16种排布方式，其中oooo，ooox，ooxx，oxxx，xxxx，xxxo，xxoo，xooo可以由$F$输出，其他情况无法输出的，因此$$\mathcal{N}(F,4)=8$$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们一般化考虑一下，当样本个数为n时，有$2^n$中排布可能，但是$F$中假设函数可以输出的排布，一定是可以找到某一点，左边全是x，右边全是o；或者左边全是o，右边全是x。可以这样思考有多少可能：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先n个样本全是oo...o，这是一个输出可能&lt;/li&gt;
&lt;li&gt;从右边开始，依次将每个位置的样本由o变为x，经过n次，变为xx..x，这是n种可能输出&lt;/li&gt;
&lt;li&gt;再从右边开始，依次将x变成o，经过n次，变为oo..o，也是n种输出可能，但是由于全是o的情况在上面已经提到了，所以这里有n-1种新的输出可能&lt;/li&gt;
&lt;li&gt;将上面可能输出相加$1+n+n-1=2n$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因此我们可得，对于例7的模型，$\mathcal{N}(F,n)=2n$&lt;/p&gt;
&lt;h3 id=&quot;523-一致收敛上界&quot;&gt;5.2.3 一致收敛上界&lt;/h3&gt;
&lt;p&gt;有了上面的铺垫，我们可以推导一般情况下ERM一致收敛的条件了。
$$
\begin{align}
&amp;P(\mathop{sup}_{f\in F}|R(f)-R_{emp}(f)|\gt\epsilon) \\
&amp;\le 2P(\mathop{sup}_{f\in F}|R_{emp}(f)-R_{emp}&#39;(f)|\gt\epsilon/2) \\
&amp;= 2P(\mathop{sup}_{f\in F_{2^{2n}}}|R_{emp}(f)-R_{emp}&#39;(f)|\gt\epsilon/2) \\
&amp;\le 2\mathcal{N}(F,2n)exp(-n\epsilon^2/4)
\end{align} \\
$$&lt;/p&gt;
&lt;p&gt;这个推导稍微有点复杂，下面说明一下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;第一步推导是上面提到的Symmetrization&lt;/li&gt;
&lt;li&gt;第二部推导是基于在两个容量为n的样本集上，其经验风险差值的输出只有$2^{2n}$种可能，将$F$等价为一个容量为$2^{2n}$的有限假设空间&lt;/li&gt;
&lt;li&gt;第三步推论基于有限假设空间的Chernoff bound给出&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;至此，我们得到了ERM一致的一个一般性上界条件：&lt;strong&gt;若随着$n\rightarrow \infty$，$2\mathcal{N}(F,2n)exp(-n\epsilon^2/4)\rightarrow 0$，则ERM是一致的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;看几个例子：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;上面提到例7中，$\mathcal{N}(F,2n)=4n$，代入上界，得到$8nexp(-n\epsilon^2/4)$，显然这个是收敛到0的，所以例7在ERM下是一致的&lt;/li&gt;
&lt;li&gt;考虑$\mathcal{N}(F,n)\le (2n)^k$，其中$k$是常数。此时，上界为$2exp(klog(2n)-n\epsilon^2/4)$，显然是收敛到0的。所以&lt;strong&gt;如果$\mathcal{N}(F,2n)$随着n的增长呈多项式级别增长，则ERM是一致的&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;考虑$F$可以任意取函数，也就是$\mathcal{N}(F,2n)=2^{2n}$，此时上界为$2exp(n(2log(2)-\epsilon^2/4)$，这个上界并不收敛到0。但是此时不能贸然说这个$F$就不一致，因为上界收敛只是一致的充分条件，而不是必要条件。如果用更多的数学技巧，我们可以得出一致的一个必要条件：$log\mathcal{N}(F,n/)/n\rightarrow 0$，由于$log(2^n)/n=nlog2/n=log2$不收敛到0，所以如果$F$取全体可能的假设时，ERM是不一致的&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;524-vc维&quot;&gt;5.2.4 VC维&lt;/h3&gt;
&lt;p&gt;上面的shattering coefficient可以看成对假设空间容量的一种度量，除了shattering coefficient外，还有一些其他的度量方式，可以给出ERM一致的充分条件。我们这里介绍其中最知名的一个，叫做VC维（VC Dimension）。&lt;/p&gt;
&lt;p&gt;简单来说，一个假设空间的$F$的VC维是一个非负整数整数$d$，其意义是，我们可以构造一个容量为$d$的样本，使得$F$中的函数可以输出$2^d$种不同结果，但是无法构造一个容量为$d+1$的样本，使得$F$中的函数可以输出$2^{d+1}$种不同结果。&lt;/p&gt;
&lt;p&gt;举个例子。考虑二维空间的线性分类器，当样本容量为3时，我们可以这样排布样本，使得8种情况都可以被分开：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../uploads/pictures/statistical-learning-theory/slt03.png&quot; alt=&quot;slt03&quot;&gt;&lt;/p&gt;
&lt;p&gt;注意，这里我们不需要对于所有容量为3的样本都可以完全分开（若三个样本共线，则存在线性分类器分不开的情况），我们只需要存在这样一组样本即可。&lt;/p&gt;
&lt;p&gt;但是，当样本容量为4时，则无法构造一个排布令16种情况都可以被分开，因为无论如何排不，都会遇到类似如下的情况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../uploads/pictures/statistical-learning-theory/slt04.png&quot; alt=&quot;slt04&quot;&gt;&lt;/p&gt;
&lt;p&gt;无法被一条线分开。&lt;/p&gt;
&lt;p&gt;所以，二维平面上线性分类器的VC维为3。&lt;/p&gt;
&lt;p&gt;基于VC维，我们可以给出这样一个ERM一致的充分必要条件：&lt;strong&gt;ERM对于假设空间$F$一致，当且仅当$F$的VC维有限&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;由于是充要条件，VC维往往可以用来判断一个ERM是否有效。例如可以证明，对于任何有限的维数，线性分类器的VC维都是有限的，所以线性分类器总是ERM一致。这就为我们使用ERM准则训练线性模型做分类找到了理论依据。例如，逻辑回归就是一种线性分类器，其训练准则就是ERM。&lt;/p&gt;
&lt;h2 id=&quot;53-贝叶斯一致&quot;&gt;5.3 贝叶斯一致&lt;/h2&gt;
&lt;p&gt;到目前为止，我们都在讨论$F$内的一致性，即ERM是否可以逼近$f_F$，但是一直没有涉及贝叶斯一致。实践中，贝叶斯一致不是那么受关注，因为一般统计学习中，我们更注重方差的收敛，只要能找到假设空间中的最优函数，就可以接受。而要达到贝叶斯一致，势必要使用更大的假设空间，而上面分析可以看到，一旦假设空间太大，很容易就不一致，就算一致，也要冒着方差变大的风险，有时得不偿失。&lt;/p&gt;
&lt;p&gt;所以这一小节，我们简单讨论一下达到贝叶斯一致的理论，但是不会像上文讨论$F$内一致那么细致。&lt;/p&gt;
&lt;p&gt;从直觉上可以知道，如果要实现贝叶斯一致，需要同时满足一下两个条件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不能使用固定的$F$（除非有什么办法保证$f_b\in F$），随着样本数的增多，$F$要不断扩大，使其无限一定会包含$f_b$&lt;/li&gt;
&lt;li&gt;$F$的扩张速度不能太快，或者说，不能导致$F$内本身不一致&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面给出一个基于VC维定义的贝叶斯一致定理：&lt;/p&gt;
&lt;p&gt;设有一个扩张假设空间序列：$F_1\subset F_2\subset ... \subset F_n \subset ...$，$f_1,f_2,...,f_n,...$是假设空间中经验风险最小化准则下的最优解，如果随着$n\rightarrow \infty$，满足如下两个条件：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$VC(F_n)logn/n\rightarrow 0$&lt;/li&gt;
&lt;li&gt;$R(f_n)\rightarrow R(f_b)$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;则$f_n$贝叶斯一致。&lt;/p&gt;
&lt;p&gt;我们不再详细分析这个定理，有兴趣的同学可以自行查找相关资料。&lt;/p&gt;
&lt;p&gt;一般在实践中，我们无法根据上述准则准确调整$F$使得ERM下贝叶斯一致，更常用的方法是使用正则化（Regularization）。&lt;/p&gt;
&lt;p&gt;所谓正则化，就是我们定义如下风险：&lt;/p&gt;
&lt;p&gt;$$
R_{reg}(f)=R_{emp}(f)+\lambda\Omega(f)
$$&lt;/p&gt;
&lt;p&gt;其中$\lambda$是一个非负数，用于控制正则化的作用，$\Omega(f)$是一个函数的函数，用于评价函数的复杂性。&lt;/p&gt;
&lt;p&gt;上述风险叫做结构风险，相应的，最小化上述风险就叫做结构风险最小化。&lt;/p&gt;
&lt;p&gt;为了使得正则化能起到促进贝叶斯一致的作用，理论上我们要小心调整$\lambda$，使得随着n的增大，$\lambda$逐渐收敛为0。但在实际中使用正则化时，往往是使用经验进行调整，而非如此精细的量化分析。&lt;/p&gt;
&lt;h1 id=&quot;6-天下没有免费午餐定理&quot;&gt;6 天下没有免费午餐定理&lt;/h1&gt;
&lt;p&gt;通过以上分析，我们似乎得到了一个非常乐观的结论：不论底层联合分布$P(X,Y)$如何，只要我们按上文分析控制$F$的规模，则总可以通过ERM准则学习到一些东西（一致）。那么现实真的如此美好吗？&lt;/p&gt;
&lt;p&gt;考虑你通过ERM学习出一个你认为的最好分类器f，那么我一定可以构造一个集合$\{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\}$，使得你的分类器在这个样本集上经验风险为0，只要我按你的分类器给出的输出为每个样本赋值就可以了，同样的，我也可以构造一个集合让你的分类器风险任意大，只要我给出一个足够大的n，并且对其中每个样本根据你的分类器反向赋值就好了。&lt;/p&gt;
&lt;p&gt;由此推断，&lt;strong&gt;在你给定我一个分类器$f$后，我总有办法构造一个样本集，让你的分类器的经验风险是任何值&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;思考一下为什么会出现这个问题？这个和上面说的一致性是否矛盾呢？实际上不矛盾，因为我们上面所有一致性分析都基于一个假设：训练样本可以无限大，但是，现实中样本集总是有限的。&lt;/p&gt;
&lt;p&gt;基于以上分析，我们可以得到这样一个结论：对于任意统计学习方法，我们总可以构造一个联合分布，使得基于这个分布的iid有限大小抽样所学习到的分类器在其上的效果与随机猜测无异。一个形式化的表述为：&lt;/p&gt;
&lt;p&gt;给定$\epsilon\gt0$，对于任意$n\in \mathbb{N}$和分类器$f_n$，我们总可以构造一个联合概率分布$P$，使得$P$的贝叶斯风险为0，且$f_n$的期望风险大于$\frac{1}{2}-\epsilon$&lt;/p&gt;
&lt;p&gt;以上定理称为天下没有免费的午餐定理（No free launch theorem，以下简称NFL定理）。&lt;/p&gt;
&lt;p&gt;NFL定理可以说是SLT重最重要的定理，没有之一。根据NFL定理，我们可以得出如下重要推论：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如果不对底层联合概率分布做任何假设，则统计学习无法从理论上保证学到任何东西&lt;/li&gt;
&lt;li&gt;没有一个分类器天生比另一个分类器更优，平均来说所有分类器都是一样的，只有当对底层联合分布有假设后，才能判定分类器的优劣&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;之所以说NFL重要，因为它同时说明了如下统计学习的本质：&lt;strong&gt;统计学习不是个纯粹的数学问题，数学不能保证统计学习是有效的，更不能从数学上分析出普遍意义上一个模型比另一个模型更好。统计学习只有结合业务经验才能起作用，没有业务经验对底层联合分布的预设判断，统计学习就没有意义。这也意味着，不存在独立于业务经验的纯数学意义的模型优劣的判定，也不可能独立于业务经验，仅靠对训练样本的数学分析全自动进行统计学习&lt;/strong&gt;。&lt;/p&gt;
&lt;h1 id=&quot;7-特定分布形式下的学习框架&quot;&gt;7 特定分布形式下的学习框架&lt;/h1&gt;
&lt;p&gt;上面的分析是基于不假设$P$的形式进行的，最后我们到处了NFL定理，说明若对$P$无任何假设，则统计学习不可能。&lt;/p&gt;
&lt;p&gt;所以，现实中的统计学习，往往是首先假设$P(X,Y)$的分布形式，而认为不确定的仅仅是$P(X,Y)$的参数。进一步，如果我们仅仅是需要得到判别结果，我们并不需要去估计$P(X,Y)$，而只要得到以下条件概率的估计就好了：&lt;/p&gt;
&lt;p&gt;$$
P(Y|X=x;\theta)
$$&lt;/p&gt;
&lt;p&gt;$\theta$是这个分布的参数向量。例如假设$P(Y|X;\theta)$是一个高斯分布，则$\theta=(\mu,\sigma^2)$。如果能估计出上述分布，我们只要按照：&lt;/p&gt;
&lt;p&gt;$$
\mathop{\arg\max}_{y\in Y}{P(y|X=x;\theta)}
$$&lt;/p&gt;
&lt;p&gt;就可以得到$y$的判别结果。所以现在问题变成了，如何通过样本集估计$\theta$。&lt;/p&gt;
&lt;p&gt;从不同视角出发，这个问题可以有不同解法，下面我们先探讨数理统计的两个流派：频率学派和贝叶斯学派，以及他们对于这个问题视角的差异。然后，分别给出两个流派解决这个问题的框架。&lt;/p&gt;
&lt;h2 id=&quot;71-频率学派vs贝叶斯学派&quot;&gt;7.1 频率学派vs贝叶斯学派&lt;/h2&gt;
&lt;p&gt;频率学派与贝叶斯学派是数理统计中的两个重要派别，两者主要的区别在于对于随机这一概念的视角不同。具体来说：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;频率学派认为随机的系统客观而本质存在的属性，决定随机变量分布的参数虽然我们无法直接观测到，但参数是客观确定的&lt;/li&gt;
&lt;li&gt;贝叶斯学派认为随机是主观的，不是系统固有的属性，之所以存在随机，是因为掌握的信息量不足以完全消除不确定定性，概率分布的参数不是固定不变的，而是随着观察者掌握的信息量不同而不同&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;举个抛硬币的例子，对于硬币有时正面有时反面这一随机性，频率学派会说这是由于硬币和抛硬币的人以及抛硬币所在环境组成的整个系统存在随机性，且出现正面反面的概率是确定的；而贝叶斯学派则认为，客观不存在随机性，之所以看起来随机，是因为我们掌握的信息不够，如果我们能观察到方方面面的信息，如硬币的密度分布、抛起的初速度、抛起时的形态、自身的角动量、空气的温度、湿度、空气密度、气流气压等等，那么我们理论上可以通过动力学和流体力学方程精确预测硬币落下时是哪一面，因此就不存在随机性了。但是由于我们无法掌握这些信息，所以只能认为存在随机，同时，贝叶斯学派认为，既然并不存在什么客观随机，也就不存在什么确定的概率分布的参数了，他们同时考虑所有可能的参数，也就是说，认为概率分布的参数也是服从一个分布的，但这不是因为存在客观随机，而是因为信息不够，我们只能这样认为。&lt;/p&gt;
&lt;p&gt;可能上面还是比较抽象，那么下面我们通过一个例子，来详细看看两个学派对于同一个问题是分别如何思考的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;例8：我们面前有一个赌博机，屏幕每次会随机显示一个o或一个x，但我们并不知道显示o和x的概率，但是我们知道每次显示什么是独立事件。现在经过5次观察，显示分别为xxoxo，我们应该如何预测下一次显示o还是x？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;72-频率学派与最大似然估计&quot;&gt;7.2 频率学派与最大似然估计&lt;/h2&gt;
&lt;p&gt;频率学派解决这个问题的方法是最大似然估计（Maximum likelihood estimation，以下简称MLE）。频率学派是这么思考这个问题的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;设赌博机显示o的概率为$p$，这可以看成是我们要估计的参数，同时，显示x的概率为$1-p$。&lt;/li&gt;
&lt;li&gt;将观察到的五次事件看成一个联合事件，由于是独立事件，这个联合事件发生的概率是$(1-p)(1-p)p(1-p)p=p^2(1-p)^3$。&lt;/li&gt;
&lt;li&gt;现在我们找一个$p$，让上面的概率最大，也就是我们认为最好的参数选择应该是让已观察到的事件发生的概率最大，由于连乘不好求解，于是我们取个对数（对数和原函数取最大值在同一位置）变成：$2log(p)+3log(1-p)$。&lt;/li&gt;
&lt;li&gt;为了求最大值，对$p$求导得$2/p-3/(1-p)$，令导函数等于0，解出$p=2/5$。这就是我们对$p$的估计。&lt;/li&gt;
&lt;li&gt;因此，我们认为下次显示o的概率是$2/5$，显示x的概率是$3/5$，因此预测下次出x。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下面定义最大似然估计的通用框架：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;给定iid样本集$D_n=(X_1,X_2,...,X_n)$，其中每个样本服从形式已知但参数未知的分布$P(X;\theta)$&lt;/li&gt;
&lt;li&gt;所以样本集出现的概率为$\Pi_{i=1}^nP(X_i;\theta)$，这个函数成为似然（Likelihood）&lt;/li&gt;
&lt;li&gt;我们取令似然最大的参数$\theta$作为估计参数，为了方便计算，我们通常利用对数函数与原函数在同一位置取相同最大值的的特性，将似然取对数，将连乘变成连加方便计算&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最大似然估计在实践中是经常被使用的方法，例如我们常用的交叉熵损失(Cross-entropy Loss)，也叫对数损失（Log Loss），其本质就是最大似然估计（最小化对数似然的负数，相当于最大化似然函数）。&lt;/p&gt;
&lt;h2 id=&quot;73-贝叶斯学派与贝叶斯学习&quot;&gt;7.3 贝叶斯学派与贝叶斯学习&lt;/h2&gt;
&lt;p&gt;贝叶斯学派是这么考虑这个问题的：我不认为赌博机显示o的概率$p$是一个固定的值，理论上如果我把赌博机的电路、程序以及赌博机的随机数生成算法仔细分析一遍，可以精确预测下一次显示的是o还是x。&lt;/p&gt;
&lt;p&gt;但是现在并不允许我这么做，所以我应该利用先验知识+观测结果，共同得出结论，且这个结论不应该是一个固定的$p$，而是在先验知识+观测结果提供的信息下，给出一个$p$的概率分布，且随着观测结果增加，可以更新这个分布。&lt;/p&gt;
&lt;p&gt;具体到例8，贝叶斯学派会这样解这个问题：&lt;/p&gt;
&lt;p&gt;我们猜测$p$可能是0到1之间的任意值，但是经验告诉我们赌博机没有理由偏向于任何一方，因为如果有偏向，那么赌徒可以获取一个正向的收益期望，这样长期赌场会亏本，所以我们强烈怀疑赌博机$p$的值为$0.5$，但是我们不排除任何其他可能，而是给出一个$p$的先验分布，这里我们认为$P(p)\sim Beta(10,10)$。我们先不要纠结为什么这里我们用$Beta(10,10)$作为先验分布，后面会详细讨论，这里只需知道$Beta(10,10)$表示我们认为$p$最可能的取值为$0.5$，且越接近边缘（0或1），越不可能。下图是先验分布P(p)的概率密度函数图形：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../uploads/pictures/statistical-learning-theory/slt05.png&quot; alt=&quot;slt05&quot;&gt;&lt;/p&gt;
&lt;p&gt;根据观测到的”xxoxo“，我们更新先验分布到后验分布，更新公式是贝叶斯公式：
$$
P(p|D_n)=\frac{P(D_n|p)P(p)}{P(D_n)}
$$
如果按上述公式算起来，还挺麻烦的。但是由于已经知道，$Beta(\alpha,\beta)$分布在这个场景下，有一个特别简单的更新公式：&lt;/p&gt;
&lt;p&gt;$$
P(p|D_n)\sim Beta(\alpha+\text{出现o的次数},\beta+\text{出现x的次数})=Beta(12,13)
$$&lt;/p&gt;
&lt;p&gt;之所以会有上述简单更新公式，是因为$Beta$分布是我们这个问题的共轭先验分布，这里对这个话题先不展开。&lt;/p&gt;
&lt;p&gt;于是更新后后验分布的图形如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../uploads/pictures/statistical-learning-theory/slt06.png&quot; alt=&quot;slt06&quot;&gt;&lt;/p&gt;
&lt;p&gt;可以看到这个图形相比先验分布，这个图形更”瘦“了，另外向左侧略有偏斜（肉眼可能看不出来），这表示，虽然我们对$p$的倾向略有倾斜，但是，总体却更笃定它应该集中在0.5附近。&lt;/p&gt;
&lt;p&gt;此时我们可以用$E(p)$作为$p$的估计：
$$
E(Beta(12,13))=\frac{12}{12+13}=0.48
$$
因此我们认为下次出o的概率为0.48，出x的概率为0.52。于是选择$x$。&lt;/p&gt;
&lt;p&gt;以上过程叫做贝叶斯学习。&lt;/p&gt;
&lt;h2 id=&quot;74-对两种方法的比较&quot;&gt;7.4 对两种方法的比较&lt;/h2&gt;
&lt;p&gt;首先简单总结一下上面两种方法的核心思想：&lt;/p&gt;
&lt;p&gt;最大似然估计的估计方法是：
$$
\hat{\theta}=\mathop{\arg\max}_\theta{P(D_n|\theta)}
$$
也就是最大化似然函数。&lt;/p&gt;
&lt;p&gt;贝叶斯学习的估计方法是：
$$
\hat{\theta}=\mathop{\arg\max}_\theta P(\theta|D_n)\propto P(D_n|\theta)P(\theta)
$$&lt;/p&gt;
&lt;p&gt;也就是最大化后验概率。&lt;/p&gt;
&lt;p&gt;这里不能直接说孰优孰劣，但是可以看成两者有一定的区别：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;从实现角度来看，MLE更简单，只要求解似然函数的最大值，而贝叶斯学习需要计算后验概率分布，如果是做判别，则后验概率分布正比与先验概率分布和似然的乘积，计算较为复杂&lt;/li&gt;
&lt;li&gt;贝叶斯学习中，为了计算方便，需要针对不同模型，选择合适的共轭先验分布，所谓共轭先验分布就是先验分布和后验分布具有相同的分布函数，例如上面问题中，先验分布和后验分布都是$Beta$分布&lt;/li&gt;
&lt;li&gt;MLE只考虑样本集，样本集完全决定了参数估计结果；而贝叶斯学习通过先验分布，可以将一定的先验知识”编码“进去，从而在某些现实中更贴合。从上面的例子可以看出，虽然两者都预测$p$的值小于0.5，但是MLE直接用样本集频率认为$p$是0.4，而同样的样本，贝叶斯学习认为$p$是0.48，这是因为我们在贝叶斯学习中使用的先验分布具有一定的偏执，可以防止少数样本的偶然结果得出不合常理的结论。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;关于上面第3点，这里可以再举一个例子辅助理解。假设一个足球队来了一个新的球员，教练想估计他踢点球的成功率，踢了三次，都进了，根据MLE，应该认为他点球成功率100%，这显然不合常理，因为地球上没有一个球员能保证100%的点球成功率。那么教练可以用经验知识，先确定一个这名新球员点球成功率的先验分布，然后根据观察，更新这个分布，这样就避免了上面的情况。而且根据不同的经验，可以设置不同的先验分布参数，这既可以决定先验分布的强弱（先验分布越强，则需要更多的样本才能撼动这个分布）。&lt;/p&gt;
&lt;h1 id=&quot;8-总结&quot;&gt;8 总结&lt;/h1&gt;
&lt;p&gt;最后我们总结一下这篇文章的主要内容。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一节我们从数学角度定义了统计学习的目标：从假设空间中找出风险最小的假设函数，并导出了如果联合分布$P(X,Y)$已知，回归和二分类问题的通用最优解，并给出了统计学习的严格定义。&lt;/li&gt;
&lt;li&gt;第二节讨论了在无法知道$P(X,Y)$的情况下，统计学习的一致性问题。我们首先讨论了统计学习的两种误差：偏差和方差。同时从假设空间大小的角度，说明了两者很难同时进行优化，最后给出了三种一致性的严格定义。&lt;/li&gt;
&lt;li&gt;第三节讨论了一种全局一致算法kNN，并讨论了kNN全局一致的条件及现实中遇到的限制。&lt;/li&gt;
&lt;li&gt;第四节讨论了现实中经常使用的学习准则：经验风险最小化。并通过一个反例证明了如果假设空间不加限制，则ERM不一致。接着，我们导出了ERM一致的条件：假设空间一致收敛。&lt;/li&gt;
&lt;li&gt;第五节接着第四节的内容，详细推导出假设空间一致收敛的条件，给出了Shattering Coefficient和VC维的定义，并基于两者给出了ERM一致的充分必要条件，在这一节末尾简单讨论了贝叶斯一致的条件。&lt;/li&gt;
&lt;li&gt;第六节讨论了SLT中最重要的定理：天下没有免费的午餐定理。这个定理给出了SLT中的重要推论：如果不对$P(X,Y)$最任何假设，则在任意大的有限样本集下，都不能保证统计学习能学到任何东西。所以统计学习必须和业务经验结合才有意义。&lt;/li&gt;
&lt;li&gt;第七节讨论了限定$P(X,Y)$分布形式下的参数估计方法，探讨了频率学派和贝叶斯学派观念的差异，并给出了两个学派解决参数估计问题的主要思路：MLE和贝叶斯学习。最后对两种方法进行了比较。&lt;/li&gt;
&lt;/ul&gt;
</description> 
        </item> 
        
        <item> 
            <title>对论文《A Mathematical Theory of Communication》的简要解读</title> 
            <link>http://blog.codinglabs.org/articles/simple-explain-of-amtoc.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link> 
            <guid>http://blog.codinglabs.org/articles/simple-explain-of-amtoc.html</guid> 
            <author>ericzhang.buaa@gmail.com 张洋</author> 
            <pubDate>Wed, 31 May 2017 00:00:00 +0800</pubDate> 
            <description>&lt;p&gt;香农在1948年发表了一篇著名的论文&lt;a href=&quot;http://math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf&quot;&gt;A Mathematical Theory of Communication&lt;/a&gt;，作为现代信息论的奠基之作，不管是从理论角度还是对人类实际生活的贡献，再怎么强调这篇论文的重要性都不过分。虽然之前对信息论已经有所了解，但是为了向信息论鼻祖致敬，最近还是拜读了这篇论文。这篇论文自成体系，可以说是字字珠玑，读完后对整个信息论的来龙去脉有了更加深入的了解。其实这篇论文主要就是要解决如何用数学方式去度量信息的价值，虽然核心思想及方法非常简单明了，但是由于是一篇数学论文，其中对”价值“并没有进行直观描述，再加上掺杂了一些略微复杂的数学公式，所以有可能阅读起来会略有困难。我写这篇文章就是想通过一个直观的类比（通过一个猜硬币游戏），并把论文中抽象的“价值”直接具象化为“金钱”，以此帮助读者更容易理解论文要阐述的关键点，从而更好的阅读这篇论文。&lt;/p&gt;
&lt;h1 id=&quot;1-衡量信息价值&quot;&gt;1 衡量信息价值&lt;/h1&gt;
&lt;h2 id=&quot;11-猜硬币游戏&quot;&gt;1.1 猜硬币游戏&lt;/h2&gt;
&lt;p&gt;正文开篇需要再强调一遍，这篇论文的核心就是&lt;strong&gt;提出一种在数学上量化信息价值的方法&lt;/strong&gt;，整个论文的内容基本都是为这个主题服务的，因此理解了这个度量方法，也就掌握了理解这篇论文的关键。而这也是这篇论文最开辟性的地方，在香农之前，没有人能明确使用数学方法量化信息这一概念。&lt;/p&gt;
&lt;p&gt;为了直观理解这一方法，先看一个简单的猜硬币游戏：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;猜硬币游戏规则：一枚硬币被连续掷出，每次掷硬币正反面概率各为1/2，每次掷硬币事件相互独立。玩家可以猜任意次结果，猜对赢得1元，猜错输掉1元。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;很明显，如果没有其他附加信息，这个游戏是一个&lt;strong&gt;期望为0&lt;/strong&gt;的游戏，即不管是猜多少次，总盈利的期望总是0。&lt;/p&gt;
&lt;h2 id=&quot;12-单个符号的价值&quot;&gt;1.2 单个符号的价值&lt;/h2&gt;
&lt;p&gt;现在考虑这样一种情况，有一个人可以偷窥到硬币掷完后的状态，并且每次看到时，可以向你传递信息，但是这个信息只能是&lt;strong&gt;一个有两种状态的符号&lt;/strong&gt;，为了方便我们姑且认为这个符号可以是0或1，那么请问每一个这样的符号值多少钱？&lt;/p&gt;
&lt;p&gt;很显然，我们可以和信息传递者约定，0表示正面，1表示反面，这样每一个符号可以稳定帮我们赚到1元钱，所以我们可以说每一个这样的符号价值是1元。&lt;/p&gt;
&lt;p&gt;现在考虑另一种情况，如果现在&lt;strong&gt;允许每个符号有10种状态&lt;/strong&gt;（姑且认为可以是阿拉伯数字0-9），那么同样一个符号，价值是多少钱？&lt;/p&gt;
&lt;p&gt;此时为了最大发挥这个符号的价值，我们可以这样做：不再是掷一次硬币传递一个符号，而是掷N次后再传递一个符号，而这个符号必须能准确表示这N次投掷的状态。由于3次投掷有8种状态，而4次投掷有16种状态，所以这里的N最多只能是3。我们可以这样约定如何传输这个符号：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;正正正 - 0，正正反 - 1，正反正 - 2，正反反 - 3，反正正 - 4，反正反 - 5， 反反正 - 6，反反反 - 7&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;还有两个状态8和9没用，先不管了，照这种方式，一个符号至少可以稳定帮我们赚3元。我们看到，同样是一个符号，10个状态比两个状态价值高很多，所以我们得到了第一个重要的结论：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;定性结论1：在其它条件不变的情况下，单个信息符号可表示状态越多，价值越大。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这里我们先给出定性结论，如何用数学定量的方式度量这个符号的价值，后面再说。&lt;/p&gt;
&lt;h2 id=&quot;13-不确定性与符号价值&quot;&gt;1.3 不确定性与符号价值&lt;/h2&gt;
&lt;p&gt;上面我们知道，在这个游戏中，一个二状态信息符号值一元钱，现在我们变更以下游戏条件，硬币正反面不再是等概率，而是正面概率为$p$，反面概率为$1-p$，那么此时这个符号还值1元吗？我们首先考虑一个极端情况：$p=1$，此时硬币永远是正面，显然此时我们根本不需要这个符号，只要一直猜正面就能每次稳赚1元钱，所以此时可以说这个信息毫无价值；反之如果$p=0$也一样，我们一直猜反面就好了。&lt;/p&gt;
&lt;p&gt;那么，如果$p=0.8$，会怎么样？此时我们知道，即使没有这个符号信息，我们只要每次猜正面，猜对的概率也有80%，此时每一轮游戏期望收益为：$E(x)=0.8\times1+0.2\times(-1)=0.6$。&lt;/p&gt;
&lt;p&gt;即是说，每一次猜正面，本身就可以有0.6元的收益，因此此时一个符号附加的价值是$1-0.6=0.4$。&lt;/p&gt;
&lt;p&gt;由上分析，我们得到第二个定性结论：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;定性结论2：在其它条件不变的情况下，单个符号所面对的情况越随机，价值越大。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;或者换一种说法：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;定性结论2*：一个信息符号的价值取决于其消除的不确定性，消除的不确定性越高，价值越大。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;最后我们得出一个总的定性结论：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一个信息符号的价值取决于符号可表示状态数及可以消除的不确定性。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;所以，如果要量化符号价值，只需量化“可表示状态数”及“不确定性”即可。&lt;/p&gt;
&lt;h2 id=&quot;14-可表示状态数的量化&quot;&gt;1.4 可表示状态数的量化&lt;/h2&gt;
&lt;p&gt;还是以上面二状态和十状态符号为例，上面看到后者的价值至少是前者的三倍，那么这个事情如何数学化呢。首先我们明显可以看到，在离散情况下，二状态符号是传递信息的最小单位，只有一个状态的符号不能传递信息。所以，我们可以规定二状态符号是信息传递的单位符号，价值记为1。&lt;/p&gt;
&lt;p&gt;那么这个问题就变成了&lt;strong&gt;一个n状态符号（n &gt; 2）所表示的状态需要几个二状态符号表示&lt;/strong&gt;？由于m个二状态符号能表示$2^m$种状态，所以问题变成了求解$n=2^m$，得$m=log_2n$，因此我们得到第一个定量结果：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;二状态符号是传递信息的最小单位，设为价值1，n状态符号的价值为$log_2n$。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;由此可以知道，上文中十状态符号的价值是$log_210\approx3.32$，即3.32元（在正反概率皆为1/2时）。但是由于受到离散化限制，需要取个整，因此那个符号最大收益就是3元。&lt;/p&gt;
&lt;h2 id=&quot;15-不确定性的量化&quot;&gt;1.5 不确定性的量化&lt;/h2&gt;
&lt;p&gt;相比于可表示状态数，不确定性的量化稍微困难一些。具体来说，我们是要做这么一件事：对于一个有N种结果的随机变量X，在概率分布函数$P(X)$已知的情况下，寻找一个泛函$H(X)$（不要纠结于这个名词，这里可以简单理解为以函数为变量的函数），使得$H(X)$满足如下条件：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如果X是确定性事件（即X的结果是固定的），则$H(X)=0$&lt;/li&gt;
&lt;li&gt;$P(X)$越随机，$H(P)​$越大&lt;/li&gt;
&lt;li&gt;$H(X)$最大为1，此时随机变量随机性最大&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在论文中，香农给出了这样一个函数：
$$
H(X)=-\sum_{i=1}^Np_i(X)log(p_i(X))
$$
这就是大名鼎鼎的&lt;strong&gt;信息熵&lt;/strong&gt;，今天普遍用来度量随机事件的不确定性。&lt;/p&gt;
&lt;p&gt;回到上面的例子，可以看到$p=0$或$p=1$时，信息熵均为0，因此此时信息符号没有消除任何熵，所以没有价值。而当正反概率各位1/2时，信息熵为：$-2\times0.5\times log(0.5)=1.0$，因此一个二状态符号消除了1.0的熵（同时很容易证明，对应这个游戏，此时熵最大）。而对于$p=0.8$，信息熵为$-0.8log(0.8)-0.2log(0.2)\approx0.7219$，所以一个二状态符号消除了约0.72的不确定性，因此价值没有前者高。&lt;/p&gt;
&lt;p&gt;综上，我们可以得到如下结论：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;信息传递中，一个信息符号的价值，取决于可表示状态数及可以消除的系统不确定性。其中可表示状态数以二状态符号为单位1，n状态符号价值是二状态符号的$log_2n$倍，不确定性由信息熵度量，消除的不确定性越高则价值越高。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;以上是这篇论文要传递的最核心的内容，其余部分基本都是基于这点展开的。下面利用上文总结的点，对论文的一些关键内容做一个简要的解读。&lt;/p&gt;
&lt;h1 id=&quot;2-对论文关键点的解读&quot;&gt;2 对论文关键点的解读&lt;/h1&gt;
&lt;p&gt;整篇《A Mathematical Theory of Communication》分为两大部分，前半部分是离散信号通信相关的数学理论，后半部分是连续信号通信的数学理论。其中连续信号是将信号看做离散信号的极限情况进行分析，用到了较多的数学技巧，所以相对艰涩，不过其目的可以看做是将离散信号的各种分析推广到连续的情况，因此这里只解读离散部分，理解了离散部分，连续信号部分可以类比理解。&lt;/p&gt;
&lt;h2 id=&quot;21-无噪信道容量（capacity）的数学表示&quot;&gt;2.1 无噪信道容量（capacity）的数学表示&lt;/h2&gt;
&lt;p&gt;论文的第一部分是对无噪信道容量的数学化。首先论文对通信的定义是&lt;strong&gt;接收端对发送端符号流的还原&lt;/strong&gt;，所谓无噪信道就是接收端可以准确无误重现发送端符号流的信道，也称作理想信道。&lt;/p&gt;
&lt;p&gt;对于无噪信道，信道容量即是&lt;strong&gt;单位时间内传输的符号流所能表示的状态数的上限的对数&lt;/strong&gt;。这里我们以1秒为一个单位时间。&lt;/p&gt;
&lt;p&gt;举个几个例子：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一个信道一秒传输一个二状态符号，由于一个二状态符号只能表示两种状态，所以一秒传递的符号最多表示两个状态，$log2=1$（后面如果底数为2均省略），信道容量为1。&lt;/li&gt;
&lt;li&gt;一个信道一秒传输一个十状态符号，$log10\approx3.32$，信道容量为3.32。&lt;/li&gt;
&lt;li&gt;一个信道一秒传递十个二进制状态符号，十个二进制状态符号可以表示1024种状态，$log1024=10$，所以信道容量为10。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以看到，这里信道容量的量化和上文中对可表示状态数的量化是一回事，只是把一个符号可表示状态数换成了单位时间内传输的符号可表示状态数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;信道容量定义了一个信道单位时间内所能传输的最大信息价值&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;注意我们上面的计算方式有一定局限，因为我们假设了符号在不同状态下所占用时间一致，但实际中可能并不是，例如&lt;a href=&quot;https://en.wikipedia.org/wiki/Morse_code&quot;&gt;摩尔斯电码&lt;/a&gt;中，“划”比“点”占用时间要长。论文中给出了计算信道容量的一个通用数学公式：
$$
C=\lim_{T-&gt;\infty}\frac{logN(T)}{T}
$$
其中$T$是时间，$N(T)$表示在$T$时间内传输的符号流可以表示的最大状态数。&lt;/p&gt;
&lt;p&gt;例如对上面例子中第一个，带入公式可得$C=\lim_{T-&gt;\infty}\frac{Tlog2}{T}=log2=1$ ，对第三个$C=\lim_{T-&gt;\infty}\frac{Tlog1024}{T}=10log2=10$。&lt;/p&gt;
&lt;p&gt;当符号的不同状态占用时间不同时，需要求解一个递推方程。&lt;/p&gt;
&lt;p&gt;假设我们一个符号有n种状态，占用时间分别为$t_1,t_2,...,t_n$，由定义可以得到如下递推式：
$$
N(T)=N(T-t_1)+N(T-t_2)+...+N(T-t_n)
$$
根据数学知识可以知道这个式子的解是
$$
C=logX_0
$$
其中$X_0$是特征方程$X^{-t_1}+X^{-t_2}+...+X^{-t_n}=1$的最大实根。&lt;/p&gt;
&lt;p&gt;另外论文中还给出了一种通过把通信看成状态机的视角，然后求行列式方程求解信道容量的方法。由于目的一致，这里不再赘述。&lt;/p&gt;
&lt;h2 id=&quot;22-信源的数学表示&quot;&gt;2.2 信源的数学表示&lt;/h2&gt;
&lt;p&gt;上文的信道容量表示的是一个信道理论上能在单位时间内传输的最大信息价值，要达到这个上限，还需要信息编码本身价值最大化。香农接着用很大篇幅来对信息源及信息流编码的价值进行数学化。&lt;/p&gt;
&lt;p&gt;回顾一下之前对熵的定义，可以知道熵可以评价一个随机分布函数的不确定性。而一段符号流，也可以看做背后服从一个联合概率分布，这个联合概率分布可以看做是信源的既有特征。因此熵可以用于评价信源的不确定性，论文告诉我们熵越大的信源信息价值越大。&lt;/p&gt;
&lt;p&gt;且慢！上面明明说过，信息符号的价值取决于消除的不确定性，这和信源的不确定性有什么关系？背后的秘密在于，&lt;strong&gt;当所面对的情况不是完全随机，即熵不是1.0时，我们可以通过重新编码信源，提高符号价值，从而逼近信道最大价值&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;还是以上面掷硬币举例，假设正面概率0.8，反面概率0.2的情况。如果我们传输二状态符号，0表示正面，1表示反面，可以知道一个符号值1元。&lt;/p&gt;
&lt;p&gt;那么我们有没有办法让符号更值钱？因为理论上一个二状态符号可以消除1.0的熵（在正反各0.5的情况下），但这里熵只有0.72，所以我们貌似亏了。有一种思路是这样的：我们不再一个一个编码，而是对两次掷硬币成组编码。因为正面出现概率远大于反面，所以两次掷硬币四种组合的概率也不同，我们用较短的编码表示较大概率出现的情况，用较长的编码表示较小概率的情况，感觉上可以提高每个符号的价值。&lt;/p&gt;
&lt;p&gt;具体我们可以这么做：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;正正（0.64） - 0，正反（0.16） - 10，反正（0.16） - 110，反反（0.04） - 111&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;括号中为概率。注意，以上编码方式可以保证在解析信息流时不会出现歧义。可以算一下，这种编码方式，平均表示两次掷硬币所需的平均符号数量是$0.64\times1+0.16\times2+0.16\times3+0.04\times3=1.56$。因此我们可以平均用1.56个二状态符号赚2元，平均一个符号现在价值1.28元。&lt;strong&gt;我们通过重新编码把一个符号的价值提高了！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;再来算一下这种编码下信源的熵，此时信源出现0的概率是$0.64+0.16\times0.5+0.16\times0.33=0.7728$，出现1的概率是$0.16\times0.5+0.16\times0.67+0.04=0.2272$，信源的熵$-0.7728log(0.7728)-0.2272log(0.2272)=0.773$，比原始信息的0.7219提高了。&lt;/p&gt;
&lt;p&gt;所以我们得到了如下结论：&lt;strong&gt;如果所要传递的信息所服从的联合概率分布的熵不是最大，则有办法通过对信息重新编码，提高信源的熵，从而提高信息符号每个符号的价值，上限是编码使得信源中每个符号出现的概率相等，此时信源的熵为1.0，单个符号价值最大&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;换个角度看，我们上面用平均1.56个二状态符号准确重现了之前两个二状态符号（正反两种情况，所以一次掷硬币相当于一个二状态符号）的信息，等于把用于表示同等信息的符号流长度变短了，这就是数据压缩的原理。也就是说，&lt;strong&gt;如果一段符号的联合概率分布的熵不是最大（也称作存在冗余），则总有办法通过重新编码，使得用更短的符号流表示同等信息，此时单个符号价值变大，重新编码后的信息流熵也变大&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&quot;23-自然语言熵的近似估计&quot;&gt;2.3 自然语言熵的近似估计&lt;/h2&gt;
&lt;p&gt;上面两节可以说就是香农在论文中接下来一大部分所要传递的内容。不过论文中，香农还给出了自然语言中熵的近似估计方式，我们来看一下。&lt;/p&gt;
&lt;p&gt;首先我们知道，如果能得到一种语言的联合概率分布，那么就可以直接算出熵，而对自然语言这是不可能的。所以我们只能以某种方式去逼近自然语言真实的联合概率分布。&lt;/p&gt;
&lt;p&gt;以英文为例，为了简单我们假设英文只由26个小写英文字母组成，不考虑大写、分隔符及标点。那么，由弱及强可以有如下逼近方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;每个位置都是独立的平均分布，即每个位置每个符号以1/26的等概率出现&lt;/li&gt;
&lt;li&gt;每个位置都是独立的，但出现哪个字符的概率按照对真实英文的统计频率出现，例如e出现的概率大于x。&lt;/li&gt;
&lt;li&gt;每个位置出现各个字符的概率，取决于前一个字符及其条件概率&lt;/li&gt;
&lt;li&gt;每个位置出现各个字符的概率，取决于前两个字符及其条件概率&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这个列表可以无限延伸下去，其中越后面的逼近方式越接近真实的联合概率分布。这种方式相当于把自然语言看成一个&lt;a href=&quot;https://en.wikipedia.org/wiki/Markov_chain&quot;&gt;马尔科夫过程&lt;/a&gt;，这是随机过程和自然语言处理中一个非常重要的模型，香农的论文也使用了这个模型来表述，鉴于关于马尔科夫过程的资料非常丰富，这里不再赘述。&lt;/p&gt;
&lt;p&gt;需要注意的是，不同近似模型下算出的熵可能非常不一样，例如01010101……这种语言，即0和1交替出现，如果用近似2，则算出熵为1.0，即完全随机，但如果用近似3，则熵为0，即完全没有信息量。因此如果近似过程如果不够强，可能得出非常荒谬的结论。&lt;/p&gt;
&lt;p&gt;在经过一系列探讨后，香农给出并证明了一个非常重要的结论：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;设一个语言有n个字符，每个字符出现的概率为$p_i$，N是一个正整数，令$p=p_1^{p_1N}p=p_2^{p_2N}...p=p_n^{p_nN}$，当N足够大时，$\frac{logp^{-1}}{N}$可以以任意精度逼近真实的熵。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;原文使用了极限语言描述，更加严格，我这里给出的是更口语化的描述。&lt;/p&gt;
&lt;p&gt;上面给出了一种近似计算自然语言熵的方式，但是并没有定量给出在精度确定下N需要多大。&lt;/p&gt;
&lt;h2 id=&quot;24-有噪信道的数学表示&quot;&gt;2.4 有噪信道的数学表示&lt;/h2&gt;
&lt;p&gt;上面考虑的所有情况都假设信道是完全可靠的，即接收端完美复现发送端的符号流。但现实中信道往往都是会出错的，即是一个有噪信道。香农在离散信息数学表示的最后部分讨论了有噪信道下通信的数学表示。&lt;/p&gt;
&lt;p&gt;回到掷硬币的例子，假设我们用二状态符号传递信息，正反面概率各位0.5，已经知道在使用无噪信道时，每个符号值1元。现在我们假设这个信道并不是完美的，传输每个符号时，都有1%的可能性出错，即0变成1或1变成0，此时每个符号值多少钱？显然，如果符号出错，则我们会赔掉1块钱。也就是从统计意义上说，平均每玩一次，收益期望变为$1\times0.99+(-1)\times0.01=0.98$，所以现在每个符号值0.98元。&lt;/p&gt;
&lt;p&gt;可以看到，&lt;strong&gt;噪声的存在使得信息符号的价值变低了&lt;/strong&gt;。那么如何量化这个种噪声导致的损失呢？&lt;/p&gt;
&lt;p&gt;直觉上，当我们接收到一个字符时，对原始字符越不确定，这个损失越大。香农在论文中引入了条件熵来量化这个损失。条件熵定义如下：如果接收到字符Y，则原字符X的条件概率分布函数的熵即为X对Y的条件熵。即：
$$
H_Y(X)=-\sum_{i,j} P(X=i,Y=j)log(P(X=i|Y=j))
$$
在这个例子中，条件熵为$-0.5\times0.99\times log(0.99)-0.5\times0.01\times log(0.01)-0.5\times0.01\times log(0.99)-0.5\times0.01\times log(0.01)\approx 0.08$&lt;/p&gt;
&lt;p&gt;，这就是上述有噪信道单个字符损失的量化。&lt;/p&gt;
&lt;p&gt;于是，对于有噪信道，其容量上限是：
$$
C=H(X)-H_Y(X)
$$
那么有噪信道既然存在传输错误，还能用吗？当然是可以的，毕竟我们现实中用的信道都是有噪信道。在接下来，香农在论文中证明了一个非常让人吃惊的反直觉结论：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如果不考虑传输速率，总可以找到一种编码方式使得有噪信道传输信息的错误概率任意小。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;不过论文中只从数学上证明了存在这样的编码方式，但并没有给出如何构造这样的编码。但是现实中我们经常用到的如奇偶校验码就是用来对抗有噪信道错误的方式。当然，错误概率降的越低，传输速率也会越慢。&lt;/p&gt;
&lt;p&gt;原文中在这里给出了离散信道容量的基本原理，这个原理非常重要：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;设离散信道容量为C，信源每秒发送符号的熵为H，如果$H\le C$，则一定存在某种编码方式，使得以任意小的出错概率传递信息，如果$H\gt C$，则无法通过任何编码方式将出错概率缩减至任意小。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;上面这个结论可以说奠定了现代通信理论的基础。&lt;/p&gt;
&lt;p&gt;论文关于离散通信理论的讨论到此为止了，后面部分是将离散情况下各种讨论推广到连续信号条件下。整体上用到的数学技巧较多，但本质要表述的东西和上面是类似的，我这里就不再分析了，有兴趣的可以自行阅读。&lt;/p&gt;
&lt;h1 id=&quot;3-总结&quot;&gt;3 总结&lt;/h1&gt;
&lt;p&gt;下面总结一下本文的重要结论：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;信息传递中，一个信息符号的价值，取决于可表示状态数及可以消除的系统不确定性。其中可表示状态数以二状态符号为单位1，n状态符号价值是二状态符号的$log_2n$倍，不确定性由信息熵度量，消除的不确定性越高则价值越高&lt;/li&gt;
&lt;li&gt;信道容量定义了一个信道单位时间内所能传输的最大信息价值&lt;/li&gt;
&lt;li&gt;如果一段符号的联合概率分布的熵不是最大（也称作存在冗余），则总有办法通过重新编码，使得用更短的符号流表示同等信息，此时单个符号价值变大，重新编码后的信息流熵也变大&lt;/li&gt;
&lt;li&gt;如果不考虑传输速率，总可以找到一种编码方式使得有噪信道传输信息的错误概率任意小&lt;/li&gt;
&lt;li&gt;设离散信道容量为C，信源每秒发送符号的熵为H，如果$H\le C$，则一定存在某种编码方式，使得以任意小的出错概率传递信息，如果$H\gt C$，则无法通过任何编码方式将出错概率缩减至任意小&lt;/li&gt;
&lt;/ol&gt;
</description> 
        </item> 
        
        <item> 
            <title>如何实现一个malloc</title> 
            <link>http://blog.codinglabs.org/articles/a-malloc-tutorial.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link> 
            <guid>http://blog.codinglabs.org/articles/a-malloc-tutorial.html</guid> 
            <author>ericzhang.buaa@gmail.com 张洋</author> 
            <pubDate>Tue, 19 Aug 2014 00:00:00 +0800</pubDate> 
            <description>&lt;p&gt;任何一个用过或学过C的人对malloc都不会陌生。大家都知道malloc可以分配一段连续的内存空间，并且在不再使用时可以通过free释放掉。但是，许多程序员对malloc背后的事情并不熟悉，许多人甚至把malloc当做操作系统所提供的系统调用或C的关键字。实际上，malloc只是C的标准库中提供的一个普通函数，而且实现malloc的&lt;strong&gt;基本&lt;/strong&gt;思想并不复杂，任何一个对C和操作系统有些许了解的程序员都可以很容易理解。&lt;/p&gt;
&lt;p&gt;这篇文章通过实现一个简单的malloc来描述malloc背后的机制。当然与现有C的标准库实现（例如glibc）相比，我们实现的malloc并不是特别高效，但是这个实现比目前真实的malloc实现要简单很多，因此易于理解。重要的是，这个实现和真实实现在基本原理上是一致的。&lt;/p&gt;
&lt;p&gt;这篇文章将首先介绍一些所需的基本知识，如操作系统对进程的内存管理以及相关的系统调用，然后逐步实现一个简单的malloc。为了简单起见，这篇文章将只考虑x86_64体系结构，操作系统为Linux。&lt;/p&gt;
&lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-%E4%BB%80%E4%B9%88%E6%98%AFmalloc&quot;&gt;1 什么是malloc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86&quot;&gt;2 预备知识&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#21-linux%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86&quot;&gt;2.1 Linux内存管理&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#211-%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E5%9C%B0%E5%9D%80%E4%B8%8E%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%E5%9C%B0%E5%9D%80&quot;&gt;2.1.1 虚拟内存地址与物理内存地址&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#212-%E9%A1%B5%E4%B8%8E%E5%9C%B0%E5%9D%80%E6%9E%84%E6%88%90&quot;&gt;2.1.2 页与地址构成&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#213-%E5%86%85%E5%AD%98%E9%A1%B5%E4%B8%8E%E7%A3%81%E7%9B%98%E9%A1%B5&quot;&gt;2.1.3 内存页与磁盘页&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#22-linux%E8%BF%9B%E7%A8%8B%E7%BA%A7%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86&quot;&gt;2.2 Linux进程级内存管理&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#221-%E5%86%85%E5%AD%98%E6%8E%92%E5%B8%83&quot;&gt;2.2.1 内存排布&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#222-heap%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B&quot;&gt;2.2.2 Heap内存模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#223-brk%E4%B8%8Esbrk&quot;&gt;2.2.3 brk与sbrk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#224-%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6%E4%B8%8Erlimit&quot;&gt;2.2.4 资源限制与rlimit&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#3-%E5%AE%9E%E7%8E%B0malloc&quot;&gt;3 实现malloc&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#31-%E7%8E%A9%E5%85%B7%E5%AE%9E%E7%8E%B0&quot;&gt;3.1 玩具实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#32-%E6%AD%A3%E5%BC%8F%E5%AE%9E%E7%8E%B0&quot;&gt;3.2 正式实现&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#321-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84&quot;&gt;3.2.1 数据结构&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#322-%E5%AF%BB%E6%89%BE%E5%90%88%E9%80%82%E7%9A%84block&quot;&gt;3.2.2 寻找合适的block&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#323-%E5%BC%80%E8%BE%9F%E6%96%B0%E7%9A%84block&quot;&gt;3.2.3 开辟新的block&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#324-%E5%88%86%E8%A3%82block&quot;&gt;3.2.4 分裂block&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#325-malloc%E7%9A%84%E5%AE%9E%E7%8E%B0&quot;&gt;3.2.5 malloc的实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#326-calloc%E7%9A%84%E5%AE%9E%E7%8E%B0&quot;&gt;3.2.6 calloc的实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#327-free%E7%9A%84%E5%AE%9E%E7%8E%B0&quot;&gt;3.2.7 free的实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#328-realloc%E7%9A%84%E5%AE%9E%E7%8E%B0&quot;&gt;3.2.8 realloc的实现&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#33-%E9%81%97%E7%95%99%E9%97%AE%E9%A2%98%E5%92%8C%E4%BC%98%E5%8C%96&quot;&gt;3.3 遗留问题和优化&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#4-%E5%85%B6%E5%AE%83%E5%8F%82%E8%80%83&quot;&gt;4 其它参考&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- toc stop --&gt;


&lt;h1 id=&quot;1-什么是malloc&quot;&gt;1 什么是malloc&lt;/h1&gt;
&lt;p&gt;在实现malloc之前，先要相对正式地对malloc做一个定义。&lt;/p&gt;
&lt;p&gt;根据标准C库函数的定义，malloc具有如下原型：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-c&quot;&gt;void* malloc(size_t size);&lt;/pre&gt;
&lt;p&gt;这个函数要实现的功能是在系统中分配一段连续的可用的内存，具体有如下要求：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;malloc分配的内存大小&lt;strong&gt;至少&lt;/strong&gt;为size参数所指定的字节数&lt;/li&gt;
&lt;li&gt;malloc的返回值是一个指针，指向一段可用内存的起始地址&lt;/li&gt;
&lt;li&gt;多次调用malloc所分配的地址不能有重叠部分，除非某次malloc所分配的地址被释放掉&lt;/li&gt;
&lt;li&gt;malloc应该尽快完成内存分配并返回（不能使用&lt;a href=&quot;http://en.wikipedia.org/wiki/NP-hard&quot;&gt;NP-hard&lt;/a&gt;的内存分配算法）&lt;/li&gt;
&lt;li&gt;实现malloc时应同时实现内存大小调整和内存释放函数（即realloc和free）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于malloc更多的说明可以在命令行中键入以下命令查看：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;man malloc&lt;/pre&gt;
&lt;h1 id=&quot;2-预备知识&quot;&gt;2 预备知识&lt;/h1&gt;
&lt;p&gt;在实现malloc之前，需要先解释一些Linux系统内存相关的知识。&lt;/p&gt;
&lt;h2 id=&quot;21-linux内存管理&quot;&gt;2.1 Linux内存管理&lt;/h2&gt;
&lt;h3 id=&quot;211-虚拟内存地址与物理内存地址&quot;&gt;2.1.1 虚拟内存地址与物理内存地址&lt;/h3&gt;
&lt;p&gt;为了简单，现代操作系统在处理内存地址时，普遍采用虚拟内存地址技术。即在汇编程序（或机器语言）层面，当涉及内存地址时，都是使用虚拟内存地址。采用这种技术时，每个进程仿佛自己独享一片$2^N$字节的内存，其中$N$是机器位数。例如在64位CPU和64位操作系统下，每个进程的虚拟地址空间为$2^{64}$Byte。&lt;/p&gt;
&lt;p&gt;这种虚拟地址空间的作用主要是简化程序的编写及方便操作系统对进程间内存的隔离管理，真实中的进程不太可能（也用不到）如此大的内存空间，实际能用到的内存取决于物理内存大小。&lt;/p&gt;
&lt;p&gt;由于在机器语言层面都是采用虚拟地址，当实际的机器码程序涉及到内存操作时，需要根据当前进程运行的实际上下文将虚拟地址转换为物理内存地址，才能实现对真实内存数据的操作。这个转换一般由一个叫&lt;a href=&quot;http://en.wikipedia.org/wiki/Memory_management_unit&quot;&gt;MMU&lt;/a&gt;（Memory Management Unit）的硬件完成。&lt;/p&gt;
&lt;h3 id=&quot;212-页与地址构成&quot;&gt;2.1.2 页与地址构成&lt;/h3&gt;
&lt;p&gt;在现代操作系统中，不论是虚拟内存还是物理内存，都不是以字节为单位进行管理的，而是以页（Page）为单位。一个内存页是一段固定大小的连续内存地址的总称，具体到Linux中，典型的内存页大小为4096Byte（4K）。&lt;/p&gt;
&lt;p&gt;所以内存地址可以分为页号和页内偏移量。下面以64位机器，4G物理内存，4K页大小为例，虚拟内存地址和物理内存地址的组成如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://blog-codinglabs-org.qiniudn.com/image/a-malloc-tutorial-01.png&quot; alt=&quot;内存地址构成&quot;&gt;&lt;/p&gt;
&lt;p&gt;上面是虚拟内存地址，下面是物理内存地址。由于页大小都是4K，所以页内便宜都是用低12位表示，而剩下的高地址表示页号。&lt;/p&gt;
&lt;p&gt;MMU映射单位并不是字节，而是页，这个映射通过查一个常驻内存的数据结构&lt;a href=&quot;http://en.wikipedia.org/wiki/Page_table&quot;&gt;页表&lt;/a&gt;来实现。现在计算机具体的内存地址映射比较复杂，为了加快速度会引入一系列缓存和优化，例如&lt;a href=&quot;http://en.wikipedia.org/wiki/Translation_lookaside_buffer&quot;&gt;TLB&lt;/a&gt;等机制。下面给出一个经过简化的内存地址翻译示意图，虽然经过了简化，但是基本原理与现代计算机真实的情况的一致的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://blog-codinglabs-org.qiniudn.com/image/a-malloc-tutorial-02.png&quot; alt=&quot;内存地址翻译&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;213-内存页与磁盘页&quot;&gt;2.1.3 内存页与磁盘页&lt;/h3&gt;
&lt;p&gt;我们知道一般将内存看做磁盘的的缓存，有时MMU在工作时，会发现页表表明某个内存页不在物理内存中，此时会触发一个缺页异常（Page Fault），此时系统会到磁盘中相应的地方将磁盘页载入到内存中，然后重新执行由于缺页而失败的机器指令。关于这部分，因为可以看做对malloc实现是透明的，所以不再详细讲述，有兴趣的可以参考《深入理解计算机系统》相关章节。&lt;/p&gt;
&lt;p&gt;最后附上一张在维基百科找到的更加符合真实地址翻译的流程供大家参考，这张图加入了TLB和缺页异常的流程（&lt;a href=&quot;http://en.wikipedia.org/wiki/Page_table&quot;&gt;图片来源页&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://blog-codinglabs-org.qiniudn.com/image/a-malloc-tutorial-03.png&quot; alt=&quot;较为完整的地址翻译流程&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;22-linux进程级内存管理&quot;&gt;2.2 Linux进程级内存管理&lt;/h2&gt;
&lt;h3 id=&quot;221-内存排布&quot;&gt;2.2.1 内存排布&lt;/h3&gt;
&lt;p&gt;明白了虚拟内存和物理内存的关系及相关的映射机制，下面看一下具体在一个进程内是如何排布内存的。&lt;/p&gt;
&lt;p&gt;以Linux 64位系统为例。理论上，64bit内存地址可用空间为0x0000000000000000 ~ 0xFFFFFFFFFFFFFFFF，这是个相当庞大的空间，Linux实际上只用了其中一小部分（256T）。&lt;/p&gt;
&lt;p&gt;根据&lt;a href=&quot;https://www.kernel.org/doc/Documentation/x86/x86_64/mm.txt&quot;&gt;Linux内核相关文档&lt;/a&gt;描述，Linux64位操作系统仅使用低47位，高17位做扩展（只能是全0或全1）。所以，实际用到的地址为空间为0x0000000000000000 ~ 0x00007FFFFFFFFFFF和0xFFFF800000000000 ~ 0xFFFFFFFFFFFFFFFF，其中前面为用户空间（User Space），后者为内核空间（Kernel Space）。图示如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://blog-codinglabs-org.qiniudn.com/image/a-malloc-tutorial-04.png&quot; alt=&quot;Linux进程地址排布&quot;&gt;&lt;/p&gt;
&lt;p&gt;对用户来说，主要关注的空间是User Space。将User Space放大后，可以看到里面主要分为如下几段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Code：这是整个用户空间的最低地址部分，存放的是指令（也就是程序所编译成的可执行机器码）&lt;/li&gt;
&lt;li&gt;Data：这里存放的是初始化过的全局变量&lt;/li&gt;
&lt;li&gt;BSS：这里存放的是未初始化的全局变量&lt;/li&gt;
&lt;li&gt;Heap：堆，这是我们本文重点关注的地方，堆自低地址向高地址增长，后面要讲到的brk相关的系统调用就是从这里分配内存&lt;/li&gt;
&lt;li&gt;Mapping Area：这里是与mmap系统调用相关的区域。大多数实际的malloc实现会考虑通过mmap分配较大块的内存区域，本文不讨论这种情况。这个区域自高地址向低地址增长&lt;/li&gt;
&lt;li&gt;Stack：这是栈区域，自高地址向低地址增长&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面我们主要关注Heap区域的操作。对整个Linux内存排布有兴趣的同学可以参考其它资料。&lt;/p&gt;
&lt;h3 id=&quot;222-heap内存模型&quot;&gt;2.2.2 Heap内存模型&lt;/h3&gt;
&lt;p&gt;一般来说，malloc所申请的内存主要从Heap区域分配（本文不考虑通过mmap申请大块内存的情况）。&lt;/p&gt;
&lt;p&gt;由上文知道，进程所面对的虚拟内存地址空间，只有按页映射到物理内存地址，才能真正使用。受物理存储容量限制，整个堆虚拟内存空间不可能全部映射到实际的物理内存。Linux对堆的管理示意如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://blog-codinglabs-org.qiniudn.com/image/a-malloc-tutorial-05.png&quot; alt=&quot;Linux进程堆管理&quot;&gt;&lt;/p&gt;
&lt;p&gt;Linux维护一个break指针，这个指针指向堆空间的某个地址。从堆起始地址到break之间的地址空间为映射好的，可以供进程访问；而从break往上，是未映射的地址空间，如果访问这段空间则程序会报错。&lt;/p&gt;
&lt;h3 id=&quot;223-brk与sbrk&quot;&gt;2.2.3 brk与sbrk&lt;/h3&gt;
&lt;p&gt;由上文知道，要增加一个进程实际的可用堆大小，就需要将break指针向高地址移动。Linux通过brk和sbrk系统调用操作break指针。两个系统调用的原型如下：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-c&quot;&gt;int brk(void *addr);
void *sbrk(intptr_t increment);&lt;/pre&gt;
&lt;p&gt;brk将break指针直接设置为某个地址，而sbrk将break从当前位置移动increment所指定的增量。brk在执行成功时返回0，否则返回-1并设置errno为ENOMEM；sbrk成功时返回break移动之前所指向的地址，否则返回(void *)-1。&lt;/p&gt;
&lt;p&gt;一个小技巧是，如果将increment设置为0，则可以获得当前break的地址。&lt;/p&gt;
&lt;p&gt;另外需要注意的是，由于Linux是按页进行内存映射的，所以如果break被设置为没有按页大小对齐，则系统实际上会在最后映射一个完整的页，从而实际已映射的内存空间比break指向的地方要大一些。但是使用break之后的地址是很危险的（尽管也许break之后确实有一小块可用内存地址）。&lt;/p&gt;
&lt;h3 id=&quot;224-资源限制与rlimit&quot;&gt;2.2.4 资源限制与rlimit&lt;/h3&gt;
&lt;p&gt;系统对每一个进程所分配的资源不是无限的，包括可映射的内存空间，因此每个进程有一个rlimit表示当前进程可用的资源上限。这个限制可以通过getrlimit系统调用得到，下面代码获取当前进程虚拟内存空间的rlimit：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-c&quot;&gt;int main() {
    struct rlimit *limit = (struct rlimit *)malloc(sizeof(struct rlimit));
    getrlimit(RLIMIT_AS, limit);
    printf(&quot;soft limit: %ld, hard limit: %ld\n&quot;, limit-&gt;rlim_cur, limit-&gt;rlim_max);
}&lt;/pre&gt;
&lt;p&gt;其中rlimit是一个结构体：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-c&quot;&gt;struct rlimit {
    rlim_t rlim_cur;  /* Soft limit */
    rlim_t rlim_max;  /* Hard limit (ceiling for rlim_cur) */
};&lt;/pre&gt;
&lt;p&gt;每种资源有软限制和硬限制，并且可以通过setrlimit对rlimit进行有条件设置。其中硬限制作为软限制的上限，非特权进程只能设置软限制，且不能超过硬限制。&lt;/p&gt;
&lt;h1 id=&quot;3-实现malloc&quot;&gt;3 实现malloc&lt;/h1&gt;
&lt;h2 id=&quot;31-玩具实现&quot;&gt;3.1 玩具实现&lt;/h2&gt;
&lt;p&gt;在正式开始讨论malloc的实现前，我们可以利用上述知识实现一个简单但几乎没法用于真实的玩具malloc，权当对上面知识的复习：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-c&quot;&gt;/* 一个玩具malloc */
#include &lt;sys/types.h&gt;
#include &lt;unistd.h&gt;
void *malloc(size_t size)
{
    void *p;
    p = sbrk(0);
    if (sbrk(size) == (void *)-1)
        return NULL;
    return p;
}&lt;/pre&gt;
&lt;p&gt;这个malloc每次都在当前break的基础上增加size所指定的字节数，并将之前break的地址返回。这个malloc由于对所分配的内存缺乏记录，不便于内存释放，所以无法用于真实场景。&lt;/p&gt;
&lt;h2 id=&quot;32-正式实现&quot;&gt;3.2 正式实现&lt;/h2&gt;
&lt;p&gt;下面严肃点讨论malloc的实现方案。&lt;/p&gt;
&lt;h3 id=&quot;321-数据结构&quot;&gt;3.2.1 数据结构&lt;/h3&gt;
&lt;p&gt;首先我们要确定所采用的数据结构。一个简单可行方案是将堆内存空间以块（Block）的形式组织起来，每个块由meta区和数据区组成，meta区记录数据块的元信息（数据区大小、空闲标志位、指针等等），数据区是真实分配的内存区域，并且数据区的第一个字节地址即为malloc返回的地址。&lt;/p&gt;
&lt;p&gt;可以用如下结构体定义一个block：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-c&quot;&gt;typedef struct s_block *t_block;
struct s_block {
    size_t size;  /* 数据区大小 */
    t_block next; /* 指向下个块的指针 */
    int free;     /* 是否是空闲块 */
    int padding;  /* 填充4字节，保证meta块长度为8的倍数 */
    char data[1]  /* 这是一个虚拟字段，表示数据块的第一个字节，长度不应计入meta */
};&lt;/pre&gt;
&lt;p&gt;由于我们只考虑64位机器，为了方便，我们在结构体最后填充一个int，使得结构体本身的长度为8的倍数，以便内存对齐。示意图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://blog-codinglabs-org.qiniudn.com/image/a-malloc-tutorial-06.png&quot; alt=&quot;Block结构&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;322-寻找合适的block&quot;&gt;3.2.2 寻找合适的block&lt;/h3&gt;
&lt;p&gt;现在考虑如何在block链中查找合适的block。一般来说有两种查找算法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;First fit&lt;/strong&gt;：从头开始，使用第一个数据区大小大于要求size的块所谓此次分配的块&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Best fit&lt;/strong&gt;：从头开始，遍历所有块，使用数据区大小大于size且差值最小的块作为此次分配的块&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;两种方法各有千秋，best fit具有较高的内存使用率（payload较高），而first fit具有更好的运行效率。这里我们采用first fit算法。&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-c&quot;&gt;/* First fit */
t_block find_block(t_block *last, size_t size) {
    t_block b = first_block;
    while(b &amp;&amp; !(b-&gt;free &amp;&amp; b-&gt;size &gt;= size)) {
        *last = b;
        b = b-&gt;next;
    }
    return b;
}&lt;/pre&gt;
&lt;p&gt;find_block从frist_block开始，查找第一个符合要求的block并返回block起始地址，如果找不到这返回NULL。这里在遍历时会更新一个叫last的指针，这个指针始终指向当前遍历的block。这是为了如果找不到合适的block而开辟新block使用的，具体会在接下来的一节用到。&lt;/p&gt;
&lt;h3 id=&quot;323-开辟新的block&quot;&gt;3.2.3 开辟新的block&lt;/h3&gt;
&lt;p&gt;如果现有block都不能满足size的要求，则需要在链表最后开辟一个新的block。这里关键是如何只使用sbrk创建一个struct：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-c&quot;&gt;#define BLOCK_SIZE 24 /* 由于存在虚拟的data字段，sizeof不能正确计算meta长度，这里手工设置 */

t_block extend_heap(t_block last, size_t s) {
    t_block b;
    b = sbrk(0);
    if(sbrk(BLOCK_SIZE + s) == (void *)-1)
        return NULL;
    b-&gt;size = s;
    b-&gt;next = NULL;
    if(last)
        last-&gt;next = b;
    b-&gt;free = 0;
    return b;
}&lt;/pre&gt;
&lt;h3 id=&quot;324-分裂block&quot;&gt;3.2.4 分裂block&lt;/h3&gt;
&lt;p&gt;First fit有一个比较致命的缺点，就是可能会让很小的size占据很大的一块block，此时，为了提高payload，应该在剩余数据区足够大的情况下，将其分裂为一个新的block，示意如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://blog-codinglabs-org.qiniudn.com/image/a-malloc-tutorial-07.png&quot; alt=&quot;分裂block&quot;&gt;&lt;/p&gt;
&lt;p&gt;实现代码：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-c&quot;&gt;void split_block(t_block b, size_t s) {
    t_block new;
    new = b-&gt;data + s;
    new-&gt;size = b-&gt;size - s - BLOCK_SIZE ;
    new-&gt;next = b-&gt;next;
    new-&gt;free = 1;
    b-&gt;size = s;
    b-&gt;next = new;
}&lt;/pre&gt;
&lt;h3 id=&quot;325-malloc的实现&quot;&gt;3.2.5 malloc的实现&lt;/h3&gt;
&lt;p&gt;有了上面的代码，我们可以利用它们整合成一个简单但初步可用的malloc。注意首先我们要定义个block链表的头first_block，初始化为NULL；另外，我们需要剩余空间至少有BLOCK_SIZE + 8才执行分裂操作。&lt;/p&gt;
&lt;p&gt;由于我们希望malloc分配的数据区是按8字节对齐，所以在size不为8的倍数时，我们需要将size调整为大于size的最小的8的倍数：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-c&quot;&gt;size_t align8(size_t s) {
    if(s &amp; 0x7 == 0)
        return s;
    return ((s &gt;&gt; 3) + 1) &lt;&lt; 3;
}&lt;/pre&gt;
&lt;pre class=&quot;prettyprint linenums lang-c&quot;&gt;#define BLOCK_SIZE 24
void *first_block=NULL;

/* other functions... */

void *malloc(size_t size) {
    t_block b, last;
    size_t s;
    /* 对齐地址 */
    s = align8(size);
    if(first_block) {
        /* 查找合适的block */
        last = first_block;
        b = find_block(&amp;last, s);
        if(b) {
            /* 如果可以，则分裂 */
            if ((b-&gt;size - s) &gt;= ( BLOCK_SIZE + 8))
                split_block(b, s);
            b-&gt;free = 0;
        } else {
            /* 没有合适的block，开辟一个新的 */
            b = extend_heap(last, s);
            if(!b)
                return NULL;
        }
    } else {
        b = extend_heap(NULL, s);
        if(!b)
            return NULL;
        first_block = b;
    }
    return b-&gt;data;
}&lt;/pre&gt;
&lt;h3 id=&quot;326-calloc的实现&quot;&gt;3.2.6 calloc的实现&lt;/h3&gt;
&lt;p&gt;有了malloc，实现calloc只要两步：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;malloc一段内存&lt;/li&gt;
&lt;li&gt;将数据区内容置为0&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;由于我们的数据区是按8字节对齐的，所以为了提高效率，我们可以每8字节一组置0，而不是一个一个字节设置。我们可以通过新建一个size_t指针，将内存区域强制看做size_t类型来实现。&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-c&quot;&gt;void *calloc(size_t number, size_t size) {
    size_t *new;
    size_t s8, i;
    new = malloc(number * size);
    if(new) {
        s8 = align8(number * size) &gt;&gt; 3;
        for(i = 0; i &lt; s8; i++)
            new[i] = 0;
    }
    return new;
}&lt;/pre&gt;
&lt;h3 id=&quot;327-free的实现&quot;&gt;3.2.7 free的实现&lt;/h3&gt;
&lt;p&gt;free的实现并不像看上去那么简单，这里我们要解决两个关键问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如何验证所传入的地址是有效地址，即确实是通过malloc方式分配的数据区首地址&lt;/li&gt;
&lt;li&gt;如何解决碎片问题&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;首先我们要保证传入free的地址是有效的，这个有效包括两方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;地址应该在之前malloc所分配的区域内，即在first_block和当前break指针范围内&lt;/li&gt;
&lt;li&gt;这个地址确实是之前通过我们自己的malloc分配的&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;第一个问题比较好解决，只要进行地址比较就可以了，关键是第二个问题。这里有两种解决方案：一是在结构体内埋一个magic number字段，free之前通过相对偏移检查特定位置的值是否为我们设置的magic number，另一种方法是在结构体内增加一个magic pointer，这个指针指向数据区的第一个字节（也就是在合法时free时传入的地址），我们在free前检查magic pointer是否指向参数所指地址。这里我们采用第二种方案：&lt;/p&gt;
&lt;p&gt;首先我们在结构体中增加magic pointer（同时要修改BLOCK_SIZE）：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-c&quot;&gt;typedef struct s_block *t_block;
struct s_block {
    size_t size;  /* 数据区大小 */
    t_block next; /* 指向下个块的指针 */
    int free;     /* 是否是空闲块 */
    int padding;  /* 填充4字节，保证meta块长度为8的倍数 */
    void *ptr;    /* Magic pointer，指向data */
    char data[1]  /* 这是一个虚拟字段，表示数据块的第一个字节，长度不应计入meta */
};&lt;/pre&gt;
&lt;p&gt;然后我们定义检查地址合法性的函数：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-c&quot;&gt;t_block get_block(void *p) {
    char *tmp;  
    tmp = p;
    return (p = tmp -= BLOCK_SIZE);
}

int valid_addr(void *p) {
    if(first_block) {
        if(p &gt; first_block &amp;&amp; p &lt; sbrk(0)) {
            return p == (get_block(p))-&gt;ptr;
        }
    }
    return 0;
}&lt;/pre&gt;
&lt;p&gt;当多次malloc和free后，整个内存池可能会产生很多碎片block，这些block很小，经常无法使用，甚至出现许多碎片连在一起，虽然总体能满足某此malloc要求，但是由于分割成了多个小block而无法fit，这就是碎片问题。&lt;/p&gt;
&lt;p&gt;一个简单的解决方式时当free某个block时，如果发现它相邻的block也是free的，则将block和相邻block合并。为了满足这个实现，需要将s_block改为双向链表。修改后的block结构如下：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-c&quot;&gt;typedef struct s_block *t_block;
struct s_block {
    size_t size;  /* 数据区大小 */
    t_block prev; /* 指向上个块的指针 */
    t_block next; /* 指向下个块的指针 */
    int free;     /* 是否是空闲块 */
    int padding;  /* 填充4字节，保证meta块长度为8的倍数 */
    void *ptr;    /* Magic pointer，指向data */
    char data[1]  /* 这是一个虚拟字段，表示数据块的第一个字节，长度不应计入meta */
};&lt;/pre&gt;
&lt;p&gt;合并方法如下：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-c&quot;&gt;t_block fusion(t_block b) {
    if (b-&gt;next &amp;&amp; b-&gt;next-&gt;free) {
        b-&gt;size += BLOCK_SIZE + b-&gt;next-&gt;size;
        b-&gt;next = b-&gt;next-&gt;next;
        if(b-&gt;next)
            b-&gt;next-&gt;prev = b;
    }
    return b;
}&lt;/pre&gt;
&lt;p&gt;有了上述方法，free的实现思路就比较清晰了：首先检查参数地址的合法性，如果不合法则不做任何事；否则，将此block的free标为1，并且在可以的情况下与后面的block进行合并。如果当前是最后一个block，则回退break指针释放进程内存，如果当前block是最后一个block，则回退break指针并设置first_block为NULL。实现如下：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-c&quot;&gt;void free(void *p) {
    t_block b;
    if(valid_addr(p)) {
        b = get_block(p);
        b-&gt;free = 1;
        if(b-&gt;prev &amp;&amp; b-&gt;prev-&gt;free)
            b = fusion(b-&gt;prev);
        if(b-&gt;next)
            fusion(b);
        else {
            if(b-&gt;prev)
                b-&gt;prev-&gt;prev = NULL;
            else
                first_block = NULL;
            brk(b);
        }
    }
}&lt;/pre&gt;
&lt;h3 id=&quot;328-realloc的实现&quot;&gt;3.2.8 realloc的实现&lt;/h3&gt;
&lt;p&gt;为了实现realloc，我们首先要实现一个内存复制方法。如同calloc一样，为了效率，我们以8字节为单位进行复制：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-c&quot;&gt;void copy_block(t_block src, t_block dst) {
    size_t *sdata, *ddata;
    size_t i;
    sdata = src-&gt;ptr;
    ddata = dst-&gt;ptr;
    for(i = 0; (i * 8) &lt; src-&gt;size &amp;&amp; (i * 8) &lt; dst-&gt;size; i++)
        ddata[i] = sdata[i];
}&lt;/pre&gt;
&lt;p&gt;然后我们开始实现realloc。一个简单（但是低效）的方法是malloc一段内存，然后将数据复制过去。但是我们可以做的更高效，具体可以考虑以下几个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果当前block的数据区大于等于realloc所要求的size，则不做任何操作&lt;/li&gt;
&lt;li&gt;如果新的size变小了，考虑split&lt;/li&gt;
&lt;li&gt;如果当前block的数据区不能满足size，但是其后继block是free的，并且合并后可以满足，则考虑做合并&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面是realloc的实现：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-c&quot;&gt;void *realloc(void *p, size_t size) {
    size_t s;
    t_block b, new;
    void *newp;
    if (!p)
        /* 根据标准库文档，当p传入NULL时，相当于调用malloc */
        return malloc(size);
    if(valid_addr(p)) {
        s = align8(size);
        b = get_block(p);
        if(b-&gt;size &gt;= s) {
            if(b-&gt;size - s &gt;= (BLOCK_SIZE + 8))
                split_block(b,s);
        } else {
            /* 看是否可进行合并 */
            if(b-&gt;next &amp;&amp; b-&gt;next-&gt;free
                    &amp;&amp; (b-&gt;size + BLOCK_SIZE + b-&gt;next-&gt;size) &gt;= s) {
                fusion(b);
                if(b-&gt;size - s &gt;= (BLOCK_SIZE + 8))
                    split_block(b, s);
            } else {
                /* 新malloc */
                newp = malloc (s);
                if (!newp)
                    return NULL;
                new = get_block(newp);
                copy_block(b, new);
                free(p);
                return(newp);
            }
        }
        return (p);
    }
    return NULL;
}&lt;/pre&gt;
&lt;h2 id=&quot;33-遗留问题和优化&quot;&gt;3.3 遗留问题和优化&lt;/h2&gt;
&lt;p&gt;以上是一个较为简陋，但是初步可用的malloc实现。还有很多遗留的可能优化点，例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同时兼容32位和64位系统&lt;/li&gt;
&lt;li&gt;在分配较大快内存时，考虑使用mmap而非sbrk，这通常更高效&lt;/li&gt;
&lt;li&gt;可以考虑维护多个链表而非单个，每个链表中的block大小均为一个范围内，例如8字节链表、16字节链表、24-32字节链表等等。此时可以根据size到对应链表中做分配，可以有效减少碎片，并提高查询block的速度&lt;/li&gt;
&lt;li&gt;可以考虑链表中只存放free的block，而不存放已分配的block，可以减少查找block的次数，提高效率&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;还有很多可能的优化，这里不一一赘述。下面附上一些参考文献，有兴趣的同学可以更深入研究。&lt;/p&gt;
&lt;h1 id=&quot;4-其它参考&quot;&gt;4 其它参考&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;这篇文章大量参考了&lt;a href=&quot;http://www.inf.udec.cl/~leo/Malloc_tutorial.pdf&quot;&gt;A malloc Tutorial&lt;/a&gt;，其中一些图片和代码直接引用了文中的内容，这里特别指出&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://csapp.cs.cmu.edu/&quot;&gt;Computer Systems: A Programmer&#39;s Perspective, 2/E&lt;/a&gt;一书有许多值得参考的地方&lt;/li&gt;
&lt;li&gt;关于Linux的虚拟内存模型，&lt;a href=&quot;http://duartes.org/gustavo/blog/post/anatomy-of-a-program-in-memory/&quot;&gt;Anatomy of a Program in Memory&lt;/a&gt;是很好的参考资料，另外作者还有一篇&lt;a href=&quot;http://duartes.org/gustavo/blog/post/how-the-kernel-manages-your-memory/&quot;&gt;How the Kernel Manages Your Memory&lt;/a&gt;对于Linux内核中虚拟内存管理的部分有很好的讲解&lt;/li&gt;
&lt;li&gt;对于真实世界的malloc实现，可以参考&lt;a href=&quot;http://repo.or.cz/w/glibc.git/blob/HEAD:/malloc/malloc.c&quot;&gt;glibc的实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;本文写作过程中大量参考了&lt;a href=&quot;http://www.wikipedia.org/&quot;&gt;维基百科&lt;/a&gt;，再次感谢这个伟大的网站，并且呼吁大家在手头允许的情况下可以适当捐助维基百科，帮助这个造福人类的系统运行下去&lt;/li&gt;
&lt;/ol&gt;
</description> 
        </item> 
        
        <item> 
            <title>生成特定分布随机数的方法</title> 
            <link>http://blog.codinglabs.org/articles/methods-for-generating-random-number-distributions.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link> 
            <guid>http://blog.codinglabs.org/articles/methods-for-generating-random-number-distributions.html</guid> 
            <author>ericzhang.buaa@gmail.com 张洋</author> 
            <pubDate>Sat, 14 Jun 2014 00:00:00 +0800</pubDate> 
            <description>&lt;p&gt;生成随机数是程序设计里常见的需求。一般的编程语言都会自带一个随机数生成函数，用于生成服从均匀分布的随机数。不过有时需要生成服从其它分布的随机数，例如高斯分布或指数分布等。有些编程语言已经有比较完善的实现，例如Python的NumPy。这篇文章介绍如何通过均匀分布随机数生成函数生成符合特定概率分布的随机数，主要介绍Inverse Ttransform和Acceptance-Rejection两种基础算法以及一些相关的衍生方法。下文我们均假设已经拥有一个可以生成0到1之间均匀分布的随机数生成函数，关于如何生成均匀分布等更底层的随机数生成理论，请参考其它资料，本文不做讨论。&lt;/p&gt;
&lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95&quot;&gt;基础算法&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#inverse-transform-method&quot;&gt;Inverse Transform Method&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#itm%E7%AE%97%E6%B3%95%E6%8F%8F%E8%BF%B0&quot;&gt;ITM算法描述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#itm%E7%AE%97%E6%B3%95%E8%AF%B4%E6%98%8E&quot;&gt;ITM算法说明&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#itm%E5%AE%9E%E7%8E%B0%E7%A4%BA%E4%BE%8B&quot;&gt;ITM实现示例&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#acceptance-rejection-method&quot;&gt;Acceptance-Rejection Method&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#arm%E7%AE%97%E6%B3%95%E6%8F%8F%E8%BF%B0&quot;&gt;ARM算法描述&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#arm%E7%AE%97%E6%B3%95%E8%AF%B4%E6%98%8E&quot;&gt;ARM算法说明&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#arm%E5%AE%9E%E7%8E%B0%E7%A4%BA%E4%BE%8B&quot;&gt;ARM实现示例&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#%E8%A1%8D%E7%94%9F%E7%AE%97%E6%B3%95&quot;&gt;衍生算法&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#%E7%BB%84%E5%90%88%E7%AE%97%E6%B3%95&quot;&gt;组合算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#%E7%94%9F%E6%88%90%E5%85%B7%E6%9C%89%E7%9B%B8%E5%85%B3%E6%80%A7%E7%9A%84%E9%9A%8F%E6%9C%BA%E6%95%B0&quot;&gt;生成具有相关性的随机数&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#%E6%9B%B4%E5%A4%9A%E5%8F%82%E8%80%83&quot;&gt;更多参考&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- toc stop --&gt;


&lt;h1 id=&quot;基础算法&quot;&gt;基础算法&lt;/h1&gt;
&lt;h2 id=&quot;inverse-transform-method&quot;&gt;Inverse Transform Method&lt;/h2&gt;
&lt;p&gt;最简单的生成算法是Inverse Transform Method（下文简称ITM）。如果我们可以给出概率分布的累积分布函数（下文简称CDF）及其逆函数的解析表达式，则可以非常简单便捷的生成指定分布随机数。&lt;/p&gt;
&lt;h3 id=&quot;itm算法描述&quot;&gt;ITM算法描述&lt;/h3&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;生成一个服从均匀分布的随机数\(U \\sim Uni(0,1)\)&lt;/li&gt;
&lt;li&gt;设\(F(X)\)为指定分布的CDF，\(F^{-1}(Y)\)是其逆函数。返回\(X=F^{-1}(U)\)作为结果&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;itm算法说明&quot;&gt;ITM算法说明&lt;/h3&gt;
&lt;p&gt;这是一个非常简洁高效的算法，下面说明其原理及正确性。&lt;/p&gt;
&lt;p&gt;我们通过图示可以更直观的明白算法的原理。下图是某概率分布的CDF：&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/methods-for-generating-random-number-distributions/inverse-transformation.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;我们从横轴上标注两点\(x_a\)和\(x_b\)，其CDF值分别为\(F(x_a)\)和\(F(x_b)\)。&lt;/p&gt;
&lt;p&gt;由于U服从0到1之间的均匀分布，因此对于一次U的取样，U落入\(F(x_a)\)和\(F(x_b)\)之间的概率为:&lt;/p&gt;
&lt;p&gt;\[P(U \in (F(x_a),F(x_b))) = F(x_b) - F(x_a)\]&lt;/p&gt;
&lt;p&gt;而由于CDF都是单调非减函数，因此这个概率同时等于\(X\)落入\(x_a\)和\(x_b\)之间的概率，即：&lt;/p&gt;
&lt;p&gt;\[P(U \in (F(x_a),F(x_b))) = P(F^{-1}(U) \in (F^{-1}(F(x_a)),F^{-1}(F(x_b)))) = P(X \in (x_a,x_b)) = F(x_b) - F(x_a)\]&lt;/p&gt;
&lt;p&gt;而根据CDF的定义，这刚好说明\(X\)服从以\(F(x)\)为CDF的分布，因此我们的生成算法是正确的。&lt;/p&gt;
&lt;h3 id=&quot;itm实现示例&quot;&gt;ITM实现示例&lt;/h3&gt;
&lt;p&gt;下面以&lt;a href=&quot;http://en.wikipedia.org/wiki/Exponential_distribution&quot;&gt;指数分布&lt;/a&gt;为例说明如何应用ITM。&lt;/p&gt;
&lt;p&gt;首先我们需要求解CDF的逆函数。我们知道指数分布的CDF为&lt;/p&gt;
&lt;p&gt;\[F(X)=1-e^{-\\lambda X}\]&lt;/p&gt;
&lt;p&gt;通过简单的代数运算，可以得到其逆函数为&lt;/p&gt;
&lt;p&gt;\[F^{-1}(Y)=-\\frac{1}{\\lambda}\\ln(1-Y)\]&lt;/p&gt;
&lt;p&gt;由于\(U\)服从从0到1的均匀分布蕴含着\(1-U\)服从同样的分布，因此在实际实现时可以用\(Y\)代替\(1-Y\)，得到：&lt;/p&gt;
&lt;p&gt;\[F^{-1}(Y)=-\\frac{1}{\\lambda}\\ln(Y)\]&lt;/p&gt;
&lt;p&gt;下面给出一个Python的实现示例程序。&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-python&quot;&gt;import random
import math
def exponential_rand(lam):
    if lam &lt;= 0:
        return -1
    U = random.uniform(0.0, 1.0)
    return (-1.0 / lam) * math.log(U)&lt;/pre&gt;
&lt;h2 id=&quot;acceptance-rejection-method&quot;&gt;Acceptance-Rejection Method&lt;/h2&gt;
&lt;p&gt;一般来说ITM是一种很好的算法，简单且高效，如果可以使用的话，是第一选择。但是ITM有自身的局限性，就是要求必须能给出CDF逆函数的解析表达式，有些时候要做到这点比较困难，这限制了ITM的适用范围。&lt;/p&gt;
&lt;p&gt;当无法给出CDF逆函数的解析表达式时，Acceptance-Rejection Method（下文简称ARM）是另外的选择。ARM的适用范围比ITM要大，只要给出概率密度函数（下文简称PDF）的解析表达式即可，而大多数常用分布的PDF是可以查到的。&lt;/p&gt;
&lt;h3 id=&quot;arm算法描述&quot;&gt;ARM算法描述&lt;/h3&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;设PDF为\(f(x)\)。首先生成一个均匀分布随机数\(X \\sim Uni(x_{min},x_{max})\)&lt;/li&gt;
&lt;li&gt;独立的生成另一个均匀分布随机数\(Y \\sim Uni(y_{min},y_{max})\)&lt;/li&gt;
&lt;li&gt;如果\(Y \\leq f(X)\)，则返回\(X\)，否则回到第1步&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;arm算法说明&quot;&gt;ARM算法说明&lt;/h3&gt;
&lt;p&gt;通过一幅图可以清楚的看到ARM的工作原理。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/methods-for-generating-random-number-distributions/accept-reject.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;ARM本质上是一种模拟方法，而非直接数学方法。它每次生成新的随机数后，通过另一个随机数来保证其被接受概率服从指定的PDF。&lt;/p&gt;
&lt;p&gt;显然ARM从效率上不如ITM，但是其适应性更广，在无法得到CDF的逆函数时，ARM是不错的选择。&lt;/p&gt;
&lt;h3 id=&quot;arm实现示例&quot;&gt;ARM实现示例&lt;/h3&gt;
&lt;p&gt;下面使用ARM实现一个能产生&lt;a href=&quot;http://en.wikipedia.org/wiki/Gauss_distribution&quot;&gt;标准正态分布&lt;/a&gt;的随机数生成函数。&lt;/p&gt;
&lt;p&gt;首先我们要得到标准正态分布的PDF，其数学表示为：&lt;/p&gt;
&lt;p&gt;\[f(x)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{x^2}{2}}\]&lt;/p&gt;
&lt;p&gt;为了方便，这里我会直接使用&lt;a href=&quot;http://www.scipy.org/&quot;&gt;SciPy&lt;/a&gt;来计算其PDF。&lt;/p&gt;
&lt;p&gt;程序如下。&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-python&quot;&gt;import random
import scipy.stats as ss

def standard_normal_rand():
    while True:
        X = random.uniform(-3.0,3.0)
        Y = random.uniform(0.0, 0.5)
        if Y &lt; ss.norm.pdf(X):
            return X&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：标准正态分布的x取值范围从理论上说是\((-\\infty,\\infty)\)，但是当离开均值点很远后，其概率密度可忽略不计。这里只取\((-3.0,3.0)\)，实际使用时可以根据具体需要扩大这个取值范围。&lt;/p&gt;
&lt;h1 id=&quot;衍生算法&quot;&gt;衍生算法&lt;/h1&gt;
&lt;h2 id=&quot;组合算法&quot;&gt;组合算法&lt;/h2&gt;
&lt;p&gt;当目标分布可以用其它分布经过四则运算表示时，可以使用组合算法生成对应随机数。&lt;/p&gt;
&lt;p&gt;最常见的就是某分布可以表示成多个独立同分布（下文简称IID）随机变量之和。例如二项分布可以表示成多个0-1分布之和，&lt;a href=&quot;http://en.wikipedia.org/wiki/Erlang_distribution&quot;&gt;Erlang分布&lt;/a&gt;可以由多个IID的指数分布得出。&lt;/p&gt;
&lt;p&gt;以Erlang分布为例说明如何生成这类随机数。&lt;/p&gt;
&lt;p&gt;设\(X_1,X_2,\\cdots,X_k\)为服从0到1均匀分布的IID随机数，则\(-\\frac{1}{\\lambda}lnX_1,-\\frac{1}{\\lambda}lnX_2,\\cdots,-\\frac{1}{\\lambda}lnX_k\)为服从指数分布的IID随机数，因此&lt;/p&gt;
&lt;p&gt;\[X=-\\frac{1}{\\lambda}lnX_1-\\frac{1}{\\lambda}lnX_2-\\cdots-\\frac{1}{\\lambda}lnX_k=-\\frac{1}{\\lambda}ln\\prod_{i=1}^k{X_i}\\sim Erl(k,\\lambda)\]&lt;/p&gt;
&lt;p&gt;所以生成Erlang分布随机数的算法如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;生成\(X_1,X_2,\\cdots,X_k\\sim Uni(0,1)\)&lt;/li&gt;
&lt;li&gt;返回\(-\\frac{1}{\\lambda}ln\\prod_{i=1}^k{X_i}\)&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;这类分布的随机数生成算法很直观，就是先生成相关的n个IID随机数，然后带入简单求和公式或其它四则公式得出最终随机数。其数学理论基础是&lt;a href=&quot;http://en.wikipedia.org/wiki/Convolution&quot;&gt;卷积理论&lt;/a&gt;，稍微有些复杂，这里不再讨论，有兴趣的同学可以查阅相关资料。&lt;/p&gt;
&lt;h2 id=&quot;生成具有相关性的随机数&quot;&gt;生成具有相关性的随机数&lt;/h2&gt;
&lt;p&gt;现在考虑生成多维随机数，以最简单的二维随机数为例。&lt;/p&gt;
&lt;p&gt;如果两个维度的随机数是相互独立的，那么只要分别生成两个列就可以了。但是如果要求两列具有一定的相关系数，则需要做一些特殊处理。&lt;/p&gt;
&lt;p&gt;下列算法可以生成两列具有相关系数\(\\rho\)的随机数。&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;生成IID随机变量\(X\)和\(Y\)&lt;/li&gt;
&lt;li&gt;计算\(X&#39;=\\rho X+\\sqrt{1-\\rho^2}Y\)&lt;/li&gt;
&lt;li&gt;返回\((X,X&#39;)\)&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;可以这样验证其正确性：&lt;/p&gt;
&lt;p&gt;\[corr(X,X&#39;)=\\rho corr(X,X)+\\sqrt{1-\\rho^2}corr(X,Y)=\\rho\]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：\(corr(X,X)=1\)，\(corr(X,Y)=0\)。&lt;/p&gt;
&lt;p&gt;因此\(X\)和\(X&#39;\)确实具有相关系数\(\\rho\)。&lt;/p&gt;
&lt;h1 id=&quot;更多参考&quot;&gt;更多参考&lt;/h1&gt;
&lt;p&gt;这篇文章讨论了生成指定分布随机数的基本方法。这篇文章只打算讨论基础方法，所以还有很多有趣的内容，本文没有深入的探讨。这里给出一些扩展阅读资料，供有兴趣的朋友深入学习。首先是一篇&lt;a href=&quot;http://ftp.arl.mil/random/random.pdf&quot;&gt;非常好的文档&lt;/a&gt;，这篇文章来自美国陆军实验室，对计算机生成指定分布随机数的方方面面进行了全面深入描述，是不可多得的好资料。&lt;/p&gt;
&lt;p&gt;在实现方面，可以参考&lt;a href=&quot;https://github.com/numpy/numpy/blob/master/numpy/random/mtrand/distributions.c&quot;&gt;NumPy中关于random的实现&lt;/a&gt;以及我开发的&lt;a href=&quot;https://github.com/ericzhang-cn/random.js&quot;&gt;JavaScript实现&lt;/a&gt;。另外我做过一个&lt;a href=&quot;http://blog.codinglabs.org/demo/distributions.html&quot;&gt;不同概率分布的可视化页面&lt;/a&gt;，可以帮助你直观理解不同分布及PDF参数对分布的影响。&lt;/p&gt;
</description> 
        </item> 
        
        <item> 
            <title>2048-AI程序算法分析</title> 
            <link>http://blog.codinglabs.org/articles/2048-ai-analysis.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link> 
            <guid>http://blog.codinglabs.org/articles/2048-ai-analysis.html</guid> 
            <author>ericzhang.buaa@gmail.com 张洋</author> 
            <pubDate>Fri, 04 Apr 2014 00:00:00 +0800</pubDate> 
            <description>&lt;p&gt;针对目前火爆的&lt;a href=&quot;http://gabrielecirulli.github.io/2048/&quot;&gt;2048&lt;/a&gt;游戏，&lt;a href=&quot;http://ov3y.github.io/2048-AI/&quot;&gt;有人实现了一个AI程序&lt;/a&gt;，可以以较大概率（高于90%）赢得游戏，并且&lt;a href=&quot;http://stackoverflow.com/questions/22342854/what-is-the-optimal-algorithm-for-the-game-2048&quot;&gt;作者在stackoverflow上简要介绍了AI的算法框架和实现思路&lt;/a&gt;。但是这个回答主要集中在启发函数的选取上，对AI用到的核心算法并没有仔细说明。这篇文章将主要分为两个部分，第一部分介绍其中用到的基础算法，即Minimax和Alpha-beta剪枝；第二部分分析作者具体的实现。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/2048-ai-analysis/00.png&quot;/&gt;&lt;/p&gt;

&lt;h1 id=&quot;基础算法&quot;&gt;基础算法&lt;/h1&gt;
&lt;p&gt;2048本质上可以抽象成信息对称双人对弈模型（玩家向四个方向中的一个移动，然后计算机在某个空格中填入2或4）。这里“信息对称”是指在任一时刻对弈双方对格局的信息完全一致，移动策略仅依赖对接下来格局的推理。作者使用的核心算法为对弈模型中常用的带Alpha-beta剪枝的Minimax。这个算法也常被用于如国际象棋等信息对称对弈AI中。&lt;/p&gt;
&lt;h2 id=&quot;minimax&quot;&gt;Minimax&lt;/h2&gt;
&lt;p&gt;下面先介绍不带剪枝的Minimax。首先本文将通过一个简单的例子说明Minimax算法的思路和决策方式。&lt;/p&gt;
&lt;h3 id=&quot;问题&quot;&gt;问题&lt;/h3&gt;
&lt;p&gt;现在考虑这样一个游戏：有三个盘子A、B和C，每个盘子分别放有三张纸币。A放的是1、20、50；B放的是5、10、100；C放的是1、5、20。单位均为“元”。有甲、乙两人，两人均对三个盘子和上面放置的纸币有可以任意查看。游戏分三步：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;甲从三个盘子中选取一个。&lt;/li&gt;
&lt;li&gt;乙从甲选取的盘子中拿出两张纸币交给甲。&lt;/li&gt;
&lt;li&gt;甲从乙所给的两张纸币中选取一张，拿走。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;其中甲的目标是最后拿到的纸币面值尽量大，乙的目标是让甲最后拿到的纸币面值尽量小。&lt;/p&gt;
&lt;p&gt;下面用Minimax算法解决这个问题。&lt;/p&gt;
&lt;h3 id=&quot;基本思路&quot;&gt;基本思路&lt;/h3&gt;
&lt;p&gt;一般解决博弈类问题的自然想法是将格局组织成一棵树，树的每一个节点表示一种格局，而父子关系表示由父格局经过一步可以到达子格局。Minimax也不例外，它通过对以当前格局为根的格局树搜索来确定下一步的选择。而一切格局树搜索算法的核心都是对每个格局价值的评价。Minimax算法基于以下朴素思想确定格局价值：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Minimax是一种悲观算法，即假设对手每一步都会将我方引入从当前看理论上价值最小的格局方向，即对手具有完美决策能力。因此我方的策略应该是选择那些对方所能达到的让我方最差情况中最好的，也就是让对方在完美决策下所对我造成的损失最小。&lt;/li&gt;
&lt;li&gt;Minimax不找理论最优解，因为理论最优解往往依赖于对手是否足够愚蠢，Minimax中我方完全掌握主动，如果对方每一步决策都是完美的，则我方可以达到预计的最小损失格局，如果对方没有走出完美决策，则我方可能达到比预计的最悲观情况更好的结局。总之我方就是要在最坏情况中选择最好的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上面的表述有些抽象，下面看具体示例。&lt;/p&gt;
&lt;h3 id=&quot;解题&quot;&gt;解题&lt;/h3&gt;
&lt;p&gt;下图是上述示例问题的格局树：&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/2048-ai-analysis/01.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;注意，由于示例问题格局数非常少，我们可以给出完整的格局树。这种情况下我可以找到Minimax算法的全局最优解。而真实情况中，格局树非常庞大，即使是计算机也不可能给出完整的树，因此我们往往只搜索一定深度，这时只能找到局部最优解。&lt;/p&gt;
&lt;p&gt;我们从甲的角度考虑。其中正方形节点表示轮到我方（甲），而三角形表示轮到对方（乙）。经过三轮对弈后（我方-对方-我方），将进入终局。黄色叶结点表示所有可能的结局。从甲方看，由于最终的收益可以通过纸币的面值评价，我们自然可以用结局中甲方拿到的纸币面值表示终格局的价值。&lt;/p&gt;
&lt;p&gt;下面考虑倒数第二层节点，在这些节点上，轮到我方选择，所以我们应该引入可选择的最大价值格局，因此每个节点的价值为其子节点的最大值：&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/2048-ai-analysis/02.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;这些轮到我方的节点叫做max节点，max节点的值是其子节点最大值。&lt;/p&gt;
&lt;p&gt;倒数第三层轮到对方选择，假设对方会尽力将局势引入让我方价值最小的格局，因此这些节点的价值取决于子节点的最小值。这些轮到对方的节点叫做min节点。&lt;/p&gt;
&lt;p&gt;最后，根节点是max节点，因此价值取决于叶子节点的最大值。最终完整赋值的格局树如下：&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/2048-ai-analysis/03.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;总结一下Minimax算法的步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先确定最大搜索深度D，D可能达到终局，也可能是一个中间格局。&lt;/li&gt;
&lt;li&gt;在最大深度为D的格局树叶子节点上，使用预定义的价值评价函数对叶子节点价值进行评价。&lt;/li&gt;
&lt;li&gt;自底向上为非叶子节点赋值。其中max节点取子节点最大值，min节点取子节点最小值。&lt;/li&gt;
&lt;li&gt;每次轮到我方时（此时必处在格局树的某个max节点），选择价值等于此max节点价值的那个子节点路径。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在上面的例子中，根节点的价值为20，表示如果对方每一步都完美决策，则我方按照上述算法可最终拿到20元，这是我方在Minimax算法下最好的决策。格局转换路径如下图红色路径所示：&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/2048-ai-analysis/04.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;对于真实问题中的Minimax，再次强调几点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;真实问题一般无法构造出完整的格局树，所以需要确定一个最大深度D，每次最多从当前格局向下计算D层。&lt;/li&gt;
&lt;li&gt;因为上述原因，Minimax一般是寻找一个局部最优解而不是全局最优解，搜索深度越大越可能找到更好的解，但计算耗时会呈指数级膨胀。&lt;/li&gt;
&lt;li&gt;也是因为无法一次构造出完整的格局树，所以真实问题中Minimax一般是边对弈边计算局部格局树，而不是只计算一次，但已计算的中间结果可以缓存。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;alpha-beta剪枝&quot;&gt;Alpha-beta剪枝&lt;/h2&gt;
&lt;p&gt;简单的Minimax算法有一个很大的问题就是计算复杂性。由于所需搜索的节点数随最大深度呈指数膨胀，而算法的效果往往和深度相关，因此这极大限制了算法的效果。&lt;/p&gt;
&lt;p&gt;Alpha-beta剪枝是对Minimax的补充和改进。采用Alpha-beta剪枝后，我们可不必构造和搜索最大深度D内的所有节点，在构造过程中，如果发现当前格局再往下不能找到更好的解，我们就停止在这个格局及以下的搜索，也就是剪枝。&lt;/p&gt;
&lt;p&gt;Alpha-beta基于这样一种朴素的思想：时时刻刻记得当前已经知道的最好选择，如果从当前格局搜索下去，不可能找到比已知最优解更好的解，则停止这个格局分支的搜索（剪枝），回溯到父节点继续搜索。&lt;/p&gt;
&lt;p&gt;Alpha-beta算法可以看成变种的Minimax，基本方法是从根节点开始采用深度优先的方式构造格局树，在构造每个节点时，都会读取此节点的alpha和beta两个值，其中alpha表示搜索到当前节点时已知的最好选择的下界，而beta表示从这个节点往下搜索最坏结局的上界。由于我们假设对手会将局势引入最坏结局之一，因此当beta小于alpha时，表示从此处开始不论最终结局是哪一个，其上限价值也要低于已知的最优解，也就是说已经不可能此处向下找到更好的解，所以就会剪枝。&lt;/p&gt;
&lt;p&gt;下面同样以上述示例介绍Alpha-beta剪枝算法的工作原理。我们从根节点开始，详述使用Alpha-beta的每一个步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;根节点的alpha和beta分别被初始化为\(-\\infty\)，和\(+\\infty\)。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;深度优先搜索第一个孩子，不是叶子节点，所以alpha和beta继承自父节点，分别为\(-\\infty\)，和\(+\\infty\)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;搜索第三层的第一个孩子，同上。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;搜索第四层，到达叶子节点，采用评价函数得到此节点的评价值为1。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/2048-ai-analysis/05.png&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;此叶节点的父节点为max节点，因此更新其alpha值为1，表示此节点取值的下界为1。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;再看另外一个子节点，值为20，大于当前alpha值，因此将alpha值更新为20。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;此时第三层最左节点所有子树搜索完毕，作为max节点，更新其真实值为当前alpha值：20。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;由于其父节点（第二层最左节点）为min节点，因此更新其父节点beta值为20，表示这个节点取值最多为20。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/2048-ai-analysis/06.png&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;搜索第二层最左节点的第二个孩子及其子树，按上述逻辑，得到值为50（注意第二层最左节点的beta值要传递给孩子）。由于50大于20，不更新min节点的beta值。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/2048-ai-analysis/07.png&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;搜索第二层最左节点的第三个孩子。当看完第一个叶子节点后，发现第三个孩子的alpha=beta，此时表示这个节点下不会再有更好解，于是剪枝。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/2048-ai-analysis/08.png&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;继续搜索B分支，当搜索完B分支的第一个孩子后，发现此时B分支的alpha为20，beta为10。这表示B分支节点的最大取值不会超过10，而我们已经在A分支取到20，此时满足alpha大于等于beta的剪枝条件，因此将B剪枝。并将B分支的节点值设为10，注意，这个10不一定是这个节点的真实值，而只是上线，B节点的真实值可能是5，可能是1，可能是任何小于10的值。但是已经无所谓了，反正我们知道这个分支不会好过A分支，因此可以放弃了。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/2048-ai-analysis/09.png&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在C分支搜索时遇到了与B分支相同的情况。因此讲C分支剪枝。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/2048-ai-analysis/10.png&quot;/&gt;&lt;/p&gt;

&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;此时搜索全部完毕，而我们也得到了这一步的策略：应该走A分支。&lt;/p&gt;
&lt;p&gt;可以看到相比普通Minimax要搜索18个叶子节点相比，这里只搜索了9个。采用Alpha-beta剪枝，可以在相同时间内加大Minimax的搜索深度，因此可以获得更好的效果。并且Alpha-beta的解和普通Minimax的解是一致的。&lt;/p&gt;
&lt;h1 id=&quot;针对2048游戏的实现&quot;&gt;针对2048游戏的实现&lt;/h1&gt;
&lt;p&gt;下面看一下ov3y同学针对2048实现的AI。程序的github在&lt;a href=&quot;https://github.com/ov3y/2048-AI&quot;&gt;这里&lt;/a&gt;，主要程序都在&lt;a href=&quot;https://github.com/ov3y/2048-AI/blob/master/js/ai.js&quot;&gt;ai.js&lt;/a&gt;中。&lt;/p&gt;
&lt;h2 id=&quot;建模&quot;&gt;建模&lt;/h2&gt;
&lt;p&gt;上面说过Minimax和Alpha-beta都是针对信息对称的轮流对弈问题，这里作者是这样抽象游戏的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我方：游戏玩家。每次可以选择上、下、左、右四个行棋策略中的一种（某些格局会少于四种，因为有些方向不可走）。行棋后方块按照既定逻辑移动及合并，格局转换完成。&lt;/li&gt;
&lt;li&gt;对方：计算机。在当前任意空格子里放置一个方块，方块的数值可以是2或4。放置新方块后，格局转换完成。&lt;/li&gt;
&lt;li&gt;胜利条件：出现某个方块的数值为“2048”。&lt;/li&gt;
&lt;li&gt;失败条件：格子全满，且无法向四个方向中任何一个方向移动（均不能触发合并）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如此2048游戏就被建模成一个信息对称的双人对弈问题。&lt;/p&gt;
&lt;h2 id=&quot;格局评价&quot;&gt;格局评价&lt;/h2&gt;
&lt;p&gt;作为算法的核心，如何评价当前格局的价值是重中之重。在2048中，除了终局外，中间格局并无非常明显的价值评价指标，因此需要用一些启发式的指标来评价格局。那些分数高的“好”格局是容易引向胜利的格局，而分低的“坏”格局是容易引向失败的格局。&lt;/p&gt;
&lt;p&gt;作者采用了如下几个启发式指标。&lt;/p&gt;
&lt;h3 id=&quot;单调性&quot;&gt;单调性&lt;/h3&gt;
&lt;p&gt;单调性指方块从左到右、从上到下均遵从递增或递减。一般来说，越单调的格局越好。下面是一个具有良好单调格局的例子：&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/2048-ai-analysis/11.png&quot;/&gt;&lt;/p&gt;

&lt;h3 id=&quot;平滑性&quot;&gt;平滑性&lt;/h3&gt;
&lt;p&gt;平滑性是指每个方块与其直接相邻方块数值的差，其中差越小越平滑。例如2旁边是4就比2旁边是128平滑。一般认为越平滑的格局越好。下面是一个具有极端平滑性的例子：&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/2048-ai-analysis/12.png&quot;/&gt;&lt;/p&gt;

&lt;h3 id=&quot;空格数&quot;&gt;空格数&lt;/h3&gt;
&lt;p&gt;这个很好理解，因为一般来说，空格子越少对玩家越不利。所以我们认为空格越多的格局越好。&lt;/p&gt;
&lt;h3 id=&quot;孤立空格数&quot;&gt;孤立空格数&lt;/h3&gt;
&lt;p&gt;这个指标评价空格被分开的程度，空格越分散则格局越差。&lt;/p&gt;
&lt;p&gt;具体来说，2048-AI在评价格局时，对这些启发指标采用了加权策略。具体代码如下：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-js&quot;&gt;// static evaluation function
AI.prototype.eval = function() {
    var emptyCells = this.grid.availableCells().length;

    var smoothWeight = 0.1,
        //monoWeight   = 0.0,
        //islandWeight = 0.0,
        mono2Weight  = 1.0,
        emptyWeight  = 2.7,
        maxWeight    = 1.0;

    return this.grid.smoothness() * smoothWeight
        //+ this.grid.monotonicity() * monoWeight
        //- this.grid.islands() * islandWeight
        + this.grid.monotonicity2() * mono2Weight
        + Math.log(emptyCells) * emptyWeight
        + this.grid.maxValue() * maxWeight;
};&lt;/pre&gt;
&lt;p&gt;有兴趣的同学可以调整一下权重看看有什么效果。&lt;/p&gt;
&lt;h2 id=&quot;对对方选择的剪枝&quot;&gt;对对方选择的剪枝&lt;/h2&gt;
&lt;p&gt;在这个程序中，除了采用Alpha-beta剪枝外，在min节点还采用了另一种剪枝，即只考虑对方走出让格局最差的那一步（而实际2048中计算机的选择是随机的），而不是搜索全部对方可能的走法。这是因为对方所有可能的选择为“空格数×2”，如果全部搜索的话会严重限制搜索深度。&lt;/p&gt;
&lt;p&gt;相关剪枝代码如下：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-js&quot;&gt;// try a 2 and 4 in each cell and measure how annoying it is
// with metrics from eval
var candidates = [];
var cells = this.grid.availableCells();
var scores = { 2: [], 4: [] };
for (var value in scores) {
    for (var i in cells) {
        scores[value].push(null);
        var cell = cells[i];
        var tile = new Tile(cell, parseInt(value, 10));
        this.grid.insertTile(tile);
        scores[value][i] = -this.grid.smoothness() + this.grid.islands();
        this.grid.removeTile(cell);
    }
}

// now just pick out the most annoying moves
var maxScore = Math.max(Math.max.apply(null, scores[2]), Math.max.apply(null, scores[4]));
for (var value in scores) { // 2 and 4
    for (var i=0; i&lt;scores[value].length; i++) {
        if (scores[value][i] == maxScore) {
            candidates.push( { position: cells[i], value: parseInt(value, 10) } );
        }
    }
}&lt;/pre&gt;
&lt;h2 id=&quot;搜索深度&quot;&gt;搜索深度&lt;/h2&gt;
&lt;p&gt;在2048-AI的实现中，并没有限制搜索的最大深度，而是限制每次“思考”的时间。这里设定了一个超时时间，默认为100ms，在这个时间内，会从1开始，搜索到所能达到的深度。相关代码：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-js&quot;&gt;// performs iterative deepening over the alpha-beta search
AI.prototype.iterativeDeep = function() {
    var start = (new Date()).getTime();
    var depth = 0;
    var best;
    do {
        var newBest = this.search(depth, -10000, 10000, 0 ,0);
        if (newBest.move == -1) {
            //console.log(&#39;BREAKING EARLY&#39;);
            break;
        } else {
            best = newBest;
        }
        depth++;
    } while ( (new Date()).getTime() - start &lt; minSearchTime);
    //console.log(&#39;depth&#39;, --depth);
    //console.log(this.translate(best.move));
    //console.log(best);
    return best
}
&lt;/pre&gt;
&lt;p&gt;因此这个算法实现的效果实际上依赖于执行javascript引擎机器的性能。当然可以通过增加超时时间来达到更好的效果，但此时每一步行走速度会相应变慢。&lt;/p&gt;
&lt;h2 id=&quot;算法的改进&quot;&gt;算法的改进&lt;/h2&gt;
&lt;p&gt;目前这个实现作者声称成功合成2048的概率超过90%，但是合成4096甚至8192的概率并不高。作者在&lt;a href=&quot;https://github.com/ov3y/2048-AI/blob/master/README.md&quot;&gt;github项目的REAMDE&lt;/a&gt;中同时给出了一些优化建议，这些建议包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;缓存结果。目前这个实现并没有对已搜索的树做缓存，每一步都要重新开始搜索。&lt;/li&gt;
&lt;li&gt;多线程搜索。由于javascript引擎的单线程特性，这一点很难做到，但如果在其它平台上也许也可考虑并行技术。&lt;/li&gt;
&lt;li&gt;更好的启发函数。也许可以总结出一些更好的启发函数来评价格局价值。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;参考文献&quot;&gt;参考文献&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;http://gabrielecirulli.github.io/2048/&quot;&gt;2048 Game&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/ov3y/2048-AI&quot;&gt;2048-AI github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.flyingmachinestudios.com/programming/minimax/&quot;&gt;An Exhaustive Explanation of Minimax, a Staple AI Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.neverstopbuilding.com/minimax&quot;&gt;Tic Tac Toe: Understanding the Minimax Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://cs.ucla.edu/~rosen/161/notes/alphabeta.html&quot;&gt;CS 161 Recitation Notes - Minimax with Alpha Beta Pruning&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description> 
        </item> 
        
        <item> 
            <title>抓取网页内容生成Kindle电子书</title> 
            <link>http://blog.codinglabs.org/articles/convert-html-to-kindle-book.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link> 
            <guid>http://blog.codinglabs.org/articles/convert-html-to-kindle-book.html</guid> 
            <author>ericzhang.buaa@gmail.com 张洋</author> 
            <pubDate>Thu, 27 Mar 2014 00:00:00 +0800</pubDate> 
            <description>&lt;p&gt;自从买了kindle后，总是想着如何最大效用发挥其效用。虽然多看上有很多书可以购买，网上也有很多免费的电子书，但是仍然有很多感兴趣的内容是以网页的形式存在的。例如&lt;a href=&quot;http://chimera.labs.oreilly.com/books/&quot;&gt;O’Reilly Atlas&lt;/a&gt;就提供了诸多电子书，但是只提供免费的在线阅读；另外还有很多资料或文档都只有网页形式。于是就希望通过某种方法讲这些在线资料转为epub或mobi格式，以便在kindle上阅读。这篇文章介绍了如何借助calibre并编写少量代码来达到这个目的。&lt;/p&gt;
&lt;h1 id=&quot;calibre&quot;&gt;Calibre&lt;/h1&gt;
&lt;h2 id=&quot;calibre简介&quot;&gt;Calibre简介&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://calibre-ebook.com/&quot;&gt;Calibre&lt;/a&gt;是一个免费的电子书管理工具，可以兼容Windows, OS X及Linux，令人欣喜的是，除了GUI外，calibre还提供了诸多命令行工具，其中的ebook-convert命令可以根据用户编写的recipes文件（实际是python代码）抓取指定页面内容并生成mobi等格式的电子书。通过编写recipes可以自定制抓取行为，以适应不同的网页结构。&lt;/p&gt;
&lt;h2 id=&quot;安装calibre&quot;&gt;安装Calibre&lt;/h2&gt;
&lt;p&gt;Calibre的下载地址是&lt;a href=&quot;http://calibre-ebook.com/download&quot;&gt;http://calibre-ebook.com/download&lt;/a&gt;，可以根据自己的操作系统下载相应的安装程序。&lt;/p&gt;
&lt;p&gt;如果是Linux操作系统，还可以通过软件仓库安装：&lt;/p&gt;
&lt;p&gt;Archlinux：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;pacman -S calibre&lt;/pre&gt;
&lt;p&gt;Debian/Ubuntu：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;apt-get install calibre&lt;/pre&gt;
&lt;p&gt;RedHat/Fedora/CentOS：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;yum -y install calibre&lt;/pre&gt;
&lt;p&gt;注意，如果你使用OSX，需要单独安装&lt;a href=&quot;http://manual.calibre-ebook.com/cli/cli-index.html&quot;&gt;Command Line Tool&lt;/a&gt;。&lt;/p&gt;
&lt;h1 id=&quot;抓取网页生成电子书&quot;&gt;抓取网页生成电子书&lt;/h1&gt;
&lt;p&gt;下面以&lt;a href=&quot;http://chimera.labs.oreilly.com/books/1230000000561&quot;&gt;Git Pocket Guide&lt;/a&gt;为例，说明如何通过calibre从网页生成电子书。&lt;/p&gt;
&lt;h2 id=&quot;找到index页&quot;&gt;找到index页&lt;/h2&gt;
&lt;p&gt;要抓取整本书，第一件事就是找到index页，这个页面一般是Table of Contents，也就是目录页，其中每个目录项链接到相应内容页。index页将会指导抓取哪些页面以及生成电子书时内容组织顺序。在这个例子中，index页面是&lt;a href=&quot;http://chimera.labs.oreilly.com/books/1230000000561/index.html&quot;&gt;http://chimera.labs.oreilly.com/books/1230000000561/index.html&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&quot;编写recipes&quot;&gt;编写recipes&lt;/h2&gt;
&lt;p&gt;Recipes是一个以recipe为扩展名的脚本，内容实际上是一段python代码，用来定义calibre抓取页面的范围和行为，下面是用于抓取Git Pocket Guide的recipes：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-python&quot;&gt;from calibre.web.feeds.recipes import BasicNewsRecipe

class Git_Pocket_Guide(BasicNewsRecipe):

    title = &#39;Git Pocket Guide&#39;
    description = &#39;&#39;
    cover_url = &#39;http://akamaicovers.oreilly.com/images/0636920024972/lrg.jpg&#39;

    url_prefix = &#39;http://chimera.labs.oreilly.com/books/1230000000561/&#39;
    no_stylesheets = True
    keep_only_tags = [{ &#39;class&#39;: &#39;chapter&#39; }]

    def get_title(self, link):
        return link.contents[0].strip()

    def parse_index(self):
        soup = self.index_to_soup(self.url_prefix + &#39;index.html&#39;)

        div = soup.find(&#39;div&#39;, { &#39;class&#39;: &#39;toc&#39; })

        articles = []
        for link in div.findAll(&#39;a&#39;):
            if &#39;#&#39; in link[&#39;href&#39;]:
                continue

            if not &#39;ch&#39; in link[&#39;href&#39;]:
                continue

            til = self.get_title(link)
            url = self.url_prefix + link[&#39;href&#39;]
            a = { &#39;title&#39;: til, &#39;url&#39;: url }

            articles.append(a)

        ans = [(&#39;Git_Pocket_Guide&#39;, articles)]

        return ans&lt;/pre&gt;
&lt;p&gt;下面分别解释代码中不同部分。&lt;/p&gt;
&lt;h3 id=&quot;总体结构&quot;&gt;总体结构&lt;/h3&gt;
&lt;p&gt;总体来看，一个recipes就是一个python class，只不过这个class必须继承calibre.web.feeds.recipes.BasicNewsRecipe。&lt;/p&gt;
&lt;h3 id=&quot;parse_index&quot;&gt;parse_index&lt;/h3&gt;
&lt;p&gt;整个recipes的核心方法是parse_index，也是recipes唯一必须实现的方法。这个方法的目标是通过分析index页面的内容，返回一个稍显复杂的数据结构（稍后介绍），这个数据结构定义了整个电子书的内容及内容组织顺序。&lt;/p&gt;
&lt;h3 id=&quot;总体属性设置&quot;&gt;总体属性设置&lt;/h3&gt;
&lt;p&gt;在class的开始，定义了一些全局属性：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-python&quot;&gt;title = &#39;Git Pocket Guide&#39;
description = &#39;&#39;
cover_url = &#39;http://akamaicovers.oreilly.com/images/0636920024972/lrg.jpg&#39;

url_prefix = &#39;http://chimera.labs.oreilly.com/books/1230000000561/&#39;
no_stylesheets = True
keep_only_tags = [{ &#39;class&#39;: &#39;chapter&#39; }]&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;title：电子书标题&lt;/li&gt;
&lt;li&gt;description：电子书描述&lt;/li&gt;
&lt;li&gt;cover_url：电子书的封面图片&lt;/li&gt;
&lt;li&gt;url_prefix：这是我自用的属性，是内容页面的前缀，用于后面拼装内容页的完整url&lt;/li&gt;
&lt;li&gt;no_stylesheets：不要使用页面CSS样式&lt;/li&gt;
&lt;li&gt;keep_only_tags：这一行告诉calibre分析index页时仅考虑class属性为“chapter”的DOM元素，如果你看index页的源码会发现这对应一级标题。之所以这样是因为在这个例子中，index页面每个一级标题对应一个独立内容页，而二级标题仅链接到页面中某个锚点（anchor），所以仅需考虑一级标题&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;parse_index返回值&quot;&gt;parse_index返回值&lt;/h3&gt;
&lt;p&gt;下面介绍parse_index需要通过分析index页面返回的数据结构。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/convert-html-to-kindle-book/01.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;总体返回数据结构是一个list，其中每个元素是一个tuple，一个tuple表示一卷（volume）。在这个例子中只有一卷，所以list中只有一个tuple。&lt;/p&gt;
&lt;p&gt;每个tuple有两个元素，第一个元素是卷名，第二个元素是一个list，list中每个元素是一个map，表示一章（chapter），map中有两个元素：title和url，title是章节标题，url是章节所在内容页的url。&lt;/p&gt;
&lt;p&gt;Calibre会根据parse_index的返回结果抓取并组织整个书，并且会自行抓取并处理内容中外链的图片。&lt;/p&gt;
&lt;p&gt;整个parse_index使用soup解析index页并生成上述数据结构。&lt;/p&gt;
&lt;h3 id=&quot;更多&quot;&gt;更多&lt;/h3&gt;
&lt;p&gt;上面是最基本的recipes，想了解更多的使用方法，可以参考&lt;a href=&quot;http://manual.calibre-ebook.com/news_recipe.html&quot;&gt;API文档&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&quot;生成mobi&quot;&gt;生成mobi&lt;/h2&gt;
&lt;p&gt;编写好recipes后，在命令行下通过如下命令即可生成电子书：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;ebook-convert Git_Pocket_Guide.recipe Git_Pocket_Guide.mobi&lt;/pre&gt;
&lt;p&gt;即可生成mobi格式的电子书。ebook-convert会根据recipes代码自行抓取相关内容并组织结构。&lt;/p&gt;
&lt;h1 id=&quot;最终效果&quot;&gt;最终效果&lt;/h1&gt;
&lt;p&gt;下面是在kindle上看到的效果。&lt;/p&gt;
&lt;p&gt;目录&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/convert-html-to-kindle-book/02.jpg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;内容一&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/convert-html-to-kindle-book/03.jpg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;内容二&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/convert-html-to-kindle-book/04.jpg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;含有图片的页&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/convert-html-to-kindle-book/05.jpg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;实际效果&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/convert-html-to-kindle-book/06.jpg&quot;/&gt;&lt;/p&gt;

&lt;h1 id=&quot;我的recipes仓库&quot;&gt;我的recipes仓库&lt;/h1&gt;
&lt;p&gt;我在github上建了一个&lt;a href=&quot;https://github.com/ericzhang-cn/kindle-open-books/&quot;&gt;kindle-open-books&lt;/a&gt;，里面放了一些recipes，有我写的，也有其他同学贡献的。欢迎任何人贡献的recipes。&lt;/p&gt;
</description> 
        </item> 
        
        <item> 
            <title>开始使用Ubuntu作为工作环境</title> 
            <link>http://blog.codinglabs.org/articles/getting-started-with-ubuntu.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link> 
            <guid>http://blog.codinglabs.org/articles/getting-started-with-ubuntu.html</guid> 
            <author>ericzhang.buaa@gmail.com 张洋</author> 
            <pubDate>Mon, 30 Dec 2013 00:00:00 +0800</pubDate> 
            <description>&lt;p&gt;2012年3月，我自购了一台13寸的Macbook Air，从那时开始至今近两年时间，我一直用它作为工作本。但是最近越来越觉得4G的内存和128G的SSD力不从心，苦于Air无法升级硬件，于是终于下决心拿出入职时公司给配的Dell E6410，自己买了内存和SSD，升级成了8G内存+370G混合硬盘（120G SSD做主盘，250G硬盘做从盘）。&lt;/p&gt;
&lt;p&gt;硬件升级事小，关键是系统的迁移代价比较大。我在Dell本上装的是Ubuntu 13.10，由于我平时习惯使用Dropbox等云端服务，浏览器配置也都通过Google账号漫游，所以这部分迁移几乎没有成本，主要的成本在开发环境配置和常用软件迁移。虽然都是Unix系，但是Mac OSX下很多软件Linux下并没有。&lt;/p&gt;
&lt;p&gt;花了大约一个周末，总算把我的Ubuntu配置的比较顺手了，目前也已经正式投入工作。其中的重头戏便是开发环境（主要是terminal和vim）的配置，另外就是一些常用工具。这篇文章记录了我一些主要的工作，算是给自己留一个文档，也希望能给打算从Mac迁移到Linux的同学做一个借鉴。&lt;/p&gt;
&lt;h1 id=&quot;开发环境配置&quot;&gt;开发环境配置&lt;/h1&gt;
&lt;p&gt;之前在Mac下，我直接使用的是&lt;a href=&quot;https://github.com/square/maximum-awesome&quot;&gt;maximum-awesome&lt;/a&gt;，开发环境这块完全不用自己操心。可惜maximum-awesome只能在Mac下使用，并没有Linux版。于是需要自己做一些工作，以便让开发环境够顺手。&lt;/p&gt;
&lt;h2 id=&quot;使用terminator作为终端&quot;&gt;使用terminator作为终端&lt;/h2&gt;
&lt;h3 id=&quot;安装terminator&quot;&gt;安装terminator&lt;/h3&gt;
&lt;p&gt;Ubuntu自带的终端是gnome-terminal，虽然也还不错，但是不能支持屏幕分割、选择复制等功能让我很不爽，于是我换用terminator作为终端，terminator可以支持屏幕分割，并且默认快捷键和gnome-terminal无异，熟悉gnome-terminal的话可以快速上手。&lt;/p&gt;
&lt;p&gt;Ubuntu下可以这样安装terminator：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;sudo apt-get install terminator&lt;/pre&gt;
&lt;h3 id=&quot;terminator常用快捷键&quot;&gt;terminator常用快捷键&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Ctrl-Shift-c 拷贝&lt;/li&gt;
&lt;li&gt;Ctrl-Shift-v 粘贴&lt;/li&gt;
&lt;li&gt;Ctrl-Shift-t 开新Tab窗口&lt;/li&gt;
&lt;li&gt;Ctrl-Shift-o 上下拆分屏幕&lt;/li&gt;
&lt;li&gt;Ctrl-Shift-e 左右拆分屏幕&lt;/li&gt;
&lt;li&gt;Ctrl-Shift-w 关闭当前窗口&lt;/li&gt;
&lt;li&gt;Ctrl-Shift-q 关闭整个终端&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;配置terminator使用solarized配色&quot;&gt;配置terminator使用solarized配色&lt;/h2&gt;
&lt;h3 id=&quot;使用terminator-solarized&quot;&gt;使用terminator-solarized&lt;/h3&gt;
&lt;p&gt;maximum-awesome所使用的&lt;a href=&quot;http://ethanschoonover.com/solarized&quot;&gt;solarized&lt;/a&gt;配色是相当不错的，所以自然希望继续使用。针对terminator的solarized配色已经有人专门做好了：&lt;a href=&quot;https://github.com/ghuntley/terminator-solarized&quot;&gt;terminator-solarized&lt;/a&gt;，只要按如下操作就可以使用：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;mkdir -p ~/.config/terminator/
curl https://raw.github.com/ghuntley/terminator-solarized/master/config &gt; ~/.config/terminator/config&lt;/pre&gt;
&lt;p&gt;然后重新打开terminator就已经是solarized配色了。&lt;/p&gt;
&lt;h3 id=&quot;对terminator更多的配置&quot;&gt;对terminator更多的配置&lt;/h3&gt;
&lt;p&gt;接下来，可以在terminator-solarized配置文件的基础上进行更多的配置，例如背景透明、启用选择复制等。&lt;/p&gt;
&lt;p&gt;关于terminator的详细配置选项可以参考&lt;a href=&quot;http://manpages.ubuntu.com/manpages/intrepid/man5/terminator_config.5.html&quot;&gt;terminator manpage&lt;/a&gt;，下面贴出我的~/.config/terminator/config供参考：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;[global_config]
    title_transmit_bg_color = &quot;#d30102&quot;
    focus = system
    suppress_multiple_term_dialog = True
[keybindings]
[profiles]
    [[default]]
        palette = &quot;#073642:#dc322f:#859900:#b58900:#268bd2:#d33682:#2aa198:#eee8d5:#002b36:#cb4b16:#586e75:#657b83:#839496:#6c71c4:#93a1a1:#fdf6e3&quot;
        copy_on_selection = True
        background_image = None
        background_darkness = 0.95
        background_type = transparent
        use_system_font = False
        cursor_color = &quot;#eee8d5&quot;
        foreground_color = &quot;#839496&quot;
        show_titlebar = False
        font = Monospace 11
        background_color = &quot;#002b36&quot;
    [[solarized-dark]]
        palette = &quot;#073642:#dc322f:#859900:#b58900:#268bd2:#d33682:#2aa198:#eee8d5:#002b36:#cb4b16:#586e75:#657b83:#839496:#6c71c4:#93a1a1:#fdf6e3&quot;
        background_color = &quot;#002b36&quot;
        background_image = None
        cursor_color = &quot;#eee8d5&quot;
        foreground_color = &quot;#839496&quot;
    [[solarized-light]]
        palette = &quot;#073642:#dc322f:#859900:#b58900:#268bd2:#d33682:#2aa198:#eee8d5:#002b36:#cb4b16:#586e75:#657b83:#839496:#6c71c4:#93a1a1:#fdf6e3&quot;
        background_color = &quot;#fdf6e3&quot;
        background_image = None
        cursor_color = &quot;#002b36&quot;
        foreground_color = &quot;#657b83&quot;
[layouts]
    [[default]]
        [[[child1]]]
            type = Terminal
            parent = window0
            profile = default
        [[[window0]]]
            type = Window
            parent = &quot;&quot;
[plugins]&lt;/pre&gt;
&lt;h3 id=&quot;配置dircolors&quot;&gt;配置dircolors&lt;/h3&gt;
&lt;p&gt;完成上述配置后，你会发现用ls命令查看目录和文件时是一片灰色。这是因为默认情况下solarized各种bright方案基本都是灰色，而系统默认显示目录和文件时多用bright色，此时需要配置dircolors才能显示出彩色的文件和目录。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/seebi/dircolors-solarized&quot;&gt;dircolors-solarized&lt;/a&gt;项目提供了适合于solarized的dircolors配色方案，只要选择合适的方案使用就可以了。例如我是用的solarized dark配色，所以可以选择适合这个配色的dircolors.ansi-dark：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;curl https://raw.github.com/seebi/dircolors-solarized/master/dircolors.ansi-dark &gt; ~/.dircolors&lt;/pre&gt;
&lt;p&gt;然后在~/.bashrc中加入如下配置：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;# enable color support of ls and also add handy aliases
if [ -x /usr/bin/dircolors ]; then
    test -r ~/.dircolors &amp;&amp; eval &quot;$(dircolors -b ~/.dircolors)&quot; || eval &quot;$(dircolors -b)&quot;
    alias ls=&#39;ls --color=auto&#39;
    #alias dir=&#39;dir --color=auto&#39;
    #alias vdir=&#39;vdir --color=auto&#39;

    alias grep=&#39;grep --color=auto&#39;
    alias fgrep=&#39;fgrep --color=auto&#39;
    alias egrep=&#39;egrep --color=auto&#39;
fi

# some more ls aliases
alias ll=&#39;ls -alF&#39;
alias la=&#39;ls -A&#39;
alias l=&#39;ls -CF&#39;&lt;/pre&gt;
&lt;p&gt;执行&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;source ~/.bashrc&lt;/pre&gt;
&lt;p&gt;后，再执行ls或ll就可以看到彩色的目录或文件了。&lt;/p&gt;
&lt;p&gt;配置完的terminator效果如下：&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/getting-started-with-ubuntu/01.png&quot;/&gt;&lt;/p&gt;

&lt;h2 id=&quot;配置vim&quot;&gt;配置VIM&lt;/h2&gt;
&lt;p&gt;vim作为我日常使用频率最高的代码编辑器，自然要好好配置一番。之前的maximum-awesome自带了很多vim插件，这里我没有精力完全按照maximum-awesome的插件配置，只选取了日常比较常用的几个插件先配上，后面需要的话可以再加。&lt;/p&gt;
&lt;h3 id=&quot;插件&quot;&gt;插件&lt;/h3&gt;
&lt;p&gt;我目前安装的插件有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/scrooloose/nerdtree&quot;&gt;NERDTree&lt;/a&gt;：可以在单独的window中浏览目录和文件，方便打开的选取文件。&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vim-scripts/taglist.vim&quot;&gt;taglist&lt;/a&gt;：可以通过ctags生成的tag文件索引定位代码中的常量、函数、类等结构，阅读代码和写代码必备。&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Lokaltog/vim-powerline&quot;&gt;powerline&lt;/a&gt;：在底部显示一个非常漂亮的状态条，还可以通过不同的颜色提醒用户当前处于什么状态（如normal、insert或visual）。&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/altercation/vim-colors-solarized&quot;&gt;vim-colors-solarized&lt;/a&gt;：vim的solarized配色插件。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果所有插件都按vim标准方法安装，各种插件会非常分散，不便于管理，于是我选用&lt;a href=&quot;https://github.com/tpope/vim-pathogen&quot;&gt;pathogen&lt;/a&gt;安装和管理vim插件。pathogen允许将各个插件放在.vim/bundle/下各自的目录中，通过启动时自动加载所有插件。&lt;/p&gt;
&lt;h3 id=&quot;自动配置工具&quot;&gt;自动配置工具&lt;/h3&gt;
&lt;p&gt;整个配置过程过于繁琐不再赘述，我已经将配置过程写成了一个自动配置脚本并放到了github：&lt;a href=&quot;https://github.com/ericzhang-cn/vim-conf&quot;&gt;https://github.com/ericzhang-cn/vim-conf&lt;/a&gt;，需要的朋友只要clone下来并运行init.sh脚本就可以自动完成整个配置：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;git clone https://github.com/ericzhang-cn/vim-conf.git
cd vim-conf &amp;&amp; ./init.sh&lt;/pre&gt;
&lt;p&gt;最终配置效果如下：&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/getting-started-with-ubuntu/02.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;（更新：当前我已经换用&lt;a href=&quot;https://github.com/ericzhang-cn/maximum-awesome-linux&quot;&gt;maximum-awesome-linux&lt;/a&gt;，不再维护之前那个配置脚本）&lt;/p&gt;
&lt;h3 id=&quot;快捷键&quot;&gt;快捷键&lt;/h3&gt;
&lt;p&gt;其中并没有对vim默认的快捷键做过多重设，只有两个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;,-d：打开或关闭NERDTree&lt;/li&gt;
&lt;li&gt;,-t：打开或关闭taglist&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;（更新：换用maximum-awesome-linux后快捷键会不一样，具体请参考&lt;a href=&quot;https://github.com/ericzhang-cn/maximum-awesome-linux/blob/master/README.md&quot;&gt;README&lt;/a&gt;）&lt;/p&gt;
&lt;h1 id=&quot;常用工具&quot;&gt;常用工具&lt;/h1&gt;
&lt;h2 id=&quot;浏览器&quot;&gt;浏览器&lt;/h2&gt;
&lt;p&gt;Ubuntu自带的是Firefox，我平常使用的是Chromium，这点在Ubuntu下没任何问题，可以直接安装：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;sudo apt-get install chromium-browser&lt;/pre&gt;
&lt;p&gt;用Google账号登录后，书签、插件等会自动同步，非常方便。&lt;/p&gt;
&lt;h2 id=&quot;搜狗输入法-amp-谷歌输入法&quot;&gt;搜狗输入法&amp;谷歌输入法&lt;/h2&gt;
&lt;p&gt;Mac下有搜狗输入法或百度输入法。不过目前搜狗也基于fcitx做了linux版的搜狗输入法。&lt;/p&gt;
&lt;p&gt;Ubuntu自带的ibus直接卸掉，然后安装&lt;a href=&quot;https://fcitx-im.org/wiki/Fcitx&quot;&gt;fcitx&lt;/a&gt;：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;sudo add-apt-repository ppa:fcitx-team/nightly &amp;&amp; sudo apt-get update
sudo apt-get install fcitx-sogoupinyin&lt;/pre&gt;
&lt;p&gt;当然谷歌拼音也不错：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;sudo apt-get install fcitx-googlepinyin&lt;/pre&gt;
&lt;h2 id=&quot;邮件&quot;&gt;邮件&lt;/h2&gt;
&lt;p&gt;Mac下是使用Foxmail for Mac，linux下可以选择ThunderBird，用起来很顺手。&lt;/p&gt;
&lt;h2 id=&quot;dropbox&quot;&gt;Dropbox&lt;/h2&gt;
&lt;p&gt;Dropbox有官方linux客户端，可以到其官网下载安装。不过安装后也许会发现dropbox的icon没有出现在上面的indicator上，可以这样修复：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;sudo apt-get install libappindicator1
dropbox stop &amp;&amp; dropbox start&lt;/pre&gt;
&lt;h2 id=&quot;evernote&quot;&gt;Evernote&lt;/h2&gt;
&lt;p&gt;很不幸，我平常用来做笔记的evernote没有linux官方客户端，不过可以选择使用web版，或者安装第三方linux客户端everpad：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;sudo add-apt-repository ppa:nvbn-rm/ppa
sudo apt-get update
sudo apt-get install everpad&lt;/pre&gt;
&lt;p&gt;当然功能和美观程度都没法和Mac下官方的客户端相比，不过日常使用还是足够了。&lt;/p&gt;
&lt;h2 id=&quot;办公office&quot;&gt;办公Office&lt;/h2&gt;
&lt;p&gt;Ubuntu自带的LibreOffice可以很好的满足需求，试用了WPS for linux，无法正常打开Office 2010的文件，故而弃用之。LibreOffice打开Office 2010的文件没有问题。&lt;/p&gt;
&lt;h2 id=&quot;pdf及论文管理&quot;&gt;PDF及论文管理&lt;/h2&gt;
&lt;p&gt;平常使用的&lt;a href=&quot;http://www.mendeley.com/&quot;&gt;Mendeley&lt;/a&gt;有官方linux客户端，可以到官网下载。&lt;/p&gt;
&lt;h2 id=&quot;绘图及图像处理&quot;&gt;绘图及图像处理&lt;/h2&gt;
&lt;p&gt;平常工程文档做图一般用&lt;a href=&quot;http://www.yworks.com/en/products_yed_about.html&quot;&gt;yEd&lt;/a&gt;，是java开发的，所以在linux下可以直接使用。&lt;/p&gt;
&lt;p&gt;图像处理可以用gimp：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;sudo apt-get install gimp&lt;/pre&gt;
&lt;h2 id=&quot;影音播放&quot;&gt;影音播放&lt;/h2&gt;
&lt;p&gt;平常很少离线看视频，如果需要的话，vlc应该够了：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;sudo apt-get install vlc&lt;/pre&gt;
&lt;h2 id=&quot;截图工具&quot;&gt;截图工具&lt;/h2&gt;
&lt;p&gt;截图工具非shutter莫属：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;sudo apt-get install shutter&lt;/pre&gt;
&lt;h2 id=&quot;阿里旺旺&quot;&gt;阿里旺旺&lt;/h2&gt;
&lt;p&gt;因为工作关系，平常必须使用旺旺交流。Mac下有非常好用的官方版，linux下并没有官方旺旺，有个内部版本巨烂无比。不过之前参加活动获赠一个&lt;a href=&quot;http://www.codeweavers.com/products/&quot;&gt;CrossOver&lt;/a&gt;正版授权序列号。&lt;/p&gt;
&lt;p&gt;目前CrossOver运行阿里旺旺2013非常流畅。&lt;/p&gt;
&lt;h2 id=&quot;qq&quot;&gt;QQ&lt;/h2&gt;
&lt;p&gt;这个对我来说不是刚需。CrossOver可以运行TM2013，另外WebQQ或开VirtualBox在虚拟机中运行QQ都可以。&lt;/p&gt;
&lt;h2 id=&quot;专业软件&quot;&gt;专业软件&lt;/h2&gt;
&lt;p&gt;其它常用软件特别是如R或Octave等专业软件，本身就有linux版，所以可以按需安装。如Git等开发工具本来就是linux下的软件，当然更不在话下。&lt;/p&gt;
&lt;p&gt;目前已经用Ubuntu工作了一段时间，总体来说从Mac转过来肯定需要一点适应，不过目前感觉没有遇到特别大的问题，毕竟同属Unix系，对码农来说大多数使用习惯几乎是无缝切换。&lt;/p&gt;
&lt;p&gt;另外，重新回到OSS的感觉不错！最后上张图吧：&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/getting-started-with-ubuntu/03.png&quot;/&gt;&lt;/p&gt;</description> 
        </item> 
        
        <item> 
            <title>一个故事告诉你比特币的原理及运作机制</title> 
            <link>http://blog.codinglabs.org/articles/bitcoin-mechanism-make-easy.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link> 
            <guid>http://blog.codinglabs.org/articles/bitcoin-mechanism-make-easy.html</guid> 
            <author>ericzhang.buaa@gmail.com 张洋</author> 
            <pubDate>Mon, 16 Dec 2013 00:00:00 +0800</pubDate> 
            <description>&lt;p&gt;周末花时间看了一些比特币原理相关的资料，虽然不敢说把每个细节都完全搞懂了，不过整体思路和关键部分的主要原理还是比较明白。写一篇文章分享给大家。这篇文章的定位会比较科普，尽量用类比的方法将比特币的基本原理讲出来。这篇文章不会涉及算法和协议中比较细节的部分，打算后面会再写一篇程序员视角下的比特币原理，那里会从技术人员的视角对比特币系统中较为关键的数据结构、算法和协议进行一些讲解。&lt;/p&gt;
&lt;p&gt;在这篇文章中我会给出一个虚拟的村庄叫“比特村”，整个文章会以讲故事的方式，逐步告诉大家比特币提出的动机、解决了什么问题以及一些关键组件的目标和设计方案。&lt;/p&gt;
&lt;h1 id=&quot;问题的提出&quot;&gt;问题的提出&lt;/h1&gt;
&lt;p&gt;我们先从比特币产生的动机开始。&lt;/p&gt;
&lt;h2 id=&quot;以物易物的比特村&quot;&gt;以物易物的比特村&lt;/h2&gt;
&lt;p&gt;话说在这个世界上，有一个叫比特村的小村庄，村庄共有几百户人家。这个村庄几乎与世隔绝，过着自给自足的生活。由于没有大规模贸易，比特村村民一直过着以物易物的生活，也就是说村民之间并没有使用统一的货币，互相间的贸易基本上就是老张家拿一袋面粉换老李家一只羊，王大嫂拿一筐野果换刘大婶两尺布。村民们一直就这么纯朴的生活着。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/bitcoin-mechanism-make-easy/01.png&quot;/&gt;&lt;/p&gt;

&lt;h2 id=&quot;实物货币&quot;&gt;实物货币&lt;/h2&gt;
&lt;p&gt;终于有一天，村民觉得一直这样以物易物实在太不方便了，于是村子全员开会，讨论如何解决这个问题。有人提议，以便于分割且稀有的东西，例如黄金，作为一般等价物，把其它物品和黄金的对应关系编成一张表格，例如一克黄金对应一只羊，一克黄金对应一袋面粉等等，此时老张再也不用扛着一袋面粉气喘吁吁的去老李家换羊了，他只要从家里摸出一克金子，就可以去老李家牵回一只羊，而老李拿着这一克黄金可以从任何愿意出让面粉的人那里换回一袋面粉，当然也可以换取任何和一克黄金等值的物品。&lt;/p&gt;
&lt;p&gt;此时比特村进入了实物货币时代。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/bitcoin-mechanism-make-easy/02.png&quot;/&gt;&lt;/p&gt;

&lt;h2 id=&quot;符号货币&quot;&gt;符号货币&lt;/h2&gt;
&lt;p&gt;好景不长，过了一段时间，实物货币的弊端也出现了。因为比特村附近金矿并不多，开采和冶炼金子太费时费力了。而随着使用，金子总是不断会因为磨损、丢失或有人故意囤积而发生损耗。全村人又一次坐在了一起，开始商讨对策。此时有人说，其实大家也不必一定要真的用黄金啊，随便找张纸，写上“一克黄金”，只要全村人都认同这张纸就等于一克黄金，问题不就解决了。其他人纷纷表示认同，但同时也有了新的问题：真实的黄金是需要开采和冶炼的，金矿有限，开采和冶炼也需要成本，所以没有人可以短期凭空制造大量的黄金，可写字就不同了，只要我纸够笔够，随便像写多少写多少，那这就变成拼谁家里纸多了，搞不好到时一万张纸才能换一只羊（实际上这就发生了经济学上的通货膨胀）。&lt;/p&gt;
&lt;p&gt;大家一想也是啊。不过此时又有人提出了解决方案：这个纸不是谁写都有效，我们只认村里德高望重的老村长写得，大家都认识老村长的字。老村长写一些纸，同时按照各家黄金存量发给大家等量的纸，例如老张家有二百克黄金，老村长就发给老张二百张写着“一克黄金”的纸，同时将老张家的黄金拿走作为抵押。就这样，老村长将村里所有黄金收归到自己的家里，并按各家上交的黄金数量发给等值的写有字的纸。此时村民就可以拿着这些纸当黄金进行贸易了，而且大家都认得老村长的字，其他人伪造不出来。另外，如果谁的纸磨损太严重，也可拿到老村长那里兑换新的等值的纸，另外老村长承诺任何人如果想要换成真黄金，只要拿纸回来，老村长就会把等值的黄金还给那人。因为老村长写得纸的黄金量和真实放在家里的黄金量是一样的，所以只要严格按照销毁多少纸新写多少纸的原则，每一张有效的纸总能换回相应的真黄金。&lt;/p&gt;
&lt;p&gt;此时，比特村进入了符号货币（纸币）时代。而老村长就承担了政府和银行的角色。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/bitcoin-mechanism-make-easy/03.png&quot;/&gt;&lt;/p&gt;

&lt;h2 id=&quot;中央系统虚拟货币&quot;&gt;中央系统虚拟货币&lt;/h2&gt;
&lt;p&gt;又过了几年，老村长由于每天都要核对大量的旧纸币，写新的纸币，还要把各种账目仔细做好记录。一来二去，老村长操劳过度不幸驾鹤西去了。&lt;/p&gt;
&lt;p&gt;比特村再次召开全体大会，讨论应该怎么办。此时老村长的儿子二狗子自告奋勇接过了父亲的笔，承担起货币发行的责任。这个年轻的村长二狗子很聪明，他做了几天，发现好像也不用真的写那么多纸。完全可以这样：村民把纸币都交上来，销毁，但是二狗子会记录下每户上交的纸币数量。以后如果要进行付钱，例如老张要拿一克金子向老李换一只羊，就一起给二狗子打个电话，说明要将老张名下的一克金子划归老李名下，二狗子拿出账本，看看老张名下是否有一克金子，如果有就在老张的名下减掉一克，在老李的名下加上一克，这样就完成了支付，此时老李在电话中听到二狗子确认转账完成，就可以放心让老张把羊牵走了。&lt;/p&gt;
&lt;p&gt;此时比特村进入了中央系统虚拟货币时代。每个村民都不需要用实物支付，支付过程变成了二狗子那边维护的账本上数字的变更。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/bitcoin-mechanism-make-easy/04.png&quot;/&gt;&lt;/p&gt;

&lt;h2 id=&quot;分布式虚拟货币&quot;&gt;分布式虚拟货币&lt;/h2&gt;
&lt;p&gt;这新上任的二狗子是聪明，不过这人有时候是聪明反被聪明误。有一天二狗子盯着这账本，心想这全村各户谁有多少钱就是我说的算，那我岂不是……。于是他头脑一热，私自从老张帐下划了十克金子到自己名下。&lt;/p&gt;
&lt;p&gt;本以为天衣无缝，但没想到老张也有记账的习惯，有一天他正要付钱却被二狗子告知账户没钱了。老张核对了一下自己的账本，明明还有十克啊，于是拿着账本去找二狗子理论，这一核对发现了那笔未经老张同意的转账。&lt;/p&gt;
&lt;p&gt;东窗事发！比特村炸开锅了。二狗子被弹劾是不可避免了，不过通过这件事，大家发现了账本集中在一个人手里的弊端：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这个体系完全依赖于账本持有人的个人信用，如果这个人不守规矩，随意篡改账本，那么整个货币系统就会崩溃&lt;/li&gt;
&lt;li&gt;如果这个人家里失火或者账本失窃，同样也会为整个体系带来毁灭性的打击&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;正当人们不知所措时，村里一个叫中本聪的宅男科学家走上了台，告诉大家他已经设计了一套不依赖任何中央处理人的叫比特币的虚拟货币系统，可以解决上述问题。然后他缓缓讲述了自己的方案。&lt;/p&gt;
&lt;p&gt;下面我们就来看看中本聪同学是如何设计这套系统的。&lt;/p&gt;
&lt;h1 id=&quot;基础设施搭建&quot;&gt;基础设施搭建&lt;/h1&gt;
&lt;h2 id=&quot;账簿公开机制&quot;&gt;账簿公开机制&lt;/h2&gt;
&lt;p&gt;中本聪首先说明，要对现有账簿进行如下改造：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;账簿上不再记载每户村民的余额，而只记载每一笔交易。即记载每一笔交易的付款人、收款人和付款金额。只要账簿的初始状态确定，每一笔交易记录可靠并有时序，当前每个人持有多少钱是可以推算出来的。&lt;/li&gt;
&lt;li&gt;账簿由私有改为公开，只要任何村民需要，都可以获得当前完整的账簿，账簿上记录了从账簿创建开始到当前所有的交易记录。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;此言一出，下面立刻炸锅了。第一条还无所谓，但是第二条简直无法接受，因为账簿可是记录了所有村民的交易，这样大家的隐私不全暴露了吗。&lt;/p&gt;
&lt;p&gt;中本聪倒是不慌不忙，拿出了一对奇怪的东西。&lt;/p&gt;
&lt;h2 id=&quot;身份与签名机制（公钥加密系统）&quot;&gt;身份与签名机制（公钥加密系统）&lt;/h2&gt;
&lt;p&gt;中本聪说，大家不要慌。在他的这套机制下，任何人都不使用真实身份交易，而是使用一个唯一的代号交易。&lt;/p&gt;
&lt;p&gt;他展示了手里神奇的东西，说这两件东西分别叫保密印章和印章扫描器。后面他会给村里每一户发一个保密印章和一个印章扫描器。两者的作用如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;保密印章可以在纸上盖一个章，每个印章盖出的章都隐含了一个全村唯一的一串字符，但是凭肉眼是看不出来的。也无法通过观察来制造出相应的印章。&lt;/li&gt;
&lt;li&gt;印章扫描器可以扫描某个已经盖好的章，读出隐含的信息，并在液晶屏上显示出一串字符。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有了这两个神奇的东西，大家就可以在不暴露真实身份的情况下进行交易了，而印章隐含的那一串字符就是这户人家的代号。具体如何巧妙利用保密印章和印章扫描器进行交易，会在下文详述。&lt;/p&gt;
&lt;h2 id=&quot;成立虚拟矿工组织（挖矿群体）&quot;&gt;成立虚拟矿工组织（挖矿群体）&lt;/h2&gt;
&lt;p&gt;下一步，中本聪面向全村招募虚拟矿工，招募要求如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;矿工以组为单位，一组可以是单独的一户，也可以是几户联合为一组&lt;/li&gt;
&lt;li&gt;成为矿工不影响正常使用货币&lt;/li&gt;
&lt;li&gt;矿工每天要花费一定时间从事比特币“挖矿”活动，但是不同于挖金矿，虚拟矿工不需要拿着工具去野外作业，在家里就可以完成工作&lt;/li&gt;
&lt;li&gt;矿工有一定可能性获得报酬，在挖矿活动中付出的努力越多，获得报酬的可能性越大&lt;/li&gt;
&lt;li&gt;矿工可以随时退出，也可以随时有新的矿工加进来&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;很快，大约有五分之一的村民加入比特币矿工组织，共分成了7个组。&lt;/p&gt;
&lt;h2 id=&quot;建立初始账簿（创世块）&quot;&gt;建立初始账簿（创世块）&lt;/h2&gt;
&lt;p&gt;下面，中本聪宣布，先根据二狗子手里的账簿，把抵押的所有黄金按账簿记录的余额退还给每位村民，然后彻底销毁这本账簿。&lt;/p&gt;
&lt;p&gt;然后，中本聪拿出一本新账簿，在账簿的第一页上记录了一些交易记录，特别的是，这些记录的付款人一栏全都是“系统”，而收款人分别是每个印章对应的隐含字符，代表初始时刻，系统为每一户默认分配了一定数量比特币，但是数量非常少，都只有几枚，甚至有些不幸的村户没有获得比特币。&lt;/p&gt;
&lt;p&gt;接着中本聪说，由于目前市面上比特币非常少，大家可以先回到用黄金做货币的时代，由于我不是村长，我也没有权利强迫大家一定要承认比特币，大家可以自行决定要不要接受比特币。不过随着比特币的流动和矿工的活动，比特币会慢慢多起来。&lt;/p&gt;
&lt;h1 id=&quot;支付与交易&quot;&gt;支付与交易&lt;/h1&gt;
&lt;p&gt;做了这么多铺垫，终于说到重点了，下面说一下在这样一个体系下如何完成支付。以老张付给老李10个比特币为例。&lt;/p&gt;
&lt;h3 id=&quot;付款人签署交易单&quot;&gt;付款人签署交易单&lt;/h3&gt;
&lt;p&gt;为了支付10个比特币，老张首先要询问老李的标识字符串，例如是“ABCDEFG”，同时老张也有一个标识字符串例如是“HIJKLMN”，然后老张写一张单子，内容为“HILKLMN支付10比特币给ABCDEFG”，然后用自己的保密印章改一个章，将这张单子交给老李。另外为了便于追溯这笔钱的来源，还要在单子里注明这笔钱的来源记在哪一页，例如这个单子里，老张的10比特币来自建立账簿时系统的赠送，记录在账簿第一页。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/bitcoin-mechanism-make-easy/05.png&quot;/&gt;&lt;/p&gt;

&lt;h3 id=&quot;收款人确认单据签署人&quot;&gt;收款人确认单据签署人&lt;/h3&gt;
&lt;p&gt;老李拿到这个单子后，需要确认这个单子确实是来自“HIJKLMN”这个人（也就是老张）签署的，这个并不困难。因为单子上必须有保密章，老李拿出印章扫描器，扫一下章，如果液晶屏显示出的字符和付款人字符是一致的（这里是“HIJKLMN”），就可以确认单子确实是付款人签署的。这是因为根据保密印章的机制，没有其他人可以伪造印章，任何一个人只要扫描一下印章，都可以确认单子的付款人和盖章人是否一致。&lt;/p&gt;
&lt;h3 id=&quot;收款人确认付款人余额&quot;&gt;收款人确认付款人余额&lt;/h3&gt;
&lt;p&gt;这个系统到目前还是很有问题。通过保密印章，收款人虽然可以确认付款人确实签署了这份单子，但是无法自行确认付款人是否有足够的余额支付。之前的中央虚拟货币系统中，二狗子负责检查付款人的余额，并通知收款人交易是否有效，现在把二狗子开了，谁来负责记账和确认每笔交易的有效性呢？&lt;/p&gt;
&lt;p&gt;之前说过，中本聪设计的这个系统是分布式货币系统，不依赖任何中央人物，所以不会有一个或少数几个人负责这件事，最终承担这份工作的是之前所提到的矿工组织。老张、老李和全村其他任何使用比特币进行交易的村民都依赖矿工组织的工作才能完成交易。&lt;/p&gt;
&lt;h2 id=&quot;矿工的工作&quot;&gt;矿工的工作&lt;/h2&gt;
&lt;p&gt;矿工的工作是整个系统的核心，也是最复杂性最高的地方。下面逐步介绍矿工的工作内容和目的。&lt;/p&gt;
&lt;h3 id=&quot;矿工的工具&quot;&gt;矿工的工具&lt;/h3&gt;
&lt;p&gt;俗话说，工欲善其事，必先利其器。比特币矿工虽然不用铁撅、铁锨和探照灯等工具，不过也要有一些必备的东西。&lt;/p&gt;
&lt;p&gt;初始账簿。每个组首先自己复制一份初始账簿，初始账簿只有一页，记录了系统的第一次赠送&lt;/p&gt;
&lt;p&gt;空账簿纸。每个小组有若干账簿纸，每一页纸上仅有账簿结构，没有填内容，具体内容的书写规则后面讲述。下面是一张空账簿纸的样子，各个字段的意义后面会说到&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/bitcoin-mechanism-make-easy/06.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;编码生成器（哈希函数）。中本聪又向矿工组织的每个组分发了若干编码生成器，这个东西很神奇，将一页账簿填好内容的账簿纸放入这个机器，机器会在账簿纸的“本账单编号”一栏自动打印一串由“0”和“1”组成的编号，共256个。最神奇的是，编号生成器有如下功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;生成的编号仅与账簿纸上填入的内容有关，与填写人、字体、填写时间等因素均无关&lt;/li&gt;
&lt;li&gt;内容相同的账簿纸生成的编号总是相同，但是如果内容哪怕只改一个字符，编号就会面目全非&lt;/li&gt;
&lt;li&gt;编码生成器在打印编码时还需要将所有填入账簿纸的交易单放入，机器会扫描交易单和填入交易单的一致性，尤其是保密印章，如果发现保密印章和付款人不一致，会拒绝打印编码&lt;/li&gt;
&lt;li&gt;将一张已打印的账簿纸放入，机器会判定编号是否是有效的机器打印，并且判定编号和内容是否一致，这个编号无法伪造&lt;/li&gt;
&lt;li&gt;交易单收件箱。每个矿工小组需要在门口挂一个箱子用于收集交易单。&lt;/li&gt;
&lt;li&gt;公告板。每个矿工小组同样需要一个公告板公示一些信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有了上面的工具，矿工组织就可以开工了！&lt;/p&gt;
&lt;h3 id=&quot;收集交易单&quot;&gt;收集交易单&lt;/h3&gt;
&lt;p&gt;中本聪规定，每笔交易的发起人，不但要将交易单给到收款人，还要同时复制若干份一模一样的交易单投递到每个矿工小组的收件箱里。&lt;/p&gt;
&lt;p&gt;矿工小组的人定期到自己的收件箱里把收集到的交易单一并取出来。&lt;/p&gt;
&lt;h3 id=&quot;填写账簿&quot;&gt;填写账簿&lt;/h3&gt;
&lt;p&gt;此时小组的人拿出一张空的账簿纸，把这些交易填写到“交易清单”一栏，同时找到当前账簿最后一页，将最后一页的编号抄写到“上一张账单编号一栏”。
注意还有个“幸运数字”，可以随便填上一个数字，如12345。然后，将这样账簿纸放入编号生成器，打印好编号，一张账簿就算完成了。&lt;/p&gt;
&lt;p&gt;如果你以为矿工的工作就这么简单，那就大错特错了，中本聪有个变态的规定：只有编号的前10个数均为0，这页账簿纸才算有效。&lt;/p&gt;
&lt;p&gt;根据之前对编号生成器的描述，要修改编号，只能修改账簿纸的内容，而“交易清单”和“上一张账簿纸编号”是不能随便改的，那么只能改幸运数字了。于是为了生成有效的账簿纸，小组里的矿工就不断抄写账簿纸，但每张纸的幸运数字都不同，然后不断的重复将纸放入编码器，如果生成的编号不符合规定，这张纸就算废了，重复这个过程直到生成一串有效的编号。&lt;/p&gt;
&lt;p&gt;我们知道，如果编号的每一个数字都是随机的，那么平均写1000多张幸运数字不同的纸才能获得一个有效的编号。&lt;/p&gt;
&lt;p&gt;这就奇怪了，这些矿工为什么要拼命干这看似无意义的事情呢？还记得之前说过矿工有报酬吧，这就是矿工的动力了。中本聪规定：每一张账簿纸的交易清单第一条交易为“系统给这个小组支付50个比特币”。也就是说，如果你生成了一张有意义的账簿纸，并且被所有挖矿小组接受了，那么就意味着这条交易也被接受了，你的挖矿小组获得了50个比特币。&lt;/p&gt;
&lt;p&gt;这就是矿工被叫做矿工的原因，也是为什么之前说随着交易和矿工的活动，比特币的数量会不断增多。例如下面是一个挖矿过程，这个小组的公共比特币帐号为“UVWXYZ”。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/bitcoin-mechanism-make-easy/07.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;在幸运数字尝试到“533”时，系统生成了一页有效账簿。&lt;/p&gt;
&lt;h3 id=&quot;确认账簿&quot;&gt;确认账簿&lt;/h3&gt;
&lt;p&gt;当某挖矿小组幸运的生成了一张有意义的账簿，为了得到奖励，必须立刻请其它小组确认自己的工作。前面说过，当前村里有7个挖矿组，所以这个小组必须将有效账簿纸誊抄6份快马加鞭送到其他6个小组请求确认。&lt;/p&gt;
&lt;p&gt;中本聪规定，当某个小组接到其他小组送来的账簿纸时，必须立即停下手里的挖矿工作进行账簿确认。&lt;/p&gt;
&lt;p&gt;需要确认的信息有三个：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;账簿的编号有效&lt;/li&gt;
&lt;li&gt;账簿的前一页账簿有效&lt;/li&gt;
&lt;li&gt;交易清单有效&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;首先看第一个，这个确认比较简单。只要将送来的账簿纸放入编码生成器进行验证，如果验证通过，则编号有效。&lt;/p&gt;
&lt;p&gt;第二部分需要将账簿页上的“上一页账簿纸编号”和这个小组目前保存的有效账簿最后一页编号比对，如果相同则确认，如果不同，需要顺着已有账簿向前比对，直到找到这个编号的页。如果没有找到指定的“上一页账簿纸编号”对应的页，这个小组会将此页丢掉。不予确认。&lt;/p&gt;
&lt;p&gt;注意，由上面的机制可以保证，如果各个小组手里的账簿纸是相同的，那么他们都能按同样的顺序装订成相同的账簿。因为后面一张纸的编号总是依赖前面的纸的编号，编码生成器的机制保证了所有合法账簿纸的相对先后顺序在每个小组那里都是相同的（可能会有分支，但不会出现环，后面细讲）。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/bitcoin-mechanism-make-easy/08.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;最后是如何确认交易清单有效，其实也就是要确认当前每笔交易的付款人有足够的余额支付这笔钱。由于交易信息里包含这笔钱是如何来的，还包含了记录来源交易的账单编号。例如，HIJKLMN要给ABCDEFG10个比特币，并注明了这10个比特币来自之前OPQRST支付给HIJKLMN的一笔交易，确认时首先要确认之前这笔交易是否存在，同时还要检查HIJKLMN在这之前没有将这10个比特币支付给别人。这一切确认后，这笔交易有效性就被确认了。&lt;/p&gt;
&lt;p&gt;其中第一笔是系统奖励给生成这页账簿的小组的50个，这笔交易大家都默认承认，后面的只要按照上述方法追溯，就可以确认HIJKLMN是否当前真有10个比特币支付给ABCDEFG。&lt;/p&gt;
&lt;p&gt;如果完成了所有了上述验证并全部通过，这个小组就认可了上述账簿纸有效，然后将这张账簿纸并入小组的主账簿，舍弃目前正在进行的工作，后面的挖矿工作会基于这本更新后的主账本进行。&lt;/p&gt;
&lt;h3 id=&quot;账簿确认反馈&quot;&gt;账簿确认反馈&lt;/h3&gt;
&lt;p&gt;对于挖矿小组来说，当账簿纸送出去后，如果后面有收到其他小组送来的账簿纸，其“上一页账簿纸编号”为自己之前送出去的账簿纸，那么就表示他们的工作成功被其他小组认可了，因为已经有小组基于他们的账簿纸继续工作了。此时，可以粗略的说可以认为已经得到了50个比特币。&lt;/p&gt;
&lt;p&gt;另外，任何一个小组当新生成有效账簿纸或确认了别的小组的账簿纸时，就将最新被这个小组承认的交易写到公告牌上，那么收款人只要发现相关交易被各个小组认可了，基本就可以认为这笔钱已经到了自己的账上，后面他就可以在付款时将钱的来源指向这笔交易了。&lt;/p&gt;
&lt;p&gt;以上就是整个比特币的支付体系。下面我们来分析一下，这个体系为什么可以工作下去，以及这个体系可能面临的风险。&lt;/p&gt;
&lt;h1 id=&quot;工作机制分析&quot;&gt;工作机制分析&lt;/h1&gt;
&lt;p&gt;虽然上面阐述了比特币的基本运作规则，但是村民们还是有不少疑问。所以中本聪同学专门开了个答疑会，解答常见问题。下面总结一下村民最集中关心的问题。&lt;/p&gt;
&lt;h2 id=&quot;核心问题答疑&quot;&gt;核心问题答疑&lt;/h2&gt;
&lt;h3 id=&quot;如果同时收到两份合法的账簿页怎么办？&quot;&gt;如果同时收到两份合法的账簿页怎么办？&lt;/h3&gt;
&lt;p&gt;注意在上面的运行机制中，各个挖矿小组是并行工作的，因此完全可能出现这样的情况：某小组收到两份不一样的账簿页，它们都基于当前这个小组的主账簿的最后一页，并且内容也都完全合法，怎么办？&lt;/p&gt;
&lt;p&gt;关于这个问题，中本聪同学说，小组不应该以线性方式组织账簿，而应该以树状组织账簿，任何时刻，都以当前最长分支作为主账簿，但是保留其它分支。举个例子，某小组同时收到A、B两份账簿页，经核算都是合法的，此时小组应该将两页以分叉的形式组织起来，如下图所示：&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/bitcoin-mechanism-make-easy/09.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;黑色表示当前账簿主干。此时，可以随便选择一个页作为当前主分支，例如选择A：&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/bitcoin-mechanism-make-easy/10.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;此时如果有一个新的账簿页是基于A的，那么这个主干就延续下去：&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/bitcoin-mechanism-make-easy/11.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;如果这个主干一直这么延续下去，表示大家基本都以A为主干，B就会被遗忘。但是也有可能忽然B变成更长了：&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/bitcoin-mechanism-make-easy/12.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;那么我们就需要将B分支作为当前主干，基于这个分支进行后续工作。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/bitcoin-mechanism-make-easy/13.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;从局部来看，虽然在某一时刻各个小组的账簿主干可能存在不一致，但大方向是一致的，那些偶尔由于不同步产生的小分支，会很快被淹没在历史中。&lt;/p&gt;
&lt;h3 id=&quot;如果挖矿小组有人伪造账簿怎么办&quot;&gt;如果挖矿小组有人伪造账簿怎么办&lt;/h3&gt;
&lt;p&gt;关于这个问题，中本聪同学说，只要挖矿组织中大多数人是诚实的，这个系统就可靠，具体分几个方面给予答复。&lt;/p&gt;
&lt;p&gt;首先，基于保密印章机制，没有人能伪造他人身份进行付款，因为编码生成器在打印编码时会核对所有交易单的保密印章，印章和付款人不一致会拒绝打印。&lt;/p&gt;
&lt;p&gt;而且诚实的矿工也不会承认不合法的交易（如某笔交易付款方余额不够）。&lt;/p&gt;
&lt;p&gt;所以只有一种可能的攻击行为，即在收款人确认收款后，从另一条分支上建立另外的交易单，取消之前的付款，而将同一笔钱再次付款给另一个人（即所谓的double-spending问题）。下面同样用一个例子说明这个问题。&lt;/p&gt;
&lt;p&gt;先假设有一个攻击者拥有10个比特币，他准备将这笔钱同时支付给两名受害者A和B，并都得到承认。&lt;/p&gt;
&lt;p&gt;第一步，攻击者准备从受害者A手里买10比特币的黄金，他签署交易单给受害者A，转10个比特币给受害者A。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/bitcoin-mechanism-make-easy/14.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;第二步，这笔交易在最新的账簿页中被确认，并被各个挖矿小组公告出来。受害人A看到公告，确认比特币到账，给了攻击者10个比特币等值的黄金。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/bitcoin-mechanism-make-easy/15.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;第三步，攻击者找到账簿，从包含刚才交易的账簿页的前一页做出一个分支，生成更多的账单页，超过刚才的分支。由于此时刚才攻击者制造的分支变成了主干分支，而包含受害者A得到钱的分支变成了旁支，因此挖矿组织不再承认刚才的转账，受害者A得到的10比特币被取消了。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/bitcoin-mechanism-make-easy/16.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;第四步，攻击者可以再次签署交易单，将同一笔钱支付给受害者B。受害者B确认钱到账后，支付给攻击者等值黄金。&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/bitcoin-mechanism-make-easy/17.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;至此，攻击者将10个比特币花了两次，从两名受害者那里各购得等值黄金。攻击者还可以如法炮制，取消与受害者B的转账，将同一笔钱再支付给其他人……&lt;/p&gt;
&lt;p&gt;关于这种攻击，中本聪给出的解决方案是，建议收款人不要在公告挂出时立即确认交易完成，而是应该再看一段时间，等待各个挖矿小组再挂出6张确认账簿，并且之前的账簿没有被取消，才确认钱已到账。&lt;/p&gt;
&lt;p&gt;中本聪解释道，之前设定变态的编号规则，正是为了防御这一点。根据前面所述，生成有效账簿页不是那么简单的，要花费大量的人力反复试不同的幸运数字，而且过程完全是碰运气。如果某账簿页包含你收到钱的确认，并且在后面又延续了6个，那么攻击者想要在落后6页的情况下从另一个分支赶超当前主分支是非常困难的，除非攻击者拥有非常多的人力，超过其他所有诚实矿工的人力之和。&lt;/p&gt;
&lt;p&gt;而且，如果攻击者有如此多人力，与其花这么大力气搞这种攻击，还不如做良民挖矿来的收益大。这就从动机上杜绝了攻击的形成。&lt;/p&gt;
&lt;h3 id=&quot;比特币会一直增加下去，岂不是会严重通货膨胀&quot;&gt;比特币会一直增加下去，岂不是会严重通货膨胀&lt;/h3&gt;
&lt;p&gt;中本聪说，这一点我也想到了。前面忘了说了，我给矿工组织的操作细则手册会说明，刚开始我们协议每生成一页账簿，奖励小组50个比特币，后面，每当账簿增加21,000页，奖励就减半，例如当达到210,000页后，每生成一页账簿奖励25个比特币，420,000页后，每生成一页奖励12.5个，依次类推，等账簿达到6,930,000页后，新生成账簿页就没有奖励了。此时比特币全量约为21,000,000个，这就是比特币的总量，所以不会无限增加下去。&lt;/p&gt;
&lt;h3 id=&quot;没有奖励后，就没人做矿工了，岂不是没人帮忙确认交易了&quot;&gt;没有奖励后，就没人做矿工了，岂不是没人帮忙确认交易了&lt;/h3&gt;
&lt;p&gt;到时，矿工的收益会由挖矿所得变为收取手续费。例如，你在转账时可以指定其中1%作为手续费支付给生成账簿页的小组，各个小组会挑选手续费高的交易单优先确认。&lt;/p&gt;
&lt;h3 id=&quot;矿工如果越来越多，比特币生成速度会变快吗&quot;&gt;矿工如果越来越多，比特币生成速度会变快吗&lt;/h3&gt;
&lt;p&gt;不会。中本聪解释，虽然可以任意加入和退出矿工组织，导致矿工人数变化，每个矿工也会拿到一个编码生成器，不过我已经在编码生成器中加入了调控机制，当前工作的编码生成器越多，每个机器的效率就越低，保证新账簿页生成速率不变。&lt;/p&gt;
&lt;h3 id=&quot;虽然每个人的代号是匿名的，但如果泄露了某个人的代号，账簿又是公开的，岂不是他的所有账目都查出来了&quot;&gt;虽然每个人的代号是匿名的，但如果泄露了某个人的代号，账簿又是公开的，岂不是他的所有账目都查出来了&lt;/h3&gt;
&lt;p&gt;确实是这样的。例如你要和某人交易，必然要要到他的代号才能填写交易单。因为收款人一栏要填入那人的代号。不过中本聪说可以提供无限制的保密印章，建议每一次交易用不同的保密印章，这样查账簿就追查不到同一个人的所有账目了。&lt;/p&gt;
&lt;p&gt;答疑完毕。&lt;/p&gt;
&lt;h1 id=&quot;说明&quot;&gt;说明&lt;/h1&gt;
&lt;p&gt;本文用通俗比喻的方式讲解了比特币的运行机制。有几点需要说明：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;为了便于理解，我做了很多简化，因此有些机制细节和实际的比特币可能不完全相同。但总体思想和关键原理是一致的。&lt;/li&gt;
&lt;li&gt;由于很多计算机世界的东西（如公钥体系、网络传输）在现实世界中并没有特别好的对等物，所以故事里难免有一些生硬和不合常理的细节。&lt;/li&gt;
&lt;li&gt;本文描述的是比特币网络本身的技术原理和运作机制，当在如Mtgox这种买卖市场中进行比特币交易时，市场做了中间代理，并不遵从上述机制&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;参考&quot;&gt;参考&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;http://bitcoin.org/bitcoin.pdf&quot;&gt;Bitcoin: A Peer-to-Peer Electronic Cash System&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://bitcoin.it&quot;&gt;https://bitcoin.it&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.codingnow.com/2011/05/bitcoin.html&quot;&gt;云风的BLOG: Bitcoin 的基本原理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.btc123.com/data/docs/easy_understood_bitcoin_mechanism.pdf&quot;&gt;易懂的比特币工作机理详解&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description> 
        </item> 
        
        <item> 
            <title>MySQL索引与Index Condition Pushdown</title> 
            <link>http://blog.codinglabs.org/articles/index-condition-pushdown.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link> 
            <guid>http://blog.codinglabs.org/articles/index-condition-pushdown.html</guid> 
            <author>ericzhang.buaa@gmail.com 张洋</author> 
            <pubDate>Thu, 05 Dec 2013 00:00:00 +0800</pubDate> 
            <description>&lt;p&gt;大约在两年前，我写了&lt;a href=&quot;/articles/theory-of-mysql-index.html&quot;&gt;一篇关于MySQL索引的文章&lt;/a&gt;。最近有同学在文章的评论中对文章的内容提出质疑，质疑主要集中在联合索引的使用方式上。在那篇文章中，我说明联合索引是将各个索引字段做字符串连接后作为key，使用时将整体做前缀匹配。&lt;/p&gt;
&lt;p&gt;而这名同学在&lt;a href=&quot;https://mariadb.com/kb/en/index-condition-pushdown/&quot;&gt;这个页面&lt;/a&gt;找到了如下一句话：index condition pushdown is usually useful with multi-column indexes: the first component(s) is what index access is done for, the subsequent have columns that we read and check conditions on。从而认为联合索引的使用方式与文中不符。&lt;/p&gt;
&lt;p&gt;实际上，这个页面所讲述的是在MariaDB 5.3.3（MySQL是在5.6）开始引入的一种叫做Index Condition Pushdown（以下简称ICP）的查询优化方式。由于本身不是一个层面的东西，前文中说的是Index Access，而这里是Query Optimization，所以并不构成对前文正确性的影响。在写前文时，MySQL还没有ICP，所以文中没有涉及相关内容，但考虑到新版本的MariaDB或MySQL中ICP的启用确实影响了一些查询行为的外在表现。所以决定写这篇文章详细讲述一下ICP的原理以及对索引使用方式的优化。&lt;/p&gt;
&lt;h1 id=&quot;实验&quot;&gt;实验&lt;/h1&gt;
&lt;p&gt;先从一个简单的实验开始直观认识ICP的作用。&lt;/p&gt;
&lt;h2 id=&quot;安装数据库&quot;&gt;安装数据库&lt;/h2&gt;
&lt;p&gt;首先需要安装一个支持ICP的MariaDB或MySQL数据库。我使用的是MariaDB 5.5.34，如果是使用MySQL则需要5.6版本以上。&lt;/p&gt;
&lt;p&gt;Mac环境下可以通过brew安装：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;brew install mairadb&lt;/pre&gt;
&lt;p&gt;其它环境下的安装请参考&lt;a href=&quot;https://www.mariadb.com/kb/en/getting-installing-and-upgrading-mariadb/&quot;&gt;MariaDB官网关于下载安装的文档&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&quot;导入示例数据&quot;&gt;导入示例数据&lt;/h2&gt;
&lt;p&gt;与前文一样，我们使用&lt;a href=&quot;https://launchpad.net/test-db/&quot;&gt;Employees Sample Database&lt;/a&gt;，作为示例数据库。完整示例数据库的下载地址为：&lt;a href=&quot;https://launchpad.net/test-db/employees-db-1/1.0.6/+download/employees_db-full-1.0.6.tar.bz2&quot;&gt;https://launchpad.net/test-db/employees-db-1/1.0.6/+download/employees_db-full-1.0.6.tar.bz2&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;将下载的压缩包解压后，会看到一系列的文件，其中employees.sql就是导入数据的命令文件。执行&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;mysql -h[host] -u[user] -p &lt; employees.sql&lt;/pre&gt;
&lt;p&gt;就可以完成建库、建表和load数据等一系列操作。此时数据库中会多一个叫做employees的数据库。库中的表如下：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;MariaDB [employees]&gt; SHOW TABLES;
+---------------------+
| Tables_in_employees |
+---------------------+
| departments         |
| dept_emp            |
| dept_manager        |
| employees           |
| salaries            |
| titles              |
+---------------------+
6 rows in set (0.00 sec)&lt;/pre&gt;
&lt;p&gt;我们将使用employees表做实验。&lt;/p&gt;
&lt;h2 id=&quot;建立联合索引&quot;&gt;建立联合索引&lt;/h2&gt;
&lt;p&gt;employees表包含雇员的基本信息，表结构如下：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;MariaDB [employees]&gt; DESC employees.employees;
+------------+---------------+------+-----+---------+-------+
| Field      | Type          | Null | Key | Default | Extra |
+------------+---------------+------+-----+---------+-------+
| emp_no     | int(11)       | NO   | PRI | NULL    |       |
| birth_date | date          | NO   |     | NULL    |       |
| first_name | varchar(14)   | NO   |     | NULL    |       |
| last_name  | varchar(16)   | NO   |     | NULL    |       |
| gender     | enum(&#39;M&#39;,&#39;F&#39;) | NO   |     | NULL    |       |
| hire_date  | date          | NO   |     | NULL    |       |
+------------+---------------+------+-----+---------+-------+
6 rows in set (0.01 sec)&lt;/pre&gt;
&lt;p&gt;这个表默认只有一个主索引，因为ICP只能作用于二级索引，所以我们建立一个二级索引：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;ALTER TABLE employees.employees ADD INDEX first_name_last_name (first_name, last_name);&lt;/pre&gt;
&lt;p&gt;这样就建立了一个first_name和last_name的联合索引。&lt;/p&gt;
&lt;h2 id=&quot;查询&quot;&gt;查询&lt;/h2&gt;
&lt;p&gt;为了明确看到查询性能，我们启用profiling并关闭query cache：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;SET profiling = 1;
SET query_cache_type = 0;
SET GLOBAL query_cache_size = 0;&lt;/pre&gt;
&lt;p&gt;然后我们看下面这个查询：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;MariaDB [employees]&gt; SELECT * FROM employees WHERE first_name=&#39;Mary&#39; AND last_name LIKE &#39;%man&#39;;
+--------+------------+------------+-----------+--------+------------+
| emp_no | birth_date | first_name | last_name | gender | hire_date  |
+--------+------------+------------+-----------+--------+------------+
| 254642 | 1959-01-17 | Mary       | Botman    | M      | 1989-11-24 |
| 471495 | 1960-09-24 | Mary       | Dymetman  | M      | 1988-06-09 |
| 211941 | 1962-08-11 | Mary       | Hofman    | M      | 1993-12-30 |
| 217707 | 1962-09-05 | Mary       | Lichtman  | F      | 1987-11-20 |
| 486361 | 1957-10-15 | Mary       | Oberman   | M      | 1988-09-06 |
| 457469 | 1959-07-15 | Mary       | Weedman   | M      | 1996-11-21 |
+--------+------------+------------+-----------+--------+------------+&lt;/pre&gt;
&lt;p&gt;根据MySQL索引的前缀匹配原则，两者对索引的使用是一致的，即只有first_name采用索引，last_name由于使用了模糊前缀，没法使用索引进行匹配。我将查询联系执行三次，结果如下：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;+----------+------------+---------------------------------------------------------------------------+
| Query_ID | Duration   | Query                                                                     |
+----------+------------+---------------------------------------------------------------------------+
|       38 | 0.00084400 | SELECT * FROM employees WHERE first_name=&#39;Mary&#39; AND last_name LIKE &#39;%man&#39; |
|       39 | 0.00071800 | SELECT * FROM employees WHERE first_name=&#39;Mary&#39; AND last_name LIKE &#39;%man&#39; |
|       40 | 0.00089600 | SELECT * FROM employees WHERE first_name=&#39;Mary&#39; AND last_name LIKE &#39;%man&#39; |
+----------+------------+---------------------------------------------------------------------------+&lt;/pre&gt;
&lt;p&gt;然后我们关闭ICP：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;SET optimizer_switch=&#39;index_condition_pushdown=off&#39;;&lt;/pre&gt;
&lt;p&gt;在运行三次相同的查询，结果如下：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;+----------+------------+---------------------------------------------------------------------------+
| Query_ID | Duration   | Query                                                                     |
+----------+------------+---------------------------------------------------------------------------+
|       42 | 0.00264400 | SELECT * FROM employees WHERE first_name=&#39;Mary&#39; AND last_name LIKE &#39;%man&#39; |
|       43 | 0.01418900 | SELECT * FROM employees WHERE first_name=&#39;Mary&#39; AND last_name LIKE &#39;%man&#39; |
|       44 | 0.00234200 | SELECT * FROM employees WHERE first_name=&#39;Mary&#39; AND last_name LIKE &#39;%man&#39; |
+----------+------------+---------------------------------------------------------------------------+&lt;/pre&gt;
&lt;p&gt;有意思的事情发生了，关闭ICP后，同样的查询，耗时是之前的三倍以上。下面我们用explain看看两者有什么区别：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;MariaDB [employees]&gt; EXPLAIN SELECT * FROM employees WHERE first_name=&#39;Mary&#39; AND last_name LIKE &#39;%man&#39;;
+------+-------------+-----------+------+----------------------+----------------------+---------+-------+------+-----------------------+
| id   | select_type | table     | type | possible_keys        | key                  | key_len | ref   | rows | Extra                 |
+------+-------------+-----------+------+----------------------+----------------------+---------+-------+------+-----------------------+
|    1 | SIMPLE      | employees | ref  | first_name_last_name | first_name_last_name | 44      | const |  224 | Using index condition |
+------+-------------+-----------+------+----------------------+----------------------+---------+-------+------+-----------------------+
1 row in set (0.00 sec)&lt;/pre&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;MariaDB [employees]&gt; EXPLAIN SELECT * FROM employees WHERE first_name=&#39;Mary&#39; AND last_name LIKE &#39;%man&#39;;
+------+-------------+-----------+------+----------------------+----------------------+---------+-------+------+-------------+
| id   | select_type | table     | type | possible_keys        | key                  | key_len | ref   | rows | Extra       |
+------+-------------+-----------+------+----------------------+----------------------+---------+-------+------+-------------+
|    1 | SIMPLE      | employees | ref  | first_name_last_name | first_name_last_name | 44      | const |  224 | Using where |
+------+-------------+-----------+------+----------------------+----------------------+---------+-------+------+-------------+
1 row in set (0.00 sec)&lt;/pre&gt;
&lt;p&gt;前者是开启ICP，后者是关闭ICP。可以看到区别在于Extra，开启ICP时，用的是Using index condition；关闭ICP时，是Using where。&lt;/p&gt;
&lt;p&gt;其中Using index condition就是ICP提高查询性能的关键。下一节说明ICP提高查询性能的原理。&lt;/p&gt;
&lt;h1 id=&quot;原理&quot;&gt;原理&lt;/h1&gt;
&lt;p&gt;ICP的原理简单说来就是将可以利用索引筛选的where条件在存储引擎一侧进行筛选，而不是将所有index access的结果取出放在server端进行where筛选。&lt;/p&gt;
&lt;p&gt;以上面的查询为例，在没有ICP时，首先通过索引前缀从存储引擎中读出224条first_name为Mary的记录，然后在server段用where筛选last_name的like条件；而启用ICP后，由于last_name的like筛选可以通过索引字段进行，那么存储引擎内部通过索引与where条件的对比来筛选掉不符合where条件的记录，这个过程不需要读出整条记录，同时只返回给server筛选后的6条记录，因此提高了查询性能。&lt;/p&gt;
&lt;p&gt;下面通过图两种查询的原理详细解释。&lt;/p&gt;
&lt;h2 id=&quot;关闭icp&quot;&gt;关闭ICP&lt;/h2&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/index-condition-pushdown/01.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;在不支持ICP的系统下，索引仅仅作为data access使用。&lt;/p&gt;
&lt;h2 id=&quot;开启icp&quot;&gt;开启ICP&lt;/h2&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/index-condition-pushdown/02.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;在ICP优化开启时，在存储引擎端首先用索引过滤可以过滤的where条件，然后再用索引做data access，被index condition过滤掉的数据不必读取，也不会返回server端。&lt;/p&gt;
&lt;h2 id=&quot;注意事项&quot;&gt;注意事项&lt;/h2&gt;
&lt;p&gt;有几个关于ICP的事情要注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ICP只能用于二级索引，不能用于主索引。&lt;/li&gt;
&lt;li&gt;也不是全部where条件都可以用ICP筛选，如果某where条件的字段不在索引中，当然还是要读取整条记录做筛选，在这种情况下，仍然要到server端做where筛选。&lt;/li&gt;
&lt;li&gt;ICP的加速效果取决于在存储引擎内通过ICP筛选掉的数据的比例。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;参考&quot;&gt;参考&lt;/h1&gt;
&lt;p&gt;[1] &lt;a href=&quot;https://mariadb.com/kb/en/index-condition-pushdown/&quot;&gt;https://mariadb.com/kb/en/index-condition-pushdown/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href=&quot;http://dev.mysql.com/doc/refman/5.6/en/index-condition-pushdown-optimization.html&quot;&gt;http://dev.mysql.com/doc/refman/5.6/en/index-condition-pushdown-optimization.html&lt;/a&gt;&lt;/p&gt;
</description> 
        </item> 
        
        <item> 
            <title>使用MPlayer观看Coursera课程视频的一些心得</title> 
            <link>http://blog.codinglabs.org/articles/using-mplayer-for-coursera.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link> 
            <guid>http://blog.codinglabs.org/articles/using-mplayer-for-coursera.html</guid> 
            <author>ericzhang.buaa@gmail.com 张洋</author> 
            <pubDate>Sun, 06 Oct 2013 00:00:00 +0800</pubDate> 
            <description>&lt;p&gt;之前一直是在线看&lt;a href=&quot;https://www.coursera.org/&quot;&gt;Coursera&lt;/a&gt;上的课程视频。最近迫于租住的房子网速太差，加之Coursera访问经常不稳定，为了使得流畅学习的过程不被破坏，开始考虑将视频下载到本地观看。&lt;/p&gt;
&lt;p&gt;因为之前一直没有在本地看视频的习惯，很少使用播放器，所以找个顺心的播放器就成了重中之重。经过一番折腾，最终选择了&lt;a href=&quot;http://www.mplayerhq.hu&quot;&gt;MPlayer&lt;/a&gt;，原因主要有如下几点。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;免费的。&lt;/li&gt;
&lt;li&gt;MPlayer同时支持Mac和Linux。因为我公司用的是Mac，而住处用的是Linux，所以播放器能跨这两个操作系统很重要。&lt;/li&gt;
&lt;li&gt;通过命令行操作，简单快捷。这也是很吸引我的一点，我实在不习惯为了播放一个视频用鼠标在文件系统中一层一层的点啊点，而MPlayer只要一行命令就可以播放指定视频，并且可以方便的指定播放参数。播放过程中也是全快捷键操作，效率很高。&lt;/li&gt;
&lt;li&gt;能自动加载srt字幕。英文课程还是需要字幕支持的。&lt;/li&gt;
&lt;li&gt;可以快放并且保持语调不变。这点对我也很重要，我看视频一般是用1.5倍速播放，Coursera的html5播放器可以完美支持快放且保持音调不变，而我惊喜的发现MPlayer也只要通过简单的启动参数就可以实现相同的效果。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面和大家分享一下用MPlayer看Coursera视频的心得。&lt;/p&gt;
&lt;h1 id=&quot;安装&quot;&gt;安装&lt;/h1&gt;
&lt;p&gt;MPlayer存在于大多数Linux发行版和Mac的软件源里，因此可以很方便的安装。&lt;/p&gt;
&lt;p&gt;Mac下建议用&lt;a href=&quot;http://brew.sh/&quot;&gt;Homebrew&lt;/a&gt;安装：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums&quot;&gt;
brew install mplayer
&lt;/pre&gt;

&lt;p&gt;注意，如果你和我一样用的是OSX 10.9 Mavericks，那么直接安装会失败。这是因为brew的mplayer安装脚本不兼容10.9，这块我折腾了好久。最后在github上找到了&lt;a href=&quot;https://github.com/i8degrees/homebrew/commit/d0ba78cf321bb7fa005284377e50e98d57bf13a7&quot;&gt;相关的补丁&lt;/a&gt;。这个补丁目前还在brew的hotfix分支下，没有合并到master，我们可以手工应用补丁，将这个补丁文件覆盖掉我们本地brew下的mplayer.rb文件，再执行上面的命令就可以正常安装了。&lt;/p&gt;
&lt;p&gt;Linux下可以用相应发行版的软件源安装。例如Ubuntu或Linux Mint（我使用的发行版），可以通过apt安装：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums&quot;&gt;
sudo apt-get install mplayer
&lt;/pre&gt;

&lt;h1 id=&quot;使用&quot;&gt;使用&lt;/h1&gt;
&lt;h2 id=&quot;打开文件&quot;&gt;打开文件&lt;/h2&gt;
&lt;p&gt;安装完成后，直接在命令行用：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums&quot;&gt;
mplayer 视频文件
&lt;/pre&gt;

&lt;p&gt;就可以打开相应的文件进行播放了，具体效果见下图：&lt;/p&gt;
&lt;p class=&quot;picture&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/uploads/pictures/using-mplayer-for-coursera/01.png&quot;/&gt;&lt;/p&gt;

&lt;h2 id=&quot;基本操作&quot;&gt;基本操作&lt;/h2&gt;
&lt;p&gt;MPlayer的播放界面只有一个画面框，所有操作都是通过键盘完成。基本操作如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;左右箭头 - 快退或快进10秒&lt;/li&gt;
&lt;li&gt;上下箭头 - 快退或快进1分钟&lt;/li&gt;
&lt;li&gt;PageUp和PageDown - 快进或快退10分钟&lt;/li&gt;
&lt;li&gt;p或空格键 - 暂停/继续&lt;/li&gt;
&lt;li&gt;q或ESC键 - 退出播放&lt;/li&gt;
&lt;li&gt;/和* - 减小或增大音量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其它还有一些常用操作可以通过以下命令查看：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums&quot;&gt;
mplayer -h
&lt;/pre&gt;

&lt;h2 id=&quot;挂载字幕&quot;&gt;挂载字幕&lt;/h2&gt;
&lt;p&gt;如果有和视频文件同名的srt文件，MPlayer会自动挂载字幕，也可以通过-sub来指定字幕：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums&quot;&gt;
mplayer -sub 字幕文件 视频文件
&lt;/pre&gt;

&lt;h2 id=&quot;加速播放&quot;&gt;加速播放&lt;/h2&gt;
&lt;p&gt;大多数课程视频讲解稍显啰嗦，因此可以通过加速播放节省学习时间。MPlayer通过-speed选项改变播放速度，例如：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums&quot;&gt;
mplayer -speed 1.5 path/to/video/file
&lt;/pre&gt;

&lt;p&gt;可以将播放速度调整为原始的1.5倍。&lt;/p&gt;
&lt;h2 id=&quot;保持正常音调&quot;&gt;保持正常音调&lt;/h2&gt;
&lt;p&gt;用上面的方法加速播放后，声音也会加速，频率变快，因此音调非常尖锐刺耳，这个问题可以通过ScaleTempo插件解决。这个插件默认包含在MPlayer中。只要通过下面命令：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums&quot;&gt;
mplayer -af scaletempo -speed 1.5 path/to/video/file
&lt;/pre&gt;

&lt;p&gt;就可以加速播放的同时保持语调不变了。&lt;/p&gt;
</description> 
        </item> 
        
    </channel>
</rss>
